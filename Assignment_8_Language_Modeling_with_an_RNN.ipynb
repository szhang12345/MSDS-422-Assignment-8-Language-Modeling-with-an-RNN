{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_8 Language Modeling with an RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/szhang12345/MSDS-422-Assignment-8-Language-Modeling-with-an-RNN./blob/main/Assignment_8_Language_Modeling_with_an_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p4IoLQUz3Px"
      },
      "source": [
        "###### **MSDS 422 Assignment 8: Language Modeling with an RNN**\n",
        "\n",
        "**By Siying Zhang**\n",
        "\n",
        "**Topic: Review**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2NRJL0ozg6A"
      },
      "source": [
        "# Ingest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwIWqBuC1PFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea6b5ca-27a1-4481-e372-51b0c94f0c33"
      },
      "source": [
        "!pip install chakin\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "# Python chakin package previously installed by \n",
        "#    pip install chakin\n",
        "import chakin  \n",
        "\n",
        "import json\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "\n",
        "import datetime"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: chakin in /usr/local/lib/python3.7/dist-packages (0.0.8)\n",
            "Requirement already satisfied: pandas>=0.20.1 in /usr/local/lib/python3.7/dist-packages (from chakin) (1.1.5)\n",
            "Requirement already satisfied: progressbar2>=3.20.0 in /usr/local/lib/python3.7/dist-packages (from chakin) (3.38.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from chakin) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.1->chakin) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.1->chakin) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.1->chakin) (1.19.5)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2>=3.20.0->chakin) (2.5.6)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oePCSqm0FmI"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9uSZKrVDkVc",
        "outputId": "a294bee6-894f-4aa8-84c4-1976a47bd496"
      },
      "source": [
        "chakin.search(lang='English')  # lists available indices in English\n",
        "\n",
        "# Specify English embeddings file to download and install\n",
        "# by index number, number of dimensions, and subfoder name\n",
        "# Note that GloVe 50-, 100-, 200-, and 300-dimensional folders\n",
        "# are downloaded with a single zip download\n",
        "\n",
        "CHAKIN_INDEX = 18\n",
        "NUMBER_OF_DIMENSIONS = 50\n",
        "SUBFOLDER_NAME = \"glove.twitter.27B\"\n",
        "\n",
        "DATA_FOLDER = \"embeddings\"\n",
        "ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
        "ZIP_FILE_ALT = \"glove\" + ZIP_FILE[5:]  # sometimes it's lowercase only...\n",
        "UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
        "if SUBFOLDER_NAME[-1] == \"d\":\n",
        "    GLOVE_FILENAME = os.path.join(\n",
        "        UNZIP_FOLDER, \"{}.txt\".format(SUBFOLDER_NAME))\n",
        "else:\n",
        "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.{}d.txt\".format(\n",
        "        SUBFOLDER_NAME, NUMBER_OF_DIMENSIONS))\n",
        "    \n",
        "if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
        "    print(\"Downloading embeddings to '{}'\".format(ZIP_FILE))\n",
        "    chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
        "else:\n",
        "    print(\"Embeddings already downloaded.\")\n",
        "\n",
        "if not os.path.exists(UNZIP_FOLDER):\n",
        "    import zipfile\n",
        "    if not os.path.exists(ZIP_FILE) and os.path.exists(ZIP_FILE_ALT):\n",
        "        ZIP_FILE = ZIP_FILE_ALT\n",
        "    with zipfile.ZipFile(ZIP_FILE, \"r\") as zip_ref:\n",
        "        print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
        "        zip_ref.extractall(UNZIP_FOLDER)\n",
        "else:\n",
        "    print(\"Embeddings already extracted.\")\n",
        "\n",
        "print('\\nRun complete')\n",
        "\n",
        "# Do the same for a different vector/dimension\n",
        "\n",
        "CHAKIN_INDEX = 11\n",
        "NUMBER_OF_DIMENSIONS = 50\n",
        "SUBFOLDER_NAME = \"glove.6B\"\n",
        "\n",
        "DATA_FOLDER = \"embeddings\"\n",
        "ZIP_FILE = os.path.join(DATA_FOLDER, \"{}.zip\".format(SUBFOLDER_NAME))\n",
        "ZIP_FILE_ALT = \"glove\" + ZIP_FILE[5:]  # sometimes it's lowercase only...\n",
        "UNZIP_FOLDER = os.path.join(DATA_FOLDER, SUBFOLDER_NAME)\n",
        "if SUBFOLDER_NAME[-1] == \"d\":\n",
        "    GLOVE_FILENAME = os.path.join(\n",
        "        UNZIP_FOLDER, \"{}.txt\".format(SUBFOLDER_NAME))\n",
        "else:\n",
        "    GLOVE_FILENAME = os.path.join(UNZIP_FOLDER, \"{}.{}d.txt\".format(\n",
        "        SUBFOLDER_NAME, NUMBER_OF_DIMENSIONS))\n",
        "    \n",
        "if not os.path.exists(ZIP_FILE) and not os.path.exists(UNZIP_FOLDER):\n",
        "    print(\"Downloading embeddings to '{}'\".format(ZIP_FILE))\n",
        "    chakin.download(number=CHAKIN_INDEX, save_dir='./{}'.format(DATA_FOLDER))\n",
        "else:\n",
        "    print(\"Embeddings already downloaded.\")\n",
        "\n",
        "if not os.path.exists(UNZIP_FOLDER):\n",
        "    import zipfile\n",
        "    if not os.path.exists(ZIP_FILE) and os.path.exists(ZIP_FILE_ALT):\n",
        "        ZIP_FILE = ZIP_FILE_ALT\n",
        "    with zipfile.ZipFile(ZIP_FILE, \"r\") as zip_ref:\n",
        "        print(\"Extracting embeddings to '{}'\".format(UNZIP_FOLDER))\n",
        "        zip_ref.extractall(UNZIP_FOLDER)\n",
        "else:\n",
        "    print(\"Embeddings already extracted.\")\n",
        "\n",
        "print('\\nRun complete')\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   Name  Dimension  ... Language    Author\n",
            "2          fastText(en)        300  ...  English  Facebook\n",
            "11         GloVe.6B.50d         50  ...  English  Stanford\n",
            "12        GloVe.6B.100d        100  ...  English  Stanford\n",
            "13        GloVe.6B.200d        200  ...  English  Stanford\n",
            "14        GloVe.6B.300d        300  ...  English  Stanford\n",
            "15       GloVe.42B.300d        300  ...  English  Stanford\n",
            "16      GloVe.840B.300d        300  ...  English  Stanford\n",
            "17    GloVe.Twitter.25d         25  ...  English  Stanford\n",
            "18    GloVe.Twitter.50d         50  ...  English  Stanford\n",
            "19   GloVe.Twitter.100d        100  ...  English  Stanford\n",
            "20   GloVe.Twitter.200d        200  ...  English  Stanford\n",
            "21  word2vec.GoogleNews        300  ...  English    Google\n",
            "\n",
            "[12 rows x 7 columns]\n",
            "Embeddings already downloaded.\n",
            "Embeddings already extracted.\n",
            "\n",
            "Run complete\n",
            "Embeddings already downloaded.\n",
            "Embeddings already extracted.\n",
            "\n",
            "Run complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10SN9K1ODkVd",
        "outputId": "a140d07a-5284-4f87-c159-d35591563603"
      },
      "source": [
        "!ls -l embeddings"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2326768\n",
            "drwxr-xr-x 2 root root       4096 Feb 28 19:36 glove.6B\n",
            "-rw-r--r-- 1 root root  862182613 Feb 28 19:36 glove.6B.zip\n",
            "drwxr-xr-x 2 root root       4096 Feb 28 19:29 glove.twitter.27B\n",
            "-rw-r--r-- 1 root root 1520408563 Feb 28 19:28 glove.twitter.27B.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwKr38qAodhg"
      },
      "source": [
        "Reading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgVnZPPBdr5h"
      },
      "source": [
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbJk8-DqdyRv",
        "outputId": "e12bb4b3-e720-441d-e8ed-d11c8963cc42"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARmaunYKDkVf",
        "outputId": "d635ad15-f75b-4d38-dc4b-e756dc152d9b"
      },
      "source": [
        "!ls -l /content/drive/My\\ Drive/Colab\\ Notebooks/8_NWU_MSDS422_RNN/assignment8_files/"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35\n",
            "drwx------ 3 root root  4096 Feb 28 21:48 embeddings\n",
            "drwx------ 2 root root  4096 Feb 28 21:33 movie-reviews-negative\n",
            "drwx------ 2 root root  4096 Feb 28 21:42 movie-reviews-positive\n",
            "-rw------- 1 root root  2442 Feb 28 21:48 run-chakin-to-get-embeddings-v001.py\n",
            "-rw------- 1 root root 20021 Feb 28 21:48 run-jump-start-rnn-sentiment-v002.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLMaGDAsDkVf"
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import re  # regular expressions\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "RANDOM_SEED = 42"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2LmBsAcJDkVg",
        "outputId": "d1833fd5-acbc-4508-cace-16d0e21e5c0c"
      },
      "source": [
        "def reset_graph(seed= RANDOM_SEED):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "REMOVE_STOPWORDS = False # no stopword removal \n",
        "EVOCABSIZE = 1193515  # specify desired size of pre-defined embedding vocabulary\n",
        "\n",
        "embeddings_directory = 'embeddings/glove.twitter.27B'\n",
        "filename = 'glove.twitter.27B.100d.txt'\n",
        "\n",
        "embeddings_filename = os.path.join(embeddings_directory, filename)\n",
        "embeddings_filename"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'embeddings/glove.twitter.27B/glove.twitter.27B.100d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym1-0cU7DkVg",
        "outputId": "cd0fb719-b8fd-4e8d-d057-ad7051afb333"
      },
      "source": [
        "def load_embedding_from_disks(embeddings_filename, with_indexes=True):\n",
        "    if with_indexes:\n",
        "        word_to_index_dict = dict()\n",
        "        index_to_embedding_array = []\n",
        "  \n",
        "    else:\n",
        "        word_to_embedding_dict = dict()\n",
        "\n",
        "    with open(embeddings_filename, 'r') as embeddings_file:\n",
        "        for (i, line) in enumerate(embeddings_file):\n",
        "\n",
        "            split = line.split(' ')\n",
        "\n",
        "            word = split[0]\n",
        "\n",
        "            representation = split[1:]\n",
        "            representation = np.array(\n",
        "                [float(val) for val in representation]\n",
        "            )\n",
        "\n",
        "            if with_indexes:\n",
        "                word_to_index_dict[word] = i\n",
        "                index_to_embedding_array.append(representation)\n",
        "            else:\n",
        "                word_to_embedding_dict[word] = representation\n",
        "\n",
        "    # Empty representation for unknown words.\n",
        "    _WORD_NOT_FOUND = [0.0] * len(representation)\n",
        "    if with_indexes:\n",
        "        _LAST_INDEX = i + 1\n",
        "        word_to_index_dict = defaultdict(\n",
        "            lambda: _LAST_INDEX, word_to_index_dict)\n",
        "        index_to_embedding_array = np.array(\n",
        "            index_to_embedding_array + [_WORD_NOT_FOUND])\n",
        "        return word_to_index_dict, index_to_embedding_array\n",
        "    else:\n",
        "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
        "        return word_to_embedding_dict\n",
        "\n",
        "print('\\nLoading embeddings from', embeddings_filename)\n",
        "word_to_index, index_to_embedding = \\\n",
        "    load_embedding_from_disks(embeddings_filename, with_indexes=True)\n",
        "print(\"Embedding loaded from disks.\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading embeddings from embeddings/glove.twitter.27B/glove.twitter.27B.100d.txt\n",
            "Embedding loaded from disks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfkAnrv-ufR4"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A07hNEo-dlpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c2e2421-b485-4e1c-ebcd-7b677e827579"
      },
      "source": [
        "vocab_size, embedding_dim = index_to_embedding.shape\n",
        "print(\"Embedding is of shape: {}\".format(index_to_embedding.shape))\n",
        "print(\"This means (number of words, number of dimensions per word)\\n\")\n",
        "print(\"The first words are words that tend occur more often.\")\n",
        "\n",
        "print(\"Note: for unknown words, the representation is an empty vector,\\n\"\n",
        "      \"and the index is the last one. The dictionnary has a limit:\")\n",
        "print(\"    {} --> {} --> {}\".format(\"A word\", \"Index in embedding\", \n",
        "      \"Representation\"))\n",
        "word = \"worsdfkljsdf\"  # a word obviously not in the vocabulary\n",
        "idx = word_to_index[word] # index for word obviously not in the vocabulary\n",
        "complete_vocabulary_size = idx \n",
        "embd = list(np.array(index_to_embedding[idx], dtype=int)) # \"int\" compact print\n",
        "#print(\"    {} --> {} --> {}\".format(word, idx, embd))\n",
        "word = \"the\"\n",
        "idx = word_to_index[word]\n",
        "embd = list(index_to_embedding[idx])  # \"int\" for compact print only.\n",
        "#print(\"    {} --> {} --> {}\".format(word, idx, embd))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding is of shape: (1193515, 100)\n",
            "This means (number of words, number of dimensions per word)\n",
            "\n",
            "The first words are words that tend occur more often.\n",
            "Note: for unknown words, the representation is an empty vector,\n",
            "and the index is the last one. The dictionnary has a limit:\n",
            "    A word --> Index in embedding --> Representation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUUA8jK1DkVi",
        "outputId": "a7543070-001f-468b-a58d-851d42aa0295"
      },
      "source": [
        "# Show how to use embeddings dictionaries with a test sentence\n",
        "# This is a famous typing exercise with all letters of the alphabet\n",
        "# https://en.wikipedia.org/wiki/The_quick_brown_fox_jumps_over_the_lazy_dog\n",
        "a_typing_test_sentence = 'The quick brown fox jumps over the lazy dog'\n",
        "print('\\nTest sentence: ', a_typing_test_sentence, '\\n')\n",
        "words_in_test_sentence = a_typing_test_sentence.split()\n",
        "\n",
        "print('Test sentence embeddings from complete vocabulary of', \n",
        "      complete_vocabulary_size, 'words:\\n')\n",
        "for word in words_in_test_sentence:\n",
        "    word_ = word.lower()\n",
        "    embedding = index_to_embedding[word_to_index[word_]]\n",
        "    print(word_ + \": \", embedding)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test sentence:  The quick brown fox jumps over the lazy dog \n",
            "\n",
            "Test sentence embeddings from complete vocabulary of 1193514 words:\n",
            "\n",
            "the:  [ 9.5152e-02  3.7024e-01  5.4291e-01  1.9621e-01  4.8205e-02  3.2033e-01\n",
            " -5.9638e-01  1.5868e-02 -1.2989e-01 -6.3028e-01  8.1944e-02  2.4164e-01\n",
            " -6.0990e+00 -6.8557e-01  5.0354e-01 -3.4089e-02  1.1705e-01 -7.7403e-03\n",
            " -8.6512e-02  4.3617e-01 -4.3982e-01  2.6125e-01 -4.0348e-02 -1.9194e-01\n",
            "  8.3204e-02 -5.8246e-01 -3.1923e-02  1.2630e-01  4.0120e-01  6.8906e-02\n",
            " -1.0517e-01 -2.0804e-01 -4.2554e-01  4.7799e-01  3.4651e-01  2.4057e-01\n",
            "  5.0244e-02 -7.2587e-02 -2.4347e-03 -5.0342e-01 -1.0601e+00 -3.1586e-01\n",
            " -3.2457e-02 -7.6317e-02  7.9045e-01  8.6367e-02 -1.9632e-01  5.7566e-02\n",
            "  8.4129e-01 -4.2020e-01 -1.1335e-03 -8.5632e-02  6.1910e-02  2.1423e-01\n",
            " -1.0356e-01 -3.6946e-02 -2.6005e-01 -3.5657e-01  5.4321e-02  3.0875e-02\n",
            "  1.4092e-01 -9.1998e-02 -4.1841e-01 -3.1135e-01 -1.4937e-01 -2.2699e-04\n",
            " -3.3454e-01 -1.4848e-01 -1.1944e-01 -2.7174e-01  3.1320e-01 -1.0998e-01\n",
            " -4.7524e-01  1.4056e-01  3.9641e-01 -4.9413e-02 -4.2601e-01 -2.3576e-01\n",
            "  6.1482e-02 -3.5313e-02  2.4161e+00  2.8979e-01  3.8882e-01  3.6779e-01\n",
            "  2.0685e-01  1.3992e-01 -4.2459e-01  4.4590e-01  2.6234e-01 -4.4834e-01\n",
            "  3.7196e-03 -2.2521e-01  1.4764e-01 -3.6417e-01 -1.8493e-01  2.2282e-01\n",
            "  4.7626e-01 -5.1083e-01  4.6877e-01  3.4882e-01]\n",
            "quick:  [ 0.50111    0.37708   -0.19973   -0.55111    0.17148    0.019936\n",
            "  0.50052    0.017863  -0.43901    0.4485    -0.22766   -0.087691\n",
            " -3.5079    -0.62763   -0.75083   -0.19767   -0.39356    0.3996\n",
            " -0.081026  -0.53157   -0.38539   -0.61069    0.10148   -0.10846\n",
            " -0.29013    0.61234    0.027151  -0.044352  -0.40846    0.42045\n",
            " -0.22149    0.018245  -0.25989   -0.049784   0.28018    0.26186\n",
            " -0.22841   -0.28096    0.046061   0.26917   -0.41851    0.25948\n",
            "  0.10509    0.75517    0.43909    0.07024    0.053149   0.59465\n",
            " -0.23239    0.37033   -0.29459   -0.040892  -0.37618    0.015432\n",
            "  0.056196  -0.25702   -0.16717    0.2405     0.29895   -0.64143\n",
            "  0.91313   -0.057541   0.20291    1.0468     0.65415   -0.94901\n",
            "  0.49342    0.014261   0.14139    0.17338   -0.76048    0.53518\n",
            "  0.26007    0.34376    0.057837  -0.55036    0.66677   -0.31764\n",
            "  0.41491   -0.025773   1.5507     0.394     -0.31088   -0.53684\n",
            "  0.15205    0.70041   -0.1879    -0.24963   -0.16778   -0.34475\n",
            " -0.51597    0.010533  -0.59016   -0.44993    0.80113    0.051259\n",
            " -0.49647    0.59636    0.0075998  0.28048  ]\n",
            "brown:  [-0.26106   -0.75489   -0.022668   0.055802  -0.77145    0.05871\n",
            "  0.3852     0.40926   -0.97445   -0.33838    0.47742   -0.01054\n",
            " -3.1085    -0.55482    0.35536    0.44814    0.29137    0.16997\n",
            "  0.66486    0.22324    0.32805   -0.40968   -0.19862    0.3546\n",
            "  0.30566   -0.55413   -0.54773    0.25429   -0.72556   -0.22337\n",
            "  0.16802    0.14168   -1.0443    -0.57601   -0.21027    0.18212\n",
            " -0.81012   -0.71126   -0.39691   -0.13592   -0.37764   -0.52612\n",
            " -0.80185    0.31638   -0.073107  -0.74961    0.44858   -0.0039955\n",
            " -0.22895   -0.95689   -0.70048   -0.15495    0.30279    0.51368\n",
            " -0.51663    0.053121  -0.23784    0.49018    0.47278    0.29428\n",
            " -0.42305    0.39041   -0.051611  -0.30997    0.12854   -0.67797\n",
            " -0.23172    0.13328    0.43269   -0.28219    0.56389   -0.52302\n",
            "  0.52544    0.20713   -0.4926     0.2071    -0.012374   0.62647\n",
            "  0.38548    0.5472     1.5739     0.38571   -0.095062  -0.70715\n",
            " -0.37873   -0.065873   0.34776    0.80396   -0.34771    0.43994\n",
            " -0.23445   -0.36284   -0.11516   -0.68272   -0.027322   0.24447\n",
            " -0.088484   0.34491   -0.55879    0.343    ]\n",
            "fox:  [ 0.64344    0.0086088  0.50145   -0.70381   -0.36289   -0.51602\n",
            "  0.3751    -0.0078184  0.10752   -0.29124    0.61808   -0.036332\n",
            " -2.4467    -0.0050135  0.18236   -0.18152   -0.19349   -0.19442\n",
            "  0.3793     0.46691    0.03579   -0.48468   -0.45103   -0.045509\n",
            "  0.6732    -1.4904    -0.23975   -0.26736   -0.058426   0.11573\n",
            "  0.79477    0.09746   -0.36717   -0.20758    0.099006  -0.51114\n",
            " -0.023912   0.14275   -0.87894    0.13728   -0.26524   -0.33326\n",
            "  0.25857   -0.27703    0.5022     0.7164    -0.26708    0.018559\n",
            "  0.39153   -0.42015   -0.55746   -0.2797    -0.36874    0.090716\n",
            " -0.29017    0.25543   -0.016203   0.014775  -0.45174   -0.48211\n",
            " -0.18746    0.59934   -0.20146   -0.3756    -0.11143    0.26213\n",
            "  0.15496    0.53471    0.43618   -0.7356     0.34366   -0.036715\n",
            " -0.2377    -0.3525    -0.5546     0.44059   -0.17759    0.50194\n",
            " -0.59675   -0.0427     1.5432     0.22326    0.40868    0.70572\n",
            " -0.17751    0.071547   0.84483    0.3794    -0.67034   -0.54685\n",
            " -0.55382   -0.88651   -0.25728   -0.1996    -0.15984    0.37977\n",
            "  0.62406    0.037116  -0.427      0.029686 ]\n",
            "jumps:  [-0.28348    0.1648     1.4019    -0.85675    0.027551   0.5412\n",
            "  0.88782    0.046905  -0.45316   -0.60368    0.55262    1.205\n",
            " -2.0585     0.51703   -0.32351   -0.30435    0.45369    0.31998\n",
            " -0.96374   -0.60021    0.47335   -0.74688    0.47179   -0.2158\n",
            " -0.09306    0.83334   -0.74749   -0.089607  -0.17782    1.2692\n",
            "  0.6947     0.043769   0.52786   -0.010808  -0.16553   -0.074203\n",
            " -0.49438    0.39217    0.16966   -0.73894    0.57277    0.55778\n",
            " -0.30532   -0.24023    0.96471    0.19401    0.40399    0.1934\n",
            "  0.084298   0.66986   -0.19846    0.29749    0.3546    -0.23385\n",
            " -0.14053    0.29882    0.69889    0.19321    0.95773   -0.18805\n",
            " -0.22225   -0.23144    0.38776    0.0037293  0.24487   -0.33569\n",
            " -0.17885    0.73331    0.26516   -0.098724   0.31112   -0.33525\n",
            " -0.63795   -0.97048   -0.63374    0.25719    0.23121   -1.4143\n",
            "  1.011     -0.014403   0.8709     0.57321    0.40159    0.302\n",
            " -0.43126   -0.16309    0.81327    0.45568   -0.14238   -0.69614\n",
            " -0.21193   -0.13398   -0.20042    0.14101    0.47543   -0.36219\n",
            "  0.71711   -0.47106    0.35576    0.46552  ]\n",
            "over:  [-1.3037e-01  2.0490e-01  4.2575e-01 -3.1239e-01 -5.4739e-01  2.1011e-01\n",
            " -7.2276e-03 -6.3219e-02 -1.2984e-02 -8.2143e-02  2.5385e-01  3.2791e-01\n",
            " -4.9173e+00  3.1567e-01 -2.0232e-01 -2.5671e-01 -1.8498e-03  4.3715e-01\n",
            " -1.0066e+00  2.5198e-02 -3.9015e-02 -3.4754e-01 -2.8745e-02  6.5716e-01\n",
            "  1.0906e+00  2.3102e-01  5.5719e-01 -4.6840e-01 -5.8515e-01 -2.9006e-01\n",
            " -2.6508e-01  3.9253e-01 -5.1165e-01  2.4492e-02  8.1263e-01 -4.2014e-01\n",
            " -3.4857e-01  3.5984e-01  1.5941e-01 -6.9736e-01 -1.4426e+00 -9.9337e-03\n",
            " -2.3335e-01 -4.6266e-01  2.6243e-01 -2.9373e-01  4.8860e-01  7.2830e-01\n",
            " -3.2475e-02  6.2540e-01 -4.3399e-01 -1.0553e-01  3.1752e-01 -1.5631e-01\n",
            " -2.4268e-01 -3.9298e-01 -3.7478e-01 -6.6699e-02  1.5477e-01  7.4870e-01\n",
            " -2.3318e-01  9.7446e-02 -4.4590e-01 -6.1845e-02  1.7504e-01  7.3357e-01\n",
            "  8.8520e-01 -1.9843e-01  2.5146e-01 -3.8909e-01 -3.0322e-01  4.3190e-01\n",
            "  5.9478e-02 -2.7233e-01 -3.8758e-01  5.1850e-01 -1.6175e-01 -7.5551e-01\n",
            "  5.5890e-01  1.0797e-01  1.4943e+00  1.6329e-01  6.6365e-01  1.2885e-01\n",
            " -9.8670e-02 -4.8738e-02  1.3253e-01 -1.6620e-01 -4.2653e-01 -1.7694e-01\n",
            " -2.6400e-01  1.0666e-01 -1.9857e-02  1.2652e-01  1.5045e-01 -7.6070e-02\n",
            " -3.4198e-01 -1.4165e-01  4.8806e-01  5.2860e-01]\n",
            "the:  [ 9.5152e-02  3.7024e-01  5.4291e-01  1.9621e-01  4.8205e-02  3.2033e-01\n",
            " -5.9638e-01  1.5868e-02 -1.2989e-01 -6.3028e-01  8.1944e-02  2.4164e-01\n",
            " -6.0990e+00 -6.8557e-01  5.0354e-01 -3.4089e-02  1.1705e-01 -7.7403e-03\n",
            " -8.6512e-02  4.3617e-01 -4.3982e-01  2.6125e-01 -4.0348e-02 -1.9194e-01\n",
            "  8.3204e-02 -5.8246e-01 -3.1923e-02  1.2630e-01  4.0120e-01  6.8906e-02\n",
            " -1.0517e-01 -2.0804e-01 -4.2554e-01  4.7799e-01  3.4651e-01  2.4057e-01\n",
            "  5.0244e-02 -7.2587e-02 -2.4347e-03 -5.0342e-01 -1.0601e+00 -3.1586e-01\n",
            " -3.2457e-02 -7.6317e-02  7.9045e-01  8.6367e-02 -1.9632e-01  5.7566e-02\n",
            "  8.4129e-01 -4.2020e-01 -1.1335e-03 -8.5632e-02  6.1910e-02  2.1423e-01\n",
            " -1.0356e-01 -3.6946e-02 -2.6005e-01 -3.5657e-01  5.4321e-02  3.0875e-02\n",
            "  1.4092e-01 -9.1998e-02 -4.1841e-01 -3.1135e-01 -1.4937e-01 -2.2699e-04\n",
            " -3.3454e-01 -1.4848e-01 -1.1944e-01 -2.7174e-01  3.1320e-01 -1.0998e-01\n",
            " -4.7524e-01  1.4056e-01  3.9641e-01 -4.9413e-02 -4.2601e-01 -2.3576e-01\n",
            "  6.1482e-02 -3.5313e-02  2.4161e+00  2.8979e-01  3.8882e-01  3.6779e-01\n",
            "  2.0685e-01  1.3992e-01 -4.2459e-01  4.4590e-01  2.6234e-01 -4.4834e-01\n",
            "  3.7196e-03 -2.2521e-01  1.4764e-01 -3.6417e-01 -1.8493e-01  2.2282e-01\n",
            "  4.7626e-01 -5.1083e-01  4.6877e-01  3.4882e-01]\n",
            "lazy:  [ 1.4021e-01 -6.1686e-01  6.6047e-01  4.5844e-01 -4.7073e-02  5.6833e-01\n",
            "  4.7711e-01 -3.0135e-01  2.5490e-01  2.7677e-01 -7.2243e-01 -4.7596e-01\n",
            " -3.1877e+00 -3.0520e-01 -1.1225e+00  1.1409e-01 -1.6397e-01 -6.2531e-01\n",
            " -6.4549e-01 -7.0767e-01 -1.3721e-01  1.6656e-01 -1.5643e-01 -5.8997e-01\n",
            "  5.3493e-01  4.2989e-01 -1.6078e-01  3.1838e-01 -1.7478e-01 -6.6117e-02\n",
            " -9.1278e-02 -2.2732e-01 -6.2848e-01  3.7686e-01 -6.0958e-01  3.7723e-02\n",
            "  1.3443e-01  5.8768e-01  1.0611e-01  1.0578e+00 -7.9843e-01  1.5644e-02\n",
            "  5.1333e-01 -2.6829e-01  8.6280e-02 -4.8820e-01 -7.8925e-02  5.7910e-01\n",
            " -8.3873e-01  7.4992e-01 -4.7451e-01  5.3792e-01  2.5934e-01 -2.5577e-01\n",
            " -7.2746e-01  7.2324e-01 -3.5029e-01  2.3883e-01  2.2178e-01  2.3307e-01\n",
            " -2.4567e-01  2.3833e-01  6.6281e-01 -1.1956e-01 -2.3183e-02 -7.2004e-01\n",
            " -4.5729e-02  6.8426e-01  3.5203e-01  5.6147e-01 -6.6437e-01  4.0224e-01\n",
            " -3.9397e-01 -1.1179e-01  1.5747e-01 -1.4167e-03  1.0760e+00  6.7952e-01\n",
            " -3.5587e-01 -7.7132e-02  2.0712e+00  4.2989e-01 -3.2253e-01  1.9375e-02\n",
            "  6.2629e-01  3.2018e-01  3.3936e-01 -9.2320e-02  2.8323e-01  1.4915e-01\n",
            "  2.3714e-01  4.1720e-01 -1.6513e-01  1.8810e-01  7.0461e-01  2.5950e-01\n",
            " -1.0690e-01  9.0640e-01  2.2023e-01 -1.9887e-01]\n",
            "dog:  [ 5.0779e-01 -1.0274e+00  4.8136e-01 -9.4170e-02  4.4837e-01 -5.2291e-01\n",
            "  5.1498e-01 -3.8927e-02  3.5867e-01 -6.5994e-02 -8.2882e-01  7.6179e-01\n",
            " -3.8030e+00 -1.0576e-02  2.1654e-01  5.9712e-01  3.7424e-01 -2.2629e-02\n",
            " -1.0331e-02 -3.3966e-01  9.4336e-02  2.6253e-01 -4.0161e-01 -7.9532e-03\n",
            "  1.0206e+00 -3.5793e-01 -5.6500e-01  5.8815e-01 -8.1847e-01  3.0293e-01\n",
            "  4.7199e-01 -9.7429e-02 -6.1226e-01 -1.7797e-01 -1.1616e-01  3.2586e-01\n",
            "  1.1498e-01 -1.9030e-01  1.1591e-02  4.6478e-01 -1.6805e-01  2.1972e-01\n",
            " -2.5938e-01 -1.3541e-02  7.0714e-01  7.8106e-01  7.9917e-01  1.0389e+00\n",
            "  5.2792e-01 -1.1160e-01 -6.2275e-01  3.0692e-02  3.3847e-01 -5.3092e-01\n",
            " -9.9688e-02  2.1596e-01  6.0522e-01  1.2356e+00 -3.4528e-03 -9.7514e-02\n",
            " -2.4938e-01  2.1539e-01  4.4643e-01  9.5375e-02 -2.7366e-01 -2.8537e-01\n",
            " -4.0894e-01  4.8223e-01  3.0318e-01  1.9440e-01  8.3242e-01 -5.0378e-01\n",
            "  3.0090e-01 -4.9792e-01  5.0297e-01  3.2685e-02 -5.1790e-01 -2.3541e-01\n",
            "  2.2960e-01 -6.3588e-01  1.6270e+00  6.2832e-01 -7.4846e-01  6.0073e-01\n",
            " -1.1215e-02 -3.2113e-01  1.4339e-01 -6.0809e-02  8.8218e-02  6.5936e-01\n",
            " -4.6127e-01 -3.7644e-01 -1.1330e-01  1.5875e-01  3.9119e-01  6.7659e-01\n",
            " -7.1224e-02  1.7458e-01 -3.3406e-02  7.3152e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvY5kAsbDkVi",
        "outputId": "6d34dc7f-cf83-4f66-d75d-82db879c724d"
      },
      "source": [
        "# Define vocabulary size for the language model    \n",
        "# To reduce the size of the vocabulary to the n most frequently used words\n",
        "\n",
        "def default_factory():\n",
        "    return EVOCABSIZE  # last/unknown-word row in limited_index_to_embedding\n",
        "# dictionary has the items() function, returns list of (key, value) tuples\n",
        "limited_word_to_index = defaultdict(default_factory, \\\n",
        "    {k: v for k, v in word_to_index.items() if v < EVOCABSIZE})\n",
        "\n",
        "# Select the first EVOCABSIZE rows to the index_to_embedding\n",
        "limited_index_to_embedding = index_to_embedding[0:EVOCABSIZE,:]\n",
        "# Set the unknown-word row to be all zeros as previously\n",
        "limited_index_to_embedding = np.append(limited_index_to_embedding, \n",
        "    index_to_embedding[index_to_embedding.shape[0] - 1, :].\\\n",
        "        reshape(1,embedding_dim), \n",
        "    axis = 0)\n",
        "\n",
        "# Delete large numpy array to clear some CPU RAM\n",
        "del index_to_embedding\n",
        "\n",
        "# Verify the new vocabulary: should get same embeddings for test sentence\n",
        "# Note that a small EVOCABSIZE may yield some zero vectors for embeddings\n",
        "print('\\nTest sentence embeddings from vocabulary of', EVOCABSIZE, 'words:\\n')\n",
        "for word in words_in_test_sentence:\n",
        "    word_ = word.lower()\n",
        "    embedding = limited_index_to_embedding[limited_word_to_index[word_]]\n",
        "    print(word_ + \": \", embedding)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test sentence embeddings from vocabulary of 1193515 words:\n",
            "\n",
            "the:  [ 9.5152e-02  3.7024e-01  5.4291e-01  1.9621e-01  4.8205e-02  3.2033e-01\n",
            " -5.9638e-01  1.5868e-02 -1.2989e-01 -6.3028e-01  8.1944e-02  2.4164e-01\n",
            " -6.0990e+00 -6.8557e-01  5.0354e-01 -3.4089e-02  1.1705e-01 -7.7403e-03\n",
            " -8.6512e-02  4.3617e-01 -4.3982e-01  2.6125e-01 -4.0348e-02 -1.9194e-01\n",
            "  8.3204e-02 -5.8246e-01 -3.1923e-02  1.2630e-01  4.0120e-01  6.8906e-02\n",
            " -1.0517e-01 -2.0804e-01 -4.2554e-01  4.7799e-01  3.4651e-01  2.4057e-01\n",
            "  5.0244e-02 -7.2587e-02 -2.4347e-03 -5.0342e-01 -1.0601e+00 -3.1586e-01\n",
            " -3.2457e-02 -7.6317e-02  7.9045e-01  8.6367e-02 -1.9632e-01  5.7566e-02\n",
            "  8.4129e-01 -4.2020e-01 -1.1335e-03 -8.5632e-02  6.1910e-02  2.1423e-01\n",
            " -1.0356e-01 -3.6946e-02 -2.6005e-01 -3.5657e-01  5.4321e-02  3.0875e-02\n",
            "  1.4092e-01 -9.1998e-02 -4.1841e-01 -3.1135e-01 -1.4937e-01 -2.2699e-04\n",
            " -3.3454e-01 -1.4848e-01 -1.1944e-01 -2.7174e-01  3.1320e-01 -1.0998e-01\n",
            " -4.7524e-01  1.4056e-01  3.9641e-01 -4.9413e-02 -4.2601e-01 -2.3576e-01\n",
            "  6.1482e-02 -3.5313e-02  2.4161e+00  2.8979e-01  3.8882e-01  3.6779e-01\n",
            "  2.0685e-01  1.3992e-01 -4.2459e-01  4.4590e-01  2.6234e-01 -4.4834e-01\n",
            "  3.7196e-03 -2.2521e-01  1.4764e-01 -3.6417e-01 -1.8493e-01  2.2282e-01\n",
            "  4.7626e-01 -5.1083e-01  4.6877e-01  3.4882e-01]\n",
            "quick:  [ 0.50111    0.37708   -0.19973   -0.55111    0.17148    0.019936\n",
            "  0.50052    0.017863  -0.43901    0.4485    -0.22766   -0.087691\n",
            " -3.5079    -0.62763   -0.75083   -0.19767   -0.39356    0.3996\n",
            " -0.081026  -0.53157   -0.38539   -0.61069    0.10148   -0.10846\n",
            " -0.29013    0.61234    0.027151  -0.044352  -0.40846    0.42045\n",
            " -0.22149    0.018245  -0.25989   -0.049784   0.28018    0.26186\n",
            " -0.22841   -0.28096    0.046061   0.26917   -0.41851    0.25948\n",
            "  0.10509    0.75517    0.43909    0.07024    0.053149   0.59465\n",
            " -0.23239    0.37033   -0.29459   -0.040892  -0.37618    0.015432\n",
            "  0.056196  -0.25702   -0.16717    0.2405     0.29895   -0.64143\n",
            "  0.91313   -0.057541   0.20291    1.0468     0.65415   -0.94901\n",
            "  0.49342    0.014261   0.14139    0.17338   -0.76048    0.53518\n",
            "  0.26007    0.34376    0.057837  -0.55036    0.66677   -0.31764\n",
            "  0.41491   -0.025773   1.5507     0.394     -0.31088   -0.53684\n",
            "  0.15205    0.70041   -0.1879    -0.24963   -0.16778   -0.34475\n",
            " -0.51597    0.010533  -0.59016   -0.44993    0.80113    0.051259\n",
            " -0.49647    0.59636    0.0075998  0.28048  ]\n",
            "brown:  [-0.26106   -0.75489   -0.022668   0.055802  -0.77145    0.05871\n",
            "  0.3852     0.40926   -0.97445   -0.33838    0.47742   -0.01054\n",
            " -3.1085    -0.55482    0.35536    0.44814    0.29137    0.16997\n",
            "  0.66486    0.22324    0.32805   -0.40968   -0.19862    0.3546\n",
            "  0.30566   -0.55413   -0.54773    0.25429   -0.72556   -0.22337\n",
            "  0.16802    0.14168   -1.0443    -0.57601   -0.21027    0.18212\n",
            " -0.81012   -0.71126   -0.39691   -0.13592   -0.37764   -0.52612\n",
            " -0.80185    0.31638   -0.073107  -0.74961    0.44858   -0.0039955\n",
            " -0.22895   -0.95689   -0.70048   -0.15495    0.30279    0.51368\n",
            " -0.51663    0.053121  -0.23784    0.49018    0.47278    0.29428\n",
            " -0.42305    0.39041   -0.051611  -0.30997    0.12854   -0.67797\n",
            " -0.23172    0.13328    0.43269   -0.28219    0.56389   -0.52302\n",
            "  0.52544    0.20713   -0.4926     0.2071    -0.012374   0.62647\n",
            "  0.38548    0.5472     1.5739     0.38571   -0.095062  -0.70715\n",
            " -0.37873   -0.065873   0.34776    0.80396   -0.34771    0.43994\n",
            " -0.23445   -0.36284   -0.11516   -0.68272   -0.027322   0.24447\n",
            " -0.088484   0.34491   -0.55879    0.343    ]\n",
            "fox:  [ 0.64344    0.0086088  0.50145   -0.70381   -0.36289   -0.51602\n",
            "  0.3751    -0.0078184  0.10752   -0.29124    0.61808   -0.036332\n",
            " -2.4467    -0.0050135  0.18236   -0.18152   -0.19349   -0.19442\n",
            "  0.3793     0.46691    0.03579   -0.48468   -0.45103   -0.045509\n",
            "  0.6732    -1.4904    -0.23975   -0.26736   -0.058426   0.11573\n",
            "  0.79477    0.09746   -0.36717   -0.20758    0.099006  -0.51114\n",
            " -0.023912   0.14275   -0.87894    0.13728   -0.26524   -0.33326\n",
            "  0.25857   -0.27703    0.5022     0.7164    -0.26708    0.018559\n",
            "  0.39153   -0.42015   -0.55746   -0.2797    -0.36874    0.090716\n",
            " -0.29017    0.25543   -0.016203   0.014775  -0.45174   -0.48211\n",
            " -0.18746    0.59934   -0.20146   -0.3756    -0.11143    0.26213\n",
            "  0.15496    0.53471    0.43618   -0.7356     0.34366   -0.036715\n",
            " -0.2377    -0.3525    -0.5546     0.44059   -0.17759    0.50194\n",
            " -0.59675   -0.0427     1.5432     0.22326    0.40868    0.70572\n",
            " -0.17751    0.071547   0.84483    0.3794    -0.67034   -0.54685\n",
            " -0.55382   -0.88651   -0.25728   -0.1996    -0.15984    0.37977\n",
            "  0.62406    0.037116  -0.427      0.029686 ]\n",
            "jumps:  [-0.28348    0.1648     1.4019    -0.85675    0.027551   0.5412\n",
            "  0.88782    0.046905  -0.45316   -0.60368    0.55262    1.205\n",
            " -2.0585     0.51703   -0.32351   -0.30435    0.45369    0.31998\n",
            " -0.96374   -0.60021    0.47335   -0.74688    0.47179   -0.2158\n",
            " -0.09306    0.83334   -0.74749   -0.089607  -0.17782    1.2692\n",
            "  0.6947     0.043769   0.52786   -0.010808  -0.16553   -0.074203\n",
            " -0.49438    0.39217    0.16966   -0.73894    0.57277    0.55778\n",
            " -0.30532   -0.24023    0.96471    0.19401    0.40399    0.1934\n",
            "  0.084298   0.66986   -0.19846    0.29749    0.3546    -0.23385\n",
            " -0.14053    0.29882    0.69889    0.19321    0.95773   -0.18805\n",
            " -0.22225   -0.23144    0.38776    0.0037293  0.24487   -0.33569\n",
            " -0.17885    0.73331    0.26516   -0.098724   0.31112   -0.33525\n",
            " -0.63795   -0.97048   -0.63374    0.25719    0.23121   -1.4143\n",
            "  1.011     -0.014403   0.8709     0.57321    0.40159    0.302\n",
            " -0.43126   -0.16309    0.81327    0.45568   -0.14238   -0.69614\n",
            " -0.21193   -0.13398   -0.20042    0.14101    0.47543   -0.36219\n",
            "  0.71711   -0.47106    0.35576    0.46552  ]\n",
            "over:  [-1.3037e-01  2.0490e-01  4.2575e-01 -3.1239e-01 -5.4739e-01  2.1011e-01\n",
            " -7.2276e-03 -6.3219e-02 -1.2984e-02 -8.2143e-02  2.5385e-01  3.2791e-01\n",
            " -4.9173e+00  3.1567e-01 -2.0232e-01 -2.5671e-01 -1.8498e-03  4.3715e-01\n",
            " -1.0066e+00  2.5198e-02 -3.9015e-02 -3.4754e-01 -2.8745e-02  6.5716e-01\n",
            "  1.0906e+00  2.3102e-01  5.5719e-01 -4.6840e-01 -5.8515e-01 -2.9006e-01\n",
            " -2.6508e-01  3.9253e-01 -5.1165e-01  2.4492e-02  8.1263e-01 -4.2014e-01\n",
            " -3.4857e-01  3.5984e-01  1.5941e-01 -6.9736e-01 -1.4426e+00 -9.9337e-03\n",
            " -2.3335e-01 -4.6266e-01  2.6243e-01 -2.9373e-01  4.8860e-01  7.2830e-01\n",
            " -3.2475e-02  6.2540e-01 -4.3399e-01 -1.0553e-01  3.1752e-01 -1.5631e-01\n",
            " -2.4268e-01 -3.9298e-01 -3.7478e-01 -6.6699e-02  1.5477e-01  7.4870e-01\n",
            " -2.3318e-01  9.7446e-02 -4.4590e-01 -6.1845e-02  1.7504e-01  7.3357e-01\n",
            "  8.8520e-01 -1.9843e-01  2.5146e-01 -3.8909e-01 -3.0322e-01  4.3190e-01\n",
            "  5.9478e-02 -2.7233e-01 -3.8758e-01  5.1850e-01 -1.6175e-01 -7.5551e-01\n",
            "  5.5890e-01  1.0797e-01  1.4943e+00  1.6329e-01  6.6365e-01  1.2885e-01\n",
            " -9.8670e-02 -4.8738e-02  1.3253e-01 -1.6620e-01 -4.2653e-01 -1.7694e-01\n",
            " -2.6400e-01  1.0666e-01 -1.9857e-02  1.2652e-01  1.5045e-01 -7.6070e-02\n",
            " -3.4198e-01 -1.4165e-01  4.8806e-01  5.2860e-01]\n",
            "the:  [ 9.5152e-02  3.7024e-01  5.4291e-01  1.9621e-01  4.8205e-02  3.2033e-01\n",
            " -5.9638e-01  1.5868e-02 -1.2989e-01 -6.3028e-01  8.1944e-02  2.4164e-01\n",
            " -6.0990e+00 -6.8557e-01  5.0354e-01 -3.4089e-02  1.1705e-01 -7.7403e-03\n",
            " -8.6512e-02  4.3617e-01 -4.3982e-01  2.6125e-01 -4.0348e-02 -1.9194e-01\n",
            "  8.3204e-02 -5.8246e-01 -3.1923e-02  1.2630e-01  4.0120e-01  6.8906e-02\n",
            " -1.0517e-01 -2.0804e-01 -4.2554e-01  4.7799e-01  3.4651e-01  2.4057e-01\n",
            "  5.0244e-02 -7.2587e-02 -2.4347e-03 -5.0342e-01 -1.0601e+00 -3.1586e-01\n",
            " -3.2457e-02 -7.6317e-02  7.9045e-01  8.6367e-02 -1.9632e-01  5.7566e-02\n",
            "  8.4129e-01 -4.2020e-01 -1.1335e-03 -8.5632e-02  6.1910e-02  2.1423e-01\n",
            " -1.0356e-01 -3.6946e-02 -2.6005e-01 -3.5657e-01  5.4321e-02  3.0875e-02\n",
            "  1.4092e-01 -9.1998e-02 -4.1841e-01 -3.1135e-01 -1.4937e-01 -2.2699e-04\n",
            " -3.3454e-01 -1.4848e-01 -1.1944e-01 -2.7174e-01  3.1320e-01 -1.0998e-01\n",
            " -4.7524e-01  1.4056e-01  3.9641e-01 -4.9413e-02 -4.2601e-01 -2.3576e-01\n",
            "  6.1482e-02 -3.5313e-02  2.4161e+00  2.8979e-01  3.8882e-01  3.6779e-01\n",
            "  2.0685e-01  1.3992e-01 -4.2459e-01  4.4590e-01  2.6234e-01 -4.4834e-01\n",
            "  3.7196e-03 -2.2521e-01  1.4764e-01 -3.6417e-01 -1.8493e-01  2.2282e-01\n",
            "  4.7626e-01 -5.1083e-01  4.6877e-01  3.4882e-01]\n",
            "lazy:  [ 1.4021e-01 -6.1686e-01  6.6047e-01  4.5844e-01 -4.7073e-02  5.6833e-01\n",
            "  4.7711e-01 -3.0135e-01  2.5490e-01  2.7677e-01 -7.2243e-01 -4.7596e-01\n",
            " -3.1877e+00 -3.0520e-01 -1.1225e+00  1.1409e-01 -1.6397e-01 -6.2531e-01\n",
            " -6.4549e-01 -7.0767e-01 -1.3721e-01  1.6656e-01 -1.5643e-01 -5.8997e-01\n",
            "  5.3493e-01  4.2989e-01 -1.6078e-01  3.1838e-01 -1.7478e-01 -6.6117e-02\n",
            " -9.1278e-02 -2.2732e-01 -6.2848e-01  3.7686e-01 -6.0958e-01  3.7723e-02\n",
            "  1.3443e-01  5.8768e-01  1.0611e-01  1.0578e+00 -7.9843e-01  1.5644e-02\n",
            "  5.1333e-01 -2.6829e-01  8.6280e-02 -4.8820e-01 -7.8925e-02  5.7910e-01\n",
            " -8.3873e-01  7.4992e-01 -4.7451e-01  5.3792e-01  2.5934e-01 -2.5577e-01\n",
            " -7.2746e-01  7.2324e-01 -3.5029e-01  2.3883e-01  2.2178e-01  2.3307e-01\n",
            " -2.4567e-01  2.3833e-01  6.6281e-01 -1.1956e-01 -2.3183e-02 -7.2004e-01\n",
            " -4.5729e-02  6.8426e-01  3.5203e-01  5.6147e-01 -6.6437e-01  4.0224e-01\n",
            " -3.9397e-01 -1.1179e-01  1.5747e-01 -1.4167e-03  1.0760e+00  6.7952e-01\n",
            " -3.5587e-01 -7.7132e-02  2.0712e+00  4.2989e-01 -3.2253e-01  1.9375e-02\n",
            "  6.2629e-01  3.2018e-01  3.3936e-01 -9.2320e-02  2.8323e-01  1.4915e-01\n",
            "  2.3714e-01  4.1720e-01 -1.6513e-01  1.8810e-01  7.0461e-01  2.5950e-01\n",
            " -1.0690e-01  9.0640e-01  2.2023e-01 -1.9887e-01]\n",
            "dog:  [ 5.0779e-01 -1.0274e+00  4.8136e-01 -9.4170e-02  4.4837e-01 -5.2291e-01\n",
            "  5.1498e-01 -3.8927e-02  3.5867e-01 -6.5994e-02 -8.2882e-01  7.6179e-01\n",
            " -3.8030e+00 -1.0576e-02  2.1654e-01  5.9712e-01  3.7424e-01 -2.2629e-02\n",
            " -1.0331e-02 -3.3966e-01  9.4336e-02  2.6253e-01 -4.0161e-01 -7.9532e-03\n",
            "  1.0206e+00 -3.5793e-01 -5.6500e-01  5.8815e-01 -8.1847e-01  3.0293e-01\n",
            "  4.7199e-01 -9.7429e-02 -6.1226e-01 -1.7797e-01 -1.1616e-01  3.2586e-01\n",
            "  1.1498e-01 -1.9030e-01  1.1591e-02  4.6478e-01 -1.6805e-01  2.1972e-01\n",
            " -2.5938e-01 -1.3541e-02  7.0714e-01  7.8106e-01  7.9917e-01  1.0389e+00\n",
            "  5.2792e-01 -1.1160e-01 -6.2275e-01  3.0692e-02  3.3847e-01 -5.3092e-01\n",
            " -9.9688e-02  2.1596e-01  6.0522e-01  1.2356e+00 -3.4528e-03 -9.7514e-02\n",
            " -2.4938e-01  2.1539e-01  4.4643e-01  9.5375e-02 -2.7366e-01 -2.8537e-01\n",
            " -4.0894e-01  4.8223e-01  3.0318e-01  1.9440e-01  8.3242e-01 -5.0378e-01\n",
            "  3.0090e-01 -4.9792e-01  5.0297e-01  3.2685e-02 -5.1790e-01 -2.3541e-01\n",
            "  2.2960e-01 -6.3588e-01  1.6270e+00  6.2832e-01 -7.4846e-01  6.0073e-01\n",
            " -1.1215e-02 -3.2113e-01  1.4339e-01 -6.0809e-02  8.8218e-02  6.5936e-01\n",
            " -4.6127e-01 -3.7644e-01 -1.1330e-01  1.5875e-01  3.9119e-01  6.7659e-01\n",
            " -7.1224e-02  1.7458e-01 -3.3406e-02  7.3152e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__j7PmCbdlpR"
      },
      "source": [
        "def listdir_no_hidden(path):\n",
        "    start_list = os.listdir(path)\n",
        "    end_list = []\n",
        "    for file in start_list:\n",
        "        if (not file.startswith('.')):\n",
        "            end_list.append(file)\n",
        "    return(end_list)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z2jj6R9DkVk"
      },
      "source": [
        "# define list of codes to be dropped from document\n",
        "# carriage-returns, line-feeds, tabs\n",
        "codelist = ['\\r', '\\n', '\\t']   \n",
        "\n",
        "# We will not remove stopwords in this exercise because they are\n",
        "# important to keeping sentences intact\n",
        "if REMOVE_STOPWORDS:\n",
        "    print(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# previous analysis of a list of top terms showed a number of words, along \n",
        "# with contractions and other word strings to drop from further analysis, add\n",
        "# these to the usual English stopwords to be dropped from a document collection\n",
        "    more_stop_words = ['cant','didnt','doesnt','dont','goes','isnt','hes',\\\n",
        "        'shes','thats','theres','theyre','wont','youll','youre','youve', 'br'\\\n",
        "        've', 're', 'vs'] \n",
        "\n",
        "    some_proper_nouns_to_remove = ['dick','ginger','hollywood','jack',\\\n",
        "        'jill','john','karloff','kudrow','orson','peter','tcm','tom',\\\n",
        "        'toni','welles','william','wolheim','nikita']\n",
        "\n",
        "    # start with the initial list and add to it for movie text work \n",
        "    stoplist = nltk.corpus.stopwords.words('english') + more_stop_words +\\\n",
        "        some_proper_nouns_to_remove"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz6Vx4qODkVl"
      },
      "source": [
        "# text parsing function for creating text documents \n",
        "# there is more we could do for data preparation \n",
        "# stemming... looking for contractions... possessives... \n",
        "# but we will work with what we have in this parsing function\n",
        "# if we want to do stemming at a later time, we can use\n",
        "#     porter = nltk.PorterStemmer()  \n",
        "# in a construction like this\n",
        "#     words_stemmed =  [porter.stem(word) for word in initial_words]  \n",
        "def text_parse(string):\n",
        "    # replace non-alphanumeric with space \n",
        "    temp_string = re.sub('[^a-zA-Z]', '  ', string)    \n",
        "    # replace codes with space\n",
        "    for i in range(len(codelist)):\n",
        "        stopstring = ' ' + codelist[i] + '  '\n",
        "        temp_string = re.sub(stopstring, '  ', temp_string)      \n",
        "    # replace single-character words with space\n",
        "    temp_string = re.sub('\\s.\\s', ' ', temp_string)   \n",
        "    # convert uppercase to lowercase\n",
        "    temp_string = temp_string.lower()    \n",
        "    if REMOVE_STOPWORDS:\n",
        "        # replace selected character strings/stop-words with space\n",
        "        for i in range(len(stoplist)):\n",
        "            stopstring = ' ' + str(stoplist[i]) + ' '\n",
        "            temp_string = re.sub(stopstring, ' ', temp_string)        \n",
        "    # replace multiple blank characters with one blank character\n",
        "    temp_string = re.sub('\\s+', ' ', temp_string)    \n",
        "    return(temp_string)\n",
        "\n",
        "def read_data(filename):\n",
        "\n",
        "  with open(filename) as f:\n",
        "    data = tf.compat.as_str(f.read())\n",
        "    data = data.lower()\n",
        "    data = text_parse(data)\n",
        "    data = TreebankWordTokenizer().tokenize(data)  # The Penn Treebank\n",
        "\n",
        "  return data"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPTSvA4PDkVl",
        "outputId": "e4783f8f-a1d2-411c-ae74-d92cee3d8f32"
      },
      "source": [
        "# -----------------------------------------------\n",
        "# gather data for 500 negative movie reviews\n",
        "# -----------------------------------------------\n",
        "\n",
        "dir_name = \"/content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-negative\"\n",
        "#dir_name = '/root/movie-reviews-negative'\n",
        "    \n",
        "filenames = listdir_no_hidden(path=dir_name)\n",
        "num_files = len(filenames)\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    file_exists = os.path.isfile(os.path.join(dir_name, filenames[i]))\n",
        "    assert file_exists\n",
        "print('\\nDirectory:',dir_name)    \n",
        "print('%d files found' % len(filenames))\n",
        "\n",
        "# Read data for negative movie reviews\n",
        "# Data will be stored in a list of lists where the each list represents \n",
        "# a document and document is a list of words.\n",
        "# We then break the text into words.\n",
        "\n",
        "negative_documents = []\n",
        "\n",
        "print('\\nProcessing document files under', dir_name)\n",
        "for i in range(num_files):\n",
        "    ## print(' ', filenames[i])\n",
        "\n",
        "    words = read_data(os.path.join(dir_name, filenames[i]))\n",
        "\n",
        "    negative_documents.append(words)\n",
        "    #print('Data size (Characters) (Document %d) %d' %(i,len(words)))\n",
        "    #print('Sample string (Document %d) %s'%(i,words[:50]))"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Directory: /content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-negative\n",
            "500 files found\n",
            "\n",
            "Processing document files under /content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGGuXYwaDkVm",
        "outputId": "27b0c500-7c5b-45eb-afbf-726374555eac"
      },
      "source": [
        "# -----------------------------------------------\n",
        "# gather data for 500 positive movie reviews\n",
        "# -----------------------------------------------\n",
        "#dir_name = '/root/movie-reviews-positive'\n",
        "dir_name = \"/content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-positive\"\n",
        "filenames = listdir_no_hidden(path=dir_name)\n",
        "num_files = len(filenames)\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "    file_exists = os.path.isfile(os.path.join(dir_name, filenames[i]))\n",
        "    assert file_exists\n",
        "print('\\nDirectory:',dir_name)    \n",
        "print('%d files found' % len(filenames))\n",
        "\n",
        "# Read data for positive movie reviews\n",
        "# Data will be stored in a list of lists where the each list \n",
        "# represents a document and document is a list of words.\n",
        "# We then break the text into words.\n",
        "\n",
        "positive_documents = []\n",
        "\n",
        "print('\\nProcessing document files under', dir_name)\n",
        "for i in range(num_files):\n",
        "    ## print(' ', filenames[i])\n",
        "\n",
        "    words = read_data(os.path.join(dir_name, filenames[i]))\n",
        "\n",
        "    positive_documents.append(words)\n",
        "    # print('Data size (Characters) (Document %d) %d' %(i,len(words)))\n",
        "    # print('Sample string (Document %d) %s'%(i,words[:50]))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Directory: /content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-positive\n",
            "500 files found\n",
            "\n",
            "Processing document files under /content/drive/My Drive/Colab Notebooks/8_NWU_MSDS422_RNN/assignment8_files/movie-reviews-positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgN15f9UDkVq",
        "outputId": "04e58c6c-4be9-44ab-fce2-8e16d1d4534d"
      },
      "source": [
        "# -----------------------------------------------------\n",
        "# convert positive/negative documents into numpy array\n",
        "# note that reviews vary from 22 to 1052 words   \n",
        "# so we use the first 20 and last 20 words of each review \n",
        "# as our word sequences for analysis\n",
        "# -----------------------------------------------------\n",
        "max_review_length = 0  # initialize\n",
        "for doc in negative_documents:\n",
        "    max_review_length = max(max_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    max_review_length = max(max_review_length, len(doc)) \n",
        "print('max_review_length:', max_review_length) \n",
        "\n",
        "min_review_length = max_review_length  # initialize\n",
        "for doc in negative_documents:\n",
        "    min_review_length = min(min_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    min_review_length = min(min_review_length, len(doc)) \n",
        "print('min_review_length:', min_review_length) \n",
        "\n",
        "# construct list of 1000 lists with 20 words in each list\n",
        "from itertools import chain\n",
        "documents = []\n",
        "for doc in negative_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))    \n",
        "for doc in positive_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))    \n",
        "\n",
        "# create list of lists of lists for embeddings\n",
        "embeddings = []    \n",
        "for doc in documents:\n",
        "    embedding = []\n",
        "    for word in doc:\n",
        "       embedding.append(limited_index_to_embedding[limited_word_to_index[word]]) \n",
        "    embeddings.append(embedding)\n",
        "    \n",
        "#embeddings"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_review_length: 1052\n",
            "min_review_length: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD4U6wLIDkVq",
        "outputId": "f3efcf5f-c6ca-43a3-ebfe-82a9928f040e"
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Check on the embeddings list of list of lists \n",
        "# -----------------------------------------------------\n",
        "# Show the first word in the first document\n",
        "test_word = documents[0][0]    \n",
        "print('First word in first document:', test_word)    \n",
        "print('Embedding for this word:\\n', \n",
        "      limited_index_to_embedding[limited_word_to_index[test_word]])\n",
        "print('Corresponding embedding from embeddings list of list of lists\\n',\n",
        "      embeddings[0][0][:])\n",
        "\n",
        "# Show the last word in the last document\n",
        "test_word = documents[999][39]    \n",
        "print('First word in first document:', test_word)    \n",
        "print('Embedding for this word:\\n', \n",
        "      limited_index_to_embedding[limited_word_to_index[test_word]])\n",
        "print('Corresponding embedding from embeddings list of list of lists\\n',\n",
        "      embeddings[999][39][:])        "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First word in first document: it\n",
            "Embedding for this word:\n",
            " [-4.0204e-02  2.4451e-01  2.7863e-01  3.5576e-01 -6.4794e-02  6.7642e-01\n",
            "  1.9181e-01 -5.0071e-01  2.7229e-01  6.1884e-01  7.8804e-02  3.6170e-01\n",
            " -6.1461e+00 -1.3399e-01  2.5247e-01 -3.9622e-01 -6.2896e-02  6.5510e-02\n",
            " -2.6081e-01  1.2262e-01 -1.3021e-01  1.4528e-01 -1.4906e-02  2.0602e-01\n",
            "  3.8372e-01 -9.1961e-02 -1.6881e-01 -1.1129e-01  5.8092e-01 -1.7041e-01\n",
            " -5.1822e-01  4.4937e-01 -1.8692e-01  4.5443e-01 -1.8467e-01  2.4614e-02\n",
            " -8.3466e-02 -3.5212e-01  2.5468e-01 -9.8679e-02 -1.1378e+00 -2.4484e-01\n",
            "  6.7094e-03 -8.4167e-03  5.2478e-01  6.0223e-02 -1.9183e-01  6.0694e-02\n",
            " -1.4727e-01  1.8366e-01 -2.0860e-01  2.2762e-01 -1.1646e-01 -3.7232e-01\n",
            "  4.1695e-01 -2.7496e-03 -1.5487e-01 -2.0468e-01  6.6389e-02  3.5824e-01\n",
            "  1.3098e-01 -1.2687e-01 -1.2217e-02  3.0690e-01  2.8404e-01 -3.3045e-01\n",
            " -5.0693e-01  1.0172e-01 -4.3456e-01 -8.0154e-02  1.3064e-01  3.8311e-01\n",
            "  1.6287e-01 -3.9300e-01  2.2813e-01  3.5973e-02 -1.1221e-02  1.8664e-02\n",
            " -2.6987e-01  2.4169e-01  1.8840e+00  2.9005e-01 -6.9063e-02  1.4856e-02\n",
            " -1.7166e-01  6.9372e-02 -2.9757e-01 -2.2862e-01 -5.3910e-01 -1.0478e-01\n",
            " -3.6788e-01  2.2378e-02  2.7892e-01 -2.7278e-01 -4.1335e-01 -3.9130e-01\n",
            "  2.4167e-01 -3.7329e-01  8.2182e-02 -3.7373e-01]\n",
            "Corresponding embedding from embeddings list of list of lists\n",
            " [-4.0204e-02  2.4451e-01  2.7863e-01  3.5576e-01 -6.4794e-02  6.7642e-01\n",
            "  1.9181e-01 -5.0071e-01  2.7229e-01  6.1884e-01  7.8804e-02  3.6170e-01\n",
            " -6.1461e+00 -1.3399e-01  2.5247e-01 -3.9622e-01 -6.2896e-02  6.5510e-02\n",
            " -2.6081e-01  1.2262e-01 -1.3021e-01  1.4528e-01 -1.4906e-02  2.0602e-01\n",
            "  3.8372e-01 -9.1961e-02 -1.6881e-01 -1.1129e-01  5.8092e-01 -1.7041e-01\n",
            " -5.1822e-01  4.4937e-01 -1.8692e-01  4.5443e-01 -1.8467e-01  2.4614e-02\n",
            " -8.3466e-02 -3.5212e-01  2.5468e-01 -9.8679e-02 -1.1378e+00 -2.4484e-01\n",
            "  6.7094e-03 -8.4167e-03  5.2478e-01  6.0223e-02 -1.9183e-01  6.0694e-02\n",
            " -1.4727e-01  1.8366e-01 -2.0860e-01  2.2762e-01 -1.1646e-01 -3.7232e-01\n",
            "  4.1695e-01 -2.7496e-03 -1.5487e-01 -2.0468e-01  6.6389e-02  3.5824e-01\n",
            "  1.3098e-01 -1.2687e-01 -1.2217e-02  3.0690e-01  2.8404e-01 -3.3045e-01\n",
            " -5.0693e-01  1.0172e-01 -4.3456e-01 -8.0154e-02  1.3064e-01  3.8311e-01\n",
            "  1.6287e-01 -3.9300e-01  2.2813e-01  3.5973e-02 -1.1221e-02  1.8664e-02\n",
            " -2.6987e-01  2.4169e-01  1.8840e+00  2.9005e-01 -6.9063e-02  1.4856e-02\n",
            " -1.7166e-01  6.9372e-02 -2.9757e-01 -2.2862e-01 -5.3910e-01 -1.0478e-01\n",
            " -3.6788e-01  2.2378e-02  2.7892e-01 -2.7278e-01 -4.1335e-01 -3.9130e-01\n",
            "  2.4167e-01 -3.7329e-01  8.2182e-02 -3.7373e-01]\n",
            "First word in first document: it\n",
            "Embedding for this word:\n",
            " [-4.0204e-02  2.4451e-01  2.7863e-01  3.5576e-01 -6.4794e-02  6.7642e-01\n",
            "  1.9181e-01 -5.0071e-01  2.7229e-01  6.1884e-01  7.8804e-02  3.6170e-01\n",
            " -6.1461e+00 -1.3399e-01  2.5247e-01 -3.9622e-01 -6.2896e-02  6.5510e-02\n",
            " -2.6081e-01  1.2262e-01 -1.3021e-01  1.4528e-01 -1.4906e-02  2.0602e-01\n",
            "  3.8372e-01 -9.1961e-02 -1.6881e-01 -1.1129e-01  5.8092e-01 -1.7041e-01\n",
            " -5.1822e-01  4.4937e-01 -1.8692e-01  4.5443e-01 -1.8467e-01  2.4614e-02\n",
            " -8.3466e-02 -3.5212e-01  2.5468e-01 -9.8679e-02 -1.1378e+00 -2.4484e-01\n",
            "  6.7094e-03 -8.4167e-03  5.2478e-01  6.0223e-02 -1.9183e-01  6.0694e-02\n",
            " -1.4727e-01  1.8366e-01 -2.0860e-01  2.2762e-01 -1.1646e-01 -3.7232e-01\n",
            "  4.1695e-01 -2.7496e-03 -1.5487e-01 -2.0468e-01  6.6389e-02  3.5824e-01\n",
            "  1.3098e-01 -1.2687e-01 -1.2217e-02  3.0690e-01  2.8404e-01 -3.3045e-01\n",
            " -5.0693e-01  1.0172e-01 -4.3456e-01 -8.0154e-02  1.3064e-01  3.8311e-01\n",
            "  1.6287e-01 -3.9300e-01  2.2813e-01  3.5973e-02 -1.1221e-02  1.8664e-02\n",
            " -2.6987e-01  2.4169e-01  1.8840e+00  2.9005e-01 -6.9063e-02  1.4856e-02\n",
            " -1.7166e-01  6.9372e-02 -2.9757e-01 -2.2862e-01 -5.3910e-01 -1.0478e-01\n",
            " -3.6788e-01  2.2378e-02  2.7892e-01 -2.7278e-01 -4.1335e-01 -3.9130e-01\n",
            "  2.4167e-01 -3.7329e-01  8.2182e-02 -3.7373e-01]\n",
            "Corresponding embedding from embeddings list of list of lists\n",
            " [-4.0204e-02  2.4451e-01  2.7863e-01  3.5576e-01 -6.4794e-02  6.7642e-01\n",
            "  1.9181e-01 -5.0071e-01  2.7229e-01  6.1884e-01  7.8804e-02  3.6170e-01\n",
            " -6.1461e+00 -1.3399e-01  2.5247e-01 -3.9622e-01 -6.2896e-02  6.5510e-02\n",
            " -2.6081e-01  1.2262e-01 -1.3021e-01  1.4528e-01 -1.4906e-02  2.0602e-01\n",
            "  3.8372e-01 -9.1961e-02 -1.6881e-01 -1.1129e-01  5.8092e-01 -1.7041e-01\n",
            " -5.1822e-01  4.4937e-01 -1.8692e-01  4.5443e-01 -1.8467e-01  2.4614e-02\n",
            " -8.3466e-02 -3.5212e-01  2.5468e-01 -9.8679e-02 -1.1378e+00 -2.4484e-01\n",
            "  6.7094e-03 -8.4167e-03  5.2478e-01  6.0223e-02 -1.9183e-01  6.0694e-02\n",
            " -1.4727e-01  1.8366e-01 -2.0860e-01  2.2762e-01 -1.1646e-01 -3.7232e-01\n",
            "  4.1695e-01 -2.7496e-03 -1.5487e-01 -2.0468e-01  6.6389e-02  3.5824e-01\n",
            "  1.3098e-01 -1.2687e-01 -1.2217e-02  3.0690e-01  2.8404e-01 -3.3045e-01\n",
            " -5.0693e-01  1.0172e-01 -4.3456e-01 -8.0154e-02  1.3064e-01  3.8311e-01\n",
            "  1.6287e-01 -3.9300e-01  2.2813e-01  3.5973e-02 -1.1221e-02  1.8664e-02\n",
            " -2.6987e-01  2.4169e-01  1.8840e+00  2.9005e-01 -6.9063e-02  1.4856e-02\n",
            " -1.7166e-01  6.9372e-02 -2.9757e-01 -2.2862e-01 -5.3910e-01 -1.0478e-01\n",
            " -3.6788e-01  2.2378e-02  2.7892e-01 -2.7278e-01 -4.1335e-01 -3.9130e-01\n",
            "  2.4167e-01 -3.7329e-01  8.2182e-02 -3.7373e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYA1Wza4DkVq"
      },
      "source": [
        "RANDOM_SEED = 9999\n",
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dhs9ERqW0j_N"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VIMqU_-DkVt"
      },
      "source": [
        "Dictionary for result tracking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n3vLmJyDkVt"
      },
      "source": [
        "# Initialize a dictionary to track results\n",
        "metrics = {}\n",
        "\n",
        "\n",
        "# Metrics for evaluation\n",
        "names = ['Epoch Count','Time (s)','Training Accuracy', 'Test Accuracy']\n"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEnleEq0DkVu"
      },
      "source": [
        "Model Set 1: RNN variations using embedding: Glove.twitter.27B 100d/1.2M words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdlvi4SRdlpY"
      },
      "source": [
        "Model 1a: Jump start model - simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fItK2z8fdlpZ",
        "outputId": "a33237f7-a683-432c-a165-05069c1faee3"
      },
      "source": [
        "# --------------------------------------------------------------------------      \n",
        "# We use a very simple Recurrent Neural Network for this assignment\n",
        "# Géron, A. 2017. Hands-On Machine Learning with Scikit-Learn & TensorFlow: \n",
        "#    Concepts, Tools, and Techniques to Build Intelligent Systems. \n",
        "#    Sebastopol, Calif.: O'Reilly. [ISBN-13 978-1-491-96229-9] \n",
        "#    Chapter 14 Recurrent Neural Networks, pages 390-391\n",
        "#    Source code available at https://github.com/ageron/handson-ml \n",
        "# --------------------------------------------------------------------------  \n",
        "reset_graph()\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "# Set X and y placeholders\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
        "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
        "\n",
        "logits = tf.layers.dense(states, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                          logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        print('\\n  ---- Epoch ', epoch, ' ----\\n')\n",
        "        for iteration in range(y_train.shape[0] // batch_size):          \n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            print('  Batch ', iteration, ' training observations from ',  \n",
        "                  iteration*batch_size, ' to ', (iteration + 1)*batch_size-1,)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print('\\n  Train accuracy:', acc_train, 'Test accuracy:', acc_test)\n",
        "    \n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "\n",
        "metrics['Model 1a-simple RNN (100d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:421: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  ---- Epoch  0  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.54 Test accuracy: 0.53\n",
            "\n",
            "  ---- Epoch  1  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.57 Test accuracy: 0.565\n",
            "\n",
            "  ---- Epoch  2  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.59 Test accuracy: 0.555\n",
            "\n",
            "  ---- Epoch  3  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.58 Test accuracy: 0.545\n",
            "\n",
            "  ---- Epoch  4  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.61 Test accuracy: 0.535\n",
            "\n",
            "  ---- Epoch  5  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.63 Test accuracy: 0.56\n",
            "\n",
            "  ---- Epoch  6  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.68 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  7  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.67 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  8  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.71 Test accuracy: 0.58\n",
            "\n",
            "  ---- Epoch  9  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.73 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  10  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.72 Test accuracy: 0.57\n",
            "\n",
            "  ---- Epoch  11  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.72 Test accuracy: 0.555\n",
            "\n",
            "  ---- Epoch  12  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.73 Test accuracy: 0.56\n",
            "\n",
            "  ---- Epoch  13  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.71 Test accuracy: 0.58\n",
            "\n",
            "  ---- Epoch  14  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.71 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  15  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.72 Test accuracy: 0.59\n",
            "\n",
            "  ---- Epoch  16  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.72 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  17  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.74 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  18  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.73 Test accuracy: 0.59\n",
            "\n",
            "  ---- Epoch  19  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.585\n",
            "\n",
            "  ---- Epoch  20  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.74 Test accuracy: 0.61\n",
            "\n",
            "  ---- Epoch  21  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.61\n",
            "\n",
            "  ---- Epoch  22  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.615\n",
            "\n",
            "  ---- Epoch  23  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.59\n",
            "\n",
            "  ---- Epoch  24  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.77 Test accuracy: 0.605\n",
            "\n",
            "  ---- Epoch  25  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.79 Test accuracy: 0.62\n",
            "\n",
            "  ---- Epoch  26  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.79 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  27  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.82 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  28  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.68\n",
            "\n",
            "  ---- Epoch  29  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.84 Test accuracy: 0.675\n",
            "\n",
            "  ---- Epoch  30  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.84 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  31  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.86 Test accuracy: 0.675\n",
            "\n",
            "  ---- Epoch  32  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.86 Test accuracy: 0.675\n",
            "\n",
            "  ---- Epoch  33  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.86 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  34  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.86 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  35  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.87 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  36  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  37  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  38  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  39  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  40  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  41  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.725\n",
            "\n",
            "  ---- Epoch  42  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.72\n",
            "\n",
            "  ---- Epoch  43  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.72\n",
            "\n",
            "  ---- Epoch  44  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  45  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.91 Test accuracy: 0.72\n",
            "\n",
            "  ---- Epoch  46  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.72\n",
            "\n",
            "  ---- Epoch  47  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.87 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  48  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  49  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.92 Test accuracy: 0.73\n",
            "\n",
            "  ---- Epoch  50  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.91 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  51  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  52  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.91 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  53  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  54  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  55  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  56  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  57  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  58  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.715\n",
            "\n",
            "  ---- Epoch  59  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.685\n",
            "\n",
            "  ---- Epoch  60  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  61  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.84 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  62  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  63  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.92 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  64  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.93 Test accuracy: 0.725\n",
            "\n",
            "  ---- Epoch  65  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.93 Test accuracy: 0.67\n",
            "\n",
            "  ---- Epoch  66  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  67  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  68  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.685\n",
            "\n",
            "  ---- Epoch  69  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  70  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  71  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.93 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  72  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  73  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  74  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.71\n",
            "\n",
            "  ---- Epoch  75  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  76  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  77  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.685\n",
            "\n",
            "  ---- Epoch  78  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  79  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  80  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  81  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  82  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  83  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  84  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  85  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  86  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  87  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  88  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  89  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  90  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  91  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.69\n",
            "\n",
            "  ---- Epoch  92  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  93  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  94  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.695\n",
            "\n",
            "  ---- Epoch  95  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.7\n",
            "\n",
            "  ---- Epoch  96  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  97  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.68\n",
            "\n",
            "  ---- Epoch  98  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.705\n",
            "\n",
            "  ---- Epoch  99  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhpD8fHRdlpc"
      },
      "source": [
        "Model 1b: Long Short Term Memory Model (LSTM) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4k8dxq_iQW4",
        "scrolled": true,
        "outputId": "75be17d6-6c08-45b0-eaaa-bd7f12e4f8d9"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "n_layers = 3\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "lstm_cells = [tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
        "              for layer in range(n_layers)]\n",
        "multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
        "top_layer_h_state = states[-1][1]\n",
        "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(y_train.shape[0] // batch_size):          \n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            print('  Batch ', iteration, ' training observations from ',  \n",
        "                  iteration*batch_size, ' to ', (iteration + 1)*batch_size-1,)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(\"Epoch\", epoch, \"Train accuracy =\", acc_train, \"Test accuracy =\", acc_test)\n",
        "\n",
        "\n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "\n",
        "metrics['Model 1b-LSTM (100d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 0 Train accuracy = 0.5 Test accuracy = 0.49\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 1 Train accuracy = 0.5 Test accuracy = 0.495\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 2 Train accuracy = 0.52 Test accuracy = 0.505\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 3 Train accuracy = 0.51 Test accuracy = 0.525\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 4 Train accuracy = 0.55 Test accuracy = 0.555\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 5 Train accuracy = 0.62 Test accuracy = 0.585\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 6 Train accuracy = 0.62 Test accuracy = 0.61\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 7 Train accuracy = 0.63 Test accuracy = 0.61\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 8 Train accuracy = 0.63 Test accuracy = 0.61\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 9 Train accuracy = 0.61 Test accuracy = 0.615\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 10 Train accuracy = 0.63 Test accuracy = 0.625\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 11 Train accuracy = 0.63 Test accuracy = 0.635\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 12 Train accuracy = 0.64 Test accuracy = 0.645\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 13 Train accuracy = 0.66 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 14 Train accuracy = 0.68 Test accuracy = 0.635\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 15 Train accuracy = 0.68 Test accuracy = 0.625\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 16 Train accuracy = 0.68 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 17 Train accuracy = 0.67 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 18 Train accuracy = 0.66 Test accuracy = 0.635\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 19 Train accuracy = 0.66 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 20 Train accuracy = 0.68 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 21 Train accuracy = 0.68 Test accuracy = 0.64\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 22 Train accuracy = 0.69 Test accuracy = 0.645\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 23 Train accuracy = 0.7 Test accuracy = 0.645\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 24 Train accuracy = 0.71 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 25 Train accuracy = 0.72 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 26 Train accuracy = 0.75 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 27 Train accuracy = 0.76 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 28 Train accuracy = 0.76 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 29 Train accuracy = 0.77 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 30 Train accuracy = 0.77 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 31 Train accuracy = 0.77 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 32 Train accuracy = 0.8 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 33 Train accuracy = 0.81 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 34 Train accuracy = 0.81 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 35 Train accuracy = 0.81 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 36 Train accuracy = 0.82 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 37 Train accuracy = 0.83 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 38 Train accuracy = 0.83 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 39 Train accuracy = 0.84 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 40 Train accuracy = 0.84 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 41 Train accuracy = 0.85 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 42 Train accuracy = 0.85 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 43 Train accuracy = 0.86 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 44 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 45 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 46 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 47 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 48 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 49 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 50 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 51 Train accuracy = 0.87 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 52 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 53 Train accuracy = 0.87 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 54 Train accuracy = 0.86 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 55 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 56 Train accuracy = 0.87 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 57 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 58 Train accuracy = 0.87 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 59 Train accuracy = 0.88 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 60 Train accuracy = 0.88 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 61 Train accuracy = 0.88 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 62 Train accuracy = 0.88 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 63 Train accuracy = 0.88 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 64 Train accuracy = 0.88 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 65 Train accuracy = 0.88 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 66 Train accuracy = 0.88 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 67 Train accuracy = 0.88 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 68 Train accuracy = 0.89 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 69 Train accuracy = 0.89 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 70 Train accuracy = 0.89 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 71 Train accuracy = 0.89 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 72 Train accuracy = 0.89 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 73 Train accuracy = 0.89 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 74 Train accuracy = 0.9 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 75 Train accuracy = 0.9 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 76 Train accuracy = 0.9 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 77 Train accuracy = 0.9 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 78 Train accuracy = 0.9 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 79 Train accuracy = 0.9 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 80 Train accuracy = 0.9 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 81 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 82 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 83 Train accuracy = 0.91 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 84 Train accuracy = 0.91 Test accuracy = 0.655\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 85 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 86 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 87 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 88 Train accuracy = 0.91 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 89 Train accuracy = 0.91 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 90 Train accuracy = 0.91 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 91 Train accuracy = 0.91 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 92 Train accuracy = 0.91 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 93 Train accuracy = 0.91 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 94 Train accuracy = 0.92 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 95 Train accuracy = 0.92 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 96 Train accuracy = 0.92 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 97 Train accuracy = 0.92 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 98 Train accuracy = 0.92 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 99 Train accuracy = 0.93 Test accuracy = 0.665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDJb1ZaBdlpe"
      },
      "source": [
        "Model 1c: Drop cell (twitter.100d)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDcxEFZjdlpf",
        "outputId": "54655e5a-e3f4-4636-be6f-0c557605a954"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "n_layers = 3\n",
        "\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "keep_prob = tf.placeholder_with_default(.95, shape=())\n",
        "cells = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
        "         for layer in range(n_layers)]\n",
        "cells_drop = [tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
        "              for cell in cells]\n",
        "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(cells_drop)\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
        "\n",
        "states_concat = tf.concat(axis=1, values=states)\n",
        "logits = tf.layers.dense(states_concat, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "        \n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(y_train.shape[0] // batch_size):\n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "\n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "\n",
        "metrics['Model 1c-Drop Cell (100d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:421: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.47 Test accuracy: 0.54\n",
            "1 Train accuracy: 0.5 Test accuracy: 0.54\n",
            "2 Train accuracy: 0.52 Test accuracy: 0.55\n",
            "3 Train accuracy: 0.48 Test accuracy: 0.56\n",
            "4 Train accuracy: 0.64 Test accuracy: 0.54\n",
            "5 Train accuracy: 0.6 Test accuracy: 0.555\n",
            "6 Train accuracy: 0.71 Test accuracy: 0.6\n",
            "7 Train accuracy: 0.7 Test accuracy: 0.61\n",
            "8 Train accuracy: 0.71 Test accuracy: 0.615\n",
            "9 Train accuracy: 0.75 Test accuracy: 0.64\n",
            "10 Train accuracy: 0.78 Test accuracy: 0.65\n",
            "11 Train accuracy: 0.76 Test accuracy: 0.665\n",
            "12 Train accuracy: 0.76 Test accuracy: 0.665\n",
            "13 Train accuracy: 0.73 Test accuracy: 0.64\n",
            "14 Train accuracy: 0.8 Test accuracy: 0.685\n",
            "15 Train accuracy: 0.81 Test accuracy: 0.65\n",
            "16 Train accuracy: 0.84 Test accuracy: 0.68\n",
            "17 Train accuracy: 0.77 Test accuracy: 0.665\n",
            "18 Train accuracy: 0.81 Test accuracy: 0.675\n",
            "19 Train accuracy: 0.82 Test accuracy: 0.65\n",
            "20 Train accuracy: 0.83 Test accuracy: 0.645\n",
            "21 Train accuracy: 0.85 Test accuracy: 0.66\n",
            "22 Train accuracy: 0.88 Test accuracy: 0.61\n",
            "23 Train accuracy: 0.82 Test accuracy: 0.68\n",
            "24 Train accuracy: 0.87 Test accuracy: 0.67\n",
            "25 Train accuracy: 0.85 Test accuracy: 0.695\n",
            "26 Train accuracy: 0.83 Test accuracy: 0.66\n",
            "27 Train accuracy: 0.8 Test accuracy: 0.69\n",
            "28 Train accuracy: 0.84 Test accuracy: 0.69\n",
            "29 Train accuracy: 0.87 Test accuracy: 0.68\n",
            "30 Train accuracy: 0.87 Test accuracy: 0.675\n",
            "31 Train accuracy: 0.83 Test accuracy: 0.7\n",
            "32 Train accuracy: 0.91 Test accuracy: 0.67\n",
            "33 Train accuracy: 0.91 Test accuracy: 0.675\n",
            "34 Train accuracy: 0.9 Test accuracy: 0.695\n",
            "35 Train accuracy: 0.89 Test accuracy: 0.685\n",
            "36 Train accuracy: 0.91 Test accuracy: 0.685\n",
            "37 Train accuracy: 0.92 Test accuracy: 0.65\n",
            "38 Train accuracy: 0.85 Test accuracy: 0.69\n",
            "39 Train accuracy: 0.86 Test accuracy: 0.7\n",
            "40 Train accuracy: 0.88 Test accuracy: 0.695\n",
            "41 Train accuracy: 0.9 Test accuracy: 0.685\n",
            "42 Train accuracy: 0.87 Test accuracy: 0.68\n",
            "43 Train accuracy: 0.9 Test accuracy: 0.675\n",
            "44 Train accuracy: 0.87 Test accuracy: 0.68\n",
            "45 Train accuracy: 0.92 Test accuracy: 0.66\n",
            "46 Train accuracy: 0.9 Test accuracy: 0.675\n",
            "47 Train accuracy: 0.94 Test accuracy: 0.66\n",
            "48 Train accuracy: 0.92 Test accuracy: 0.67\n",
            "49 Train accuracy: 0.92 Test accuracy: 0.705\n",
            "50 Train accuracy: 0.92 Test accuracy: 0.685\n",
            "51 Train accuracy: 0.94 Test accuracy: 0.65\n",
            "52 Train accuracy: 0.89 Test accuracy: 0.635\n",
            "53 Train accuracy: 0.94 Test accuracy: 0.66\n",
            "54 Train accuracy: 0.93 Test accuracy: 0.635\n",
            "55 Train accuracy: 0.92 Test accuracy: 0.635\n",
            "56 Train accuracy: 0.92 Test accuracy: 0.68\n",
            "57 Train accuracy: 0.93 Test accuracy: 0.665\n",
            "58 Train accuracy: 0.93 Test accuracy: 0.695\n",
            "59 Train accuracy: 0.95 Test accuracy: 0.64\n",
            "60 Train accuracy: 0.94 Test accuracy: 0.665\n",
            "61 Train accuracy: 0.95 Test accuracy: 0.67\n",
            "62 Train accuracy: 0.91 Test accuracy: 0.67\n",
            "63 Train accuracy: 0.94 Test accuracy: 0.66\n",
            "64 Train accuracy: 0.97 Test accuracy: 0.63\n",
            "65 Train accuracy: 0.95 Test accuracy: 0.66\n",
            "66 Train accuracy: 0.95 Test accuracy: 0.685\n",
            "67 Train accuracy: 0.97 Test accuracy: 0.68\n",
            "68 Train accuracy: 0.95 Test accuracy: 0.645\n",
            "69 Train accuracy: 0.95 Test accuracy: 0.67\n",
            "70 Train accuracy: 0.95 Test accuracy: 0.675\n",
            "71 Train accuracy: 0.97 Test accuracy: 0.675\n",
            "72 Train accuracy: 0.98 Test accuracy: 0.64\n",
            "73 Train accuracy: 0.94 Test accuracy: 0.67\n",
            "74 Train accuracy: 0.97 Test accuracy: 0.655\n",
            "75 Train accuracy: 0.94 Test accuracy: 0.645\n",
            "76 Train accuracy: 0.95 Test accuracy: 0.645\n",
            "77 Train accuracy: 0.99 Test accuracy: 0.655\n",
            "78 Train accuracy: 0.94 Test accuracy: 0.63\n",
            "79 Train accuracy: 0.98 Test accuracy: 0.645\n",
            "80 Train accuracy: 0.96 Test accuracy: 0.67\n",
            "81 Train accuracy: 0.96 Test accuracy: 0.625\n",
            "82 Train accuracy: 0.98 Test accuracy: 0.675\n",
            "83 Train accuracy: 0.96 Test accuracy: 0.66\n",
            "84 Train accuracy: 0.96 Test accuracy: 0.68\n",
            "85 Train accuracy: 0.98 Test accuracy: 0.655\n",
            "86 Train accuracy: 0.97 Test accuracy: 0.68\n",
            "87 Train accuracy: 0.96 Test accuracy: 0.655\n",
            "88 Train accuracy: 0.99 Test accuracy: 0.63\n",
            "89 Train accuracy: 0.98 Test accuracy: 0.66\n",
            "90 Train accuracy: 0.97 Test accuracy: 0.675\n",
            "91 Train accuracy: 0.96 Test accuracy: 0.66\n",
            "92 Train accuracy: 0.97 Test accuracy: 0.645\n",
            "93 Train accuracy: 0.96 Test accuracy: 0.69\n",
            "94 Train accuracy: 0.99 Test accuracy: 0.64\n",
            "95 Train accuracy: 1.0 Test accuracy: 0.635\n",
            "96 Train accuracy: 0.99 Test accuracy: 0.67\n",
            "97 Train accuracy: 0.97 Test accuracy: 0.675\n",
            "98 Train accuracy: 0.98 Test accuracy: 0.68\n",
            "99 Train accuracy: 0.97 Test accuracy: 0.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r_4rxxlDkVx"
      },
      "source": [
        "Model Set 2: RNN variation models using embedding: Glove.6B 300d/400k words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyg9gtOsDkVy"
      },
      "source": [
        "Embedding setup for RNN variation models using embedding: Glove.6B 300d/400k words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J6FGWQ2uDkVy",
        "outputId": "44d2947e-97f6-4492-81db-7101e0b1ea62"
      },
      "source": [
        "def reset_graph(seed= RANDOM_SEED):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "REMOVE_STOPWORDS = False  # no stopword removal \n",
        "EVOCABSIZE = 400000\n",
        "\n",
        "embeddings_directory = 'embeddings/glove.6B'\n",
        "filename = 'glove.6B.300d.txt'\n",
        "\n",
        "embeddings_filename = os.path.join(embeddings_directory, filename)\n",
        "embeddings_filename"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'embeddings/glove.6B/glove.6B.300d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4de5j14DkVz",
        "outputId": "5a488d65-6f8c-4e47-ffed-8c91640fdb50"
      },
      "source": [
        "def load_embedding_from_disks(embeddings_filename, with_indexes=True):\n",
        "    if with_indexes:\n",
        "        word_to_index_dict = dict()\n",
        "        index_to_embedding_array = []\n",
        "  \n",
        "    else:\n",
        "        word_to_embedding_dict = dict()\n",
        "\n",
        "    with open(embeddings_filename, 'r') as embeddings_file:\n",
        "        for (i, line) in enumerate(embeddings_file):\n",
        "\n",
        "            split = line.split(' ')\n",
        "\n",
        "            word = split[0]\n",
        "\n",
        "            representation = split[1:]\n",
        "            representation = np.array(\n",
        "                [float(val) for val in representation]\n",
        "            )\n",
        "\n",
        "            if with_indexes:\n",
        "                word_to_index_dict[word] = i\n",
        "                index_to_embedding_array.append(representation)\n",
        "            else:\n",
        "                word_to_embedding_dict[word] = representation\n",
        "\n",
        "    # Empty representation for unknown words.\n",
        "    _WORD_NOT_FOUND = [0.0] * len(representation)\n",
        "    if with_indexes:\n",
        "        _LAST_INDEX = i + 1\n",
        "        word_to_index_dict = defaultdict(\n",
        "            lambda: _LAST_INDEX, word_to_index_dict)\n",
        "        index_to_embedding_array = np.array(\n",
        "            index_to_embedding_array + [_WORD_NOT_FOUND])\n",
        "        return word_to_index_dict, index_to_embedding_array\n",
        "    else:\n",
        "        word_to_embedding_dict = defaultdict(lambda: _WORD_NOT_FOUND)\n",
        "        return word_to_embedding_dict\n",
        "\n",
        "print('\\nLoading embeddings from', embeddings_filename)\n",
        "word_to_index, index_to_embedding = \\\n",
        "    load_embedding_from_disks(embeddings_filename, with_indexes=True)\n",
        "print(\"Embedding loaded from disks.\")"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loading embeddings from embeddings/glove.6B/glove.6B.300d.txt\n",
            "Embedding loaded from disks.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHlPpGhQDkVz",
        "outputId": "a286aeea-05ac-48fc-f521-748a627959cf"
      },
      "source": [
        "vocab_size, embedding_dim = index_to_embedding.shape\n",
        "print(\"Embedding is of shape: {}\".format(index_to_embedding.shape))\n",
        "print(\"This means (number of words, number of dimensions per word)\\n\")\n",
        "print(\"The first words are words that tend occur more often.\")\n",
        "\n",
        "print(\"Note: for unknown words, the representation is an empty vector,\\n\"\n",
        "      \"and the index is the last one. The dictionnary has a limit:\")\n",
        "print(\"    {} --> {} --> {}\".format(\"A word\", \"Index in embedding\", \n",
        "      \"Representation\"))\n",
        "word = \"worsdfkljsdf\"  # a word obviously not in the vocabulary\n",
        "idx = word_to_index[word] # index for word obviously not in the vocabulary\n",
        "complete_vocabulary_size = idx \n",
        "embd = list(np.array(index_to_embedding[idx], dtype=int)) # \"int\" compact print\n",
        "#print(\"    {} --> {} --> {}\".format(word, idx, embd))\n",
        "word = \"the\"\n",
        "idx = word_to_index[word]\n",
        "embd = list(index_to_embedding[idx])  # \"int\" for compact print only.\n",
        "#print(\"    {} --> {} --> {}\".format(word, idx, embd))"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding is of shape: (400001, 300)\n",
            "This means (number of words, number of dimensions per word)\n",
            "\n",
            "The first words are words that tend occur more often.\n",
            "Note: for unknown words, the representation is an empty vector,\n",
            "and the index is the last one. The dictionnary has a limit:\n",
            "    A word --> Index in embedding --> Representation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmQIbUZ6DkV0",
        "outputId": "6c4b3815-e05e-4d7d-f8d1-553b77b55904"
      },
      "source": [
        "def default_factory():\n",
        "    return EVOCABSIZE  # last/unknown-word row in limited_index_to_embedding\n",
        "# dictionary has the items() function, returns list of (key, value) tuples\n",
        "limited_word_to_index = defaultdict(default_factory, \\\n",
        "    {k: v for k, v in word_to_index.items() if v < EVOCABSIZE})\n",
        "\n",
        "# Select the first EVOCABSIZE rows to the index_to_embedding\n",
        "limited_index_to_embedding = index_to_embedding[0:EVOCABSIZE,:]\n",
        "# Set the unknown-word row to be all zeros as previously\n",
        "limited_index_to_embedding = np.append(limited_index_to_embedding, \n",
        "    index_to_embedding[index_to_embedding.shape[0] - 1, :].\\\n",
        "        reshape(1,embedding_dim), \n",
        "    axis = 0)\n",
        "\n",
        "# Delete large numpy array to clear some CPU RAM\n",
        "del index_to_embedding\n",
        "\n",
        "# Verify the new vocabulary: should get same embeddings for test sentence\n",
        "# Note that a small EVOCABSIZE may yield some zero vectors for embeddings\n",
        "print('\\nTest sentence embeddings from vocabulary of', EVOCABSIZE, 'words:\\n')\n",
        "for word in words_in_test_sentence:\n",
        "    word_ = word.lower()\n",
        "    embedding = limited_index_to_embedding[limited_word_to_index[word_]]\n",
        "    print(word_ + \": \", embedding)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Test sentence embeddings from vocabulary of 400000 words:\n",
            "\n",
            "the:  [ 4.6560e-02  2.1318e-01 -7.4364e-03 -4.5854e-01 -3.5639e-02  2.3643e-01\n",
            " -2.8836e-01  2.1521e-01 -1.3486e-01 -1.6413e+00 -2.6091e-01  3.2434e-02\n",
            "  5.6621e-02 -4.3296e-02 -2.1672e-02  2.2476e-01 -7.5129e-02 -6.7018e-02\n",
            " -1.4247e-01  3.8825e-02 -1.8951e-01  2.9977e-01  3.9305e-01  1.7887e-01\n",
            " -1.7343e-01 -2.1178e-01  2.3617e-01 -6.3681e-02 -4.2318e-01 -1.1661e-01\n",
            "  9.3754e-02  1.7296e-01 -3.3073e-01  4.9112e-01 -6.8995e-01 -9.2462e-02\n",
            "  2.4742e-01 -1.7991e-01  9.7908e-02  8.3118e-02  1.5299e-01 -2.7276e-01\n",
            " -3.8934e-02  5.4453e-01  5.3737e-01  2.9105e-01 -7.3514e-03  4.7880e-02\n",
            " -4.0760e-01 -2.6759e-02  1.7919e-01  1.0977e-02 -1.0963e-01 -2.6395e-01\n",
            "  7.3990e-02  2.6236e-01 -1.5080e-01  3.4623e-01  2.5758e-01  1.1971e-01\n",
            " -3.7135e-02 -7.1593e-02  4.3898e-01 -4.0764e-02  1.6425e-02 -4.4640e-01\n",
            "  1.7197e-01  4.6246e-02  5.8639e-02  4.1499e-02  5.3948e-01  5.2495e-01\n",
            "  1.1361e-01 -4.8315e-02 -3.6385e-01  1.8704e-01  9.2761e-02 -1.1129e-01\n",
            " -4.2085e-01  1.3992e-01 -3.9338e-01 -6.7945e-02  1.2188e-01  1.6707e-01\n",
            "  7.5169e-02 -1.5529e-02 -1.9499e-01  1.9638e-01  5.3194e-02  2.5170e-01\n",
            " -3.4845e-01 -1.0638e-01 -3.4692e-01 -1.9024e-01 -2.0040e-01  1.2154e-01\n",
            " -2.9208e-01  2.3353e-02 -1.1618e-01 -3.5768e-01  6.2304e-02  3.5884e-01\n",
            "  2.9060e-02  7.3005e-03  4.9482e-03 -1.5048e-01 -1.2313e-01  1.9337e-01\n",
            "  1.2173e-01  4.4503e-01  2.5147e-01  1.0781e-01 -1.7716e-01  3.8691e-02\n",
            "  8.1530e-02  1.4667e-01  6.3666e-02  6.1332e-02 -7.5569e-02 -3.7724e-01\n",
            "  1.5850e-02 -3.0342e-01  2.8374e-01 -4.2013e-02 -4.0715e-02 -1.5269e-01\n",
            "  7.4980e-02  1.5577e-01  1.0433e-01  3.1393e-01  1.9309e-01  1.9429e-01\n",
            "  1.5185e-01 -1.0192e-01 -1.8785e-02  2.0791e-01  1.3366e-01  1.9038e-01\n",
            " -2.5558e-01  3.0400e-01 -1.8960e-02  2.0147e-01 -4.2110e-01 -7.5156e-03\n",
            " -2.7977e-01 -1.9314e-01  4.6204e-02  1.9971e-01 -3.0207e-01  2.5735e-01\n",
            "  6.8107e-01 -1.9409e-01  2.3984e-01  2.2493e-01  6.5224e-01 -1.3561e-01\n",
            " -1.7383e-01 -4.8209e-02 -1.1860e-01  2.1588e-03 -1.9525e-02  1.1948e-01\n",
            "  1.9346e-01 -4.0820e-01 -8.2966e-02  1.6626e-01 -1.0601e-01  3.5861e-01\n",
            "  1.6922e-01  7.2590e-02 -2.4803e-01 -1.0024e-01 -5.2491e-01 -1.7745e-01\n",
            " -3.6647e-01  2.6180e-01 -1.2077e-02  8.3190e-02 -2.1528e-01  4.1045e-01\n",
            "  2.9136e-01  3.0869e-01  7.8864e-02  3.2207e-01 -4.1023e-02 -1.0970e-01\n",
            " -9.2041e-02 -1.2339e-01 -1.6416e-01  3.5382e-01 -8.2774e-02  3.3171e-01\n",
            " -2.4738e-01 -4.8928e-02  1.5746e-01  1.8988e-01 -2.6642e-02  6.3315e-02\n",
            " -1.0673e-02  3.4089e-01  1.4106e+00  1.3417e-01  2.8191e-01 -2.5940e-01\n",
            "  5.5267e-02 -5.2425e-02 -2.5789e-01  1.9127e-02 -2.2084e-02  3.2113e-01\n",
            "  6.8818e-02  5.1207e-01  1.6478e-01 -2.0194e-01  2.9232e-01  9.8575e-02\n",
            "  1.3145e-02 -1.0652e-01  1.3510e-01 -4.5332e-02  2.0697e-01 -4.8425e-01\n",
            " -4.4706e-01  3.3305e-03  2.9264e-03 -1.0975e-01 -2.3325e-01  2.2442e-01\n",
            " -1.0503e-01  1.2339e-01  1.0978e-01  4.8994e-02 -2.5157e-01  4.0319e-01\n",
            "  3.5318e-01  1.8651e-01 -2.3622e-02 -1.2734e-01  1.1475e-01  2.7359e-01\n",
            " -2.1866e-01  1.5794e-02  8.1754e-01 -2.3792e-02 -8.5469e-01 -1.6203e-01\n",
            "  1.8076e-01  2.8014e-02 -1.4340e-01  1.3139e-03 -9.1735e-02 -8.9704e-02\n",
            "  1.1105e-01 -1.6703e-01  6.8377e-02 -8.7388e-02 -3.9789e-02  1.4184e-02\n",
            "  2.1187e-01  2.8579e-01 -2.8797e-01 -5.8996e-02 -3.2436e-02 -4.7009e-03\n",
            " -1.7052e-01 -3.4741e-02 -1.1489e-01  7.5093e-02  9.9526e-02  4.8183e-02\n",
            " -7.3775e-02 -4.1817e-01  4.1268e-03  4.4414e-01 -1.6062e-01  1.4294e-01\n",
            " -2.2628e+00 -2.7347e-02  8.1311e-01  7.7417e-01 -2.5639e-01 -1.1576e-01\n",
            " -1.1982e-01 -2.1363e-01  2.8429e-02  2.7261e-01  3.1026e-02  9.6782e-02\n",
            "  6.7769e-03  1.4082e-01 -1.3064e-02 -2.9686e-01 -7.9913e-02  1.9500e-01\n",
            "  3.1549e-02  2.8506e-01 -8.7461e-02  9.0611e-03 -2.0989e-01  5.3913e-02]\n",
            "quick:  [ 0.37594    0.063183   0.51835   -0.48652    0.34026   -0.17801\n",
            "  0.32615   -0.32989    0.25508   -1.026     -0.13841    0.27258\n",
            " -0.010244   0.35186    0.28341    0.3189    -0.18892   -0.292\n",
            " -0.071297   0.25631   -0.34286    0.16179    0.065725  -0.038052\n",
            "  0.1457     0.20289    0.14274   -0.15024    0.35412   -0.13715\n",
            " -0.2677    -0.011243  -0.1541     0.1765    -1.5424     0.37699\n",
            " -0.28239    0.19172   -0.46349   -0.26345   -0.39337    0.41276\n",
            "  0.42873   -0.1317     0.31096   -0.28715    0.47212   -0.41866\n",
            " -0.11871   -0.026621  -0.21089   -0.074757   0.26429   -0.032246\n",
            " -0.084233   0.48653   -0.38692   -0.3756    -0.27031    0.15208\n",
            "  0.2263    -0.28777    0.12475   -0.17029    0.019322   0.34175\n",
            "  0.69492   -0.42039    0.3161    -0.23871    0.30485   -0.078005\n",
            "  0.25937   -0.036324   0.27365   -0.1698    -0.10004    0.13614\n",
            "  0.0094279 -0.51261    0.3464     0.032112   0.25292    0.1947\n",
            "  0.16906   -0.044683  -0.039252   0.31651   -0.27185    0.10862\n",
            "  0.070371   0.31916   -0.55993   -0.5553     0.5493    -0.17244\n",
            " -0.70848    0.039063   0.33553   -0.11393   -0.28882   -0.53623\n",
            "  0.0021584  0.24971    0.31383   -0.2516    -0.28619    0.20113\n",
            " -0.29545   -0.3285     0.33289    0.19422    0.047601  -0.13157\n",
            "  0.4269     0.085041  -0.30294   -0.38344   -0.035083  -0.0463\n",
            "  0.035454  -0.052446   0.51216   -0.37809   -0.24834    0.28464\n",
            "  0.019408   0.61137    0.14859    0.30104    0.23773    0.37627\n",
            " -0.64467    0.19701   -0.19264   -0.013601   0.073281  -0.43031\n",
            "  0.38081   -0.42172   -0.16131    0.12108   -0.12078   -0.20818\n",
            " -0.4697     0.1279    -0.63088    0.16412    0.20474    0.16701\n",
            " -0.79632   -0.075741  -0.25251   -0.025189   0.081245  -0.081758\n",
            " -0.12925   -0.33034    0.039839  -0.30436    0.023003  -0.35589\n",
            "  0.40923   -0.10969   -0.084268   0.56261    0.37604    0.10676\n",
            " -0.1678     0.11219   -0.13141   -0.025916  -0.56102   -0.074779\n",
            " -0.14769    0.13028   -0.38351    0.055938   0.1996     0.0052525\n",
            "  0.11655   -0.58141    0.45407   -0.11067   -0.10262    0.31478\n",
            " -0.049739  -0.34926   -0.016468  -0.12476   -0.071381   0.34803\n",
            " -0.12247   -0.38406    0.095986   0.12451   -0.033609  -0.62353\n",
            "  0.25048   -0.1427     0.60613   -0.080829   0.25008    0.059055\n",
            " -0.17486    0.14913   -0.41488    0.27573   -0.11921   -0.02267\n",
            " -0.34188   -0.49563   -0.22119    0.49553   -0.035482  -0.11908\n",
            "  0.0096008 -0.44059   -0.35947   -0.19156    0.28505    0.35236\n",
            " -0.3384    -0.28643   -0.22068   -0.29761    0.10412   -0.067384\n",
            "  0.043089  -0.05794   -0.31212    0.24026    0.072559  -0.024896\n",
            " -0.19299    0.020044  -0.10826    0.2022     0.097076   0.43886\n",
            "  0.35085    0.38611   -0.1838    -0.047166  -0.5351    -0.17215\n",
            "  0.17407    0.17959   -0.35965   -0.23817    0.16348   -0.79488\n",
            "  0.18858    0.027404   0.23823    0.047581   0.2485     0.18332\n",
            " -0.22626    0.54554   -0.31324   -0.22699   -0.31341    0.68296\n",
            "  0.13422   -0.27644   -0.38901   -0.29207   -0.10058    0.12057\n",
            " -0.36691   -0.69507   -0.22242   -0.023121   0.72283    0.0051197\n",
            " -1.7769     0.40651    0.025966  -0.18157    0.23957    0.37943\n",
            "  0.67713    0.49789    0.3634    -0.60131    0.53868   -0.18682\n",
            " -0.14783    0.40581    0.1379     0.054337  -0.12388    0.064828\n",
            "  0.27453    0.5165    -0.1955    -0.55939   -0.2744    -0.12146  ]\n",
            "brown:  [ 0.2793     0.18372   -0.11257    0.21734   -0.21657   -0.50335\n",
            " -0.27194    0.32181    0.031892  -0.37998    0.15544   -0.32953\n",
            " -0.19827    0.20403    0.26768    0.292     -0.34187   -0.10766\n",
            " -0.43697   -0.14488    0.14634    0.21591    0.12576    0.14895\n",
            " -0.21763    0.030797   0.10949   -0.41689   -0.30296   -0.14592\n",
            " -0.56228    0.33282   -0.20436   -0.24403   -1.4732     0.68345\n",
            "  0.45336    0.43671   -0.15641    0.15075   -0.24265   -0.040059\n",
            "  0.22323    0.19523    0.37445   -0.18509   -0.10302   -0.055363\n",
            " -0.17274   -0.45401   -0.14729   -0.24133   -0.043826  -0.23243\n",
            "  0.42367    0.15906   -0.14039   -0.36185   -0.26695   -0.42724\n",
            " -0.08843   -0.099597   0.24257   -0.05424    0.10746   -1.1304\n",
            "  0.024651  -0.10212    0.046319  -0.68792    0.4214    -0.25844\n",
            "  0.17052    0.097878   0.026835   0.32044    0.0062988  0.24575\n",
            "  0.20126   -0.16771    0.19825    0.28939   -0.064994  -0.38766\n",
            "  0.52509    0.38195    0.32421    0.20683   -0.48472   -0.080334\n",
            " -0.15345    0.35459   -0.43765    0.071575  -0.39516   -0.22906\n",
            "  0.25686    0.26659    0.37626   -0.18556    0.16445   -0.33614\n",
            " -0.56262    0.067852  -0.61642    0.19546    0.45027    0.20238\n",
            "  0.33957    0.41372    0.11855    0.087619   0.18754    0.17901\n",
            "  0.022569  -0.10854   -0.47226    0.41039    0.32588   -0.58468\n",
            " -0.0057296 -0.29201   -0.12777   -0.15729   -0.40103   -0.039414\n",
            " -0.1192     0.40093    0.032862   0.39862   -0.63525    0.11594\n",
            " -0.39954    0.36919   -0.50021   -0.51169   -0.13955    0.18055\n",
            " -0.079918  -0.19474    0.53131    0.093723   0.2773    -0.40505\n",
            " -0.20568    0.11139    0.032661  -0.04852    0.44576    0.23667\n",
            "  0.54981    0.23585   -0.51539   -0.46424    0.021099  -0.3919\n",
            "  0.58338   -0.89908    0.094066   0.30159   -0.063199  -0.31635\n",
            "  0.50333   -0.068517  -0.38681    0.33      -0.49463    0.75491\n",
            " -0.088266  -0.19413    0.4238    -0.031727  -0.4464    -0.21028\n",
            " -0.11151   -0.07088   -0.027832  -0.63304    0.27336   -0.47925\n",
            " -0.03239    0.46069    0.16968   -0.38262   -0.31413   -0.29068\n",
            " -0.031801  -0.48974   -0.50999    0.1466     0.0027995  0.56333\n",
            " -0.044347  -0.085679   0.20559   -0.051593   0.75228   -0.013291\n",
            " -0.084694  -0.4305     1.1734    -0.083233   0.1561    -0.15758\n",
            "  0.19066   -0.2966     0.63704    0.45616   -0.34797   -0.12732\n",
            "  0.4901    -0.51217   -0.063474  -0.061496   0.28825    0.17711\n",
            "  0.46301   -0.12697   -0.044627  -1.0064     0.76394    0.20494\n",
            "  0.028766   0.27597    0.021726  -0.12054    0.23284    0.18999\n",
            "  0.30048   -0.056139   0.09546   -0.036514   0.0084885  0.016599\n",
            " -0.31428   -0.2707     0.099281   0.4445    -0.36      -0.55556\n",
            " -0.18551   -0.30644    0.056475  -0.19197   -0.48886    0.33044\n",
            "  0.19535   -0.53828    0.12385   -0.29372   -0.1036     0.0051129\n",
            "  0.11483   -0.10591    0.73337    0.26978   -0.06925    0.11565\n",
            "  0.27711    0.15109   -0.069137  -0.14481    0.32319    0.039345\n",
            " -0.44964    0.27103    0.045326  -0.064534  -0.37144    0.47615\n",
            " -0.61105   -0.11922   -0.068806   0.15401   -0.40812    0.32575\n",
            " -1.2888     0.0203    -0.12893   -0.22211   -0.16402    0.29018\n",
            "  0.36295   -0.081025  -0.50492    0.5046    -0.37485    0.52111\n",
            "  0.1757     0.069686   0.48937   -0.17747   -0.20577    0.70419\n",
            "  0.068633   0.47878   -0.21754   -0.016868  -0.91378    0.45643  ]\n",
            "fox:  [-1.1570e-01 -2.5048e-02 -1.1013e-01 -4.8060e-02 -8.5504e-02  3.7308e-01\n",
            " -9.4790e-01  5.9662e-01 -2.0006e-02 -3.0469e-01  2.4997e-01 -2.0005e-01\n",
            "  1.9284e-01  4.7197e-01  2.7099e-01  3.4190e-01 -2.9186e-01 -3.9718e-01\n",
            "  5.5653e-01  3.2774e-01  9.4860e-02 -4.6588e-01  6.2119e-01  2.0709e-01\n",
            "  8.2332e-02 -1.0175e-01  3.2067e-01 -3.1875e-01  1.7941e-01 -2.4127e-01\n",
            " -1.7961e-02 -8.7154e-02  3.3423e-01 -4.5026e-02 -1.2193e+00  1.9321e-01\n",
            "  2.1427e-01  2.3893e-01 -1.8084e-01 -1.5920e-01 -1.0387e-01  2.2060e-01\n",
            "  2.5423e-01  2.0815e-01 -3.3072e-01 -2.0672e-01 -3.1424e-01  2.6498e-02\n",
            "  2.1955e-01 -3.1157e-01 -7.8914e-02 -1.5089e-02 -4.0848e-02 -2.3807e-01\n",
            "  3.1983e-01 -7.4173e-02  2.2983e-01  5.5735e-02  5.6743e-03 -7.7368e-01\n",
            "  2.7412e-01 -1.8999e-01  5.3825e-01 -1.9784e-01 -1.0898e-01 -3.4022e-01\n",
            "  3.1582e-01  5.0317e-01  3.3955e-01 -2.7143e-01 -3.3026e-02  3.4279e-01\n",
            " -4.9815e-01  2.5056e-01 -1.2791e-01 -1.5912e-01 -8.7541e-03  1.0450e-01\n",
            "  2.1969e-01 -5.9077e-02 -3.7600e-01  6.0835e-02  1.8427e-01 -8.3592e-02\n",
            "  1.1632e-01  7.5145e-01  6.5186e-02 -3.3258e-01  1.4249e-01 -6.5348e-01\n",
            " -2.6661e-03  1.0233e-01 -3.8731e-01  6.0529e-01 -2.7326e-01 -3.5777e-01\n",
            " -5.3533e-01  4.9589e-02  2.0224e-01 -3.2805e-01  3.9305e-01 -2.7540e-01\n",
            " -1.3042e-01  9.5833e-01  3.8853e-01  5.9884e-01 -3.0503e-01 -1.0708e-01\n",
            "  4.5670e-01  7.2182e-01 -4.4221e-02 -6.8201e-02 -2.9903e-01  2.6483e-01\n",
            "  6.6810e-03  1.4919e-01 -5.3155e-01 -6.1697e-01 -5.4271e-01 -4.1103e-01\n",
            " -1.7534e-01  1.3229e-01  2.6958e-02 -1.5111e-01 -1.6844e-01 -3.0684e-01\n",
            " -5.1189e-02  9.2940e-01 -6.0882e-01 -1.1373e-01 -4.2237e-01 -4.0481e-01\n",
            " -3.4182e-01  3.8472e-01 -1.1566e-01  2.2679e-02  4.4793e-01  1.8849e-01\n",
            " -1.9598e-01 -6.8914e-02 -4.4520e-01  4.1643e-01  5.8319e-02 -3.9575e-01\n",
            " -4.0471e-01  4.2855e-01  1.6339e-01 -1.6965e-01 -5.7793e-02 -1.0358e-01\n",
            "  1.0223e+00  9.0564e-01 -5.5851e-01 -2.4856e-01  7.5582e-02 -2.7374e-01\n",
            "  3.8838e-01  5.1561e-01  6.0029e-02 -5.1990e-02  1.0113e+00  8.3607e-03\n",
            "  4.9764e-01  3.2839e-02  2.5892e-02  4.0404e-01 -3.7393e-01  1.3384e-01\n",
            " -2.9458e-01  3.4668e-01  5.2114e-02  1.0785e-01 -8.4700e-01  4.0936e-01\n",
            "  3.8801e-01  4.5079e-01 -4.3880e-01  1.9777e-01  1.9102e-01 -7.6580e-02\n",
            "  2.5788e-01  3.5642e-01  2.3305e-01 -1.6206e-01 -5.0847e-02  1.3708e-01\n",
            "  5.1338e-02 -3.8552e-01 -2.5497e-01  5.3901e-02 -6.2922e-01  3.2780e-01\n",
            " -2.0383e-01 -1.7265e-01 -9.9668e-02  2.4485e-01  3.2700e-02  3.2325e-01\n",
            "  2.3912e-01  7.7014e-03  1.2890e+00  6.8030e-02  2.0671e-02  2.6268e-01\n",
            "  1.9434e-01  5.6238e-01  7.1863e-02 -6.5502e-02 -2.2858e-01  9.2883e-02\n",
            "  3.9936e-01 -2.8038e-01  3.5633e-01  1.5203e-01 -2.7883e-01  3.8225e-02\n",
            " -3.9636e-01  3.2488e-01  2.4332e-01  2.2621e-01  2.3518e-01 -6.4747e-02\n",
            "  6.2858e-01 -1.1848e-01  1.2710e-01 -1.2697e-01  1.0015e+00 -2.5693e-01\n",
            "  2.0450e-01 -1.8789e-01 -1.2913e-01 -9.6456e-02  1.2301e-01 -1.3377e-01\n",
            " -1.2808e-01  4.1857e-02  8.6418e-01  3.6137e-01  9.0372e-02 -1.0687e-02\n",
            "  4.4736e-01  7.8975e-02 -3.2992e-01 -1.4470e-01 -6.1296e-01 -4.1543e-01\n",
            " -2.6104e-01 -8.4169e-01  4.7352e-01 -4.7640e-01 -3.4393e-01  8.2156e-02\n",
            " -2.4477e-01  7.9361e-01  2.6183e-01  4.6648e-01  1.9135e-01 -5.5033e-02\n",
            "  2.3492e-01  1.1178e-01 -3.7291e-01  2.6764e-01  1.1074e-01  6.8041e-01\n",
            " -1.0361e-03 -4.2537e-02  9.4006e-01 -2.8939e-01 -2.0841e-01  3.3001e-01\n",
            "  7.3318e-02 -5.1902e-01 -3.6412e-01 -4.1372e-01  2.0266e-01  4.3162e-01\n",
            " -1.0174e+00  2.5093e-01  3.8136e-01 -1.4332e-01 -2.0525e-01 -1.8724e-01\n",
            "  5.9925e-01  3.5604e-01 -9.1457e-01 -2.2401e-01 -4.2382e-02 -1.3299e-01\n",
            "  6.1671e-01  4.4886e-01 -1.1361e-01  2.0483e-01  2.5485e-01  2.7581e-01\n",
            " -8.7158e-01 -1.3156e-01  2.6117e-01  1.5815e-01 -3.2199e-01  7.1042e-01]\n",
            "jumps:  [-0.16814   -0.10948    0.2896    -0.21108   -0.29061    0.31201\n",
            "  0.04039   -0.10149   -0.18526   -0.55483   -0.36055   -0.093569\n",
            "  0.77334    0.027921   0.13389   -0.1014    -0.06482    0.24753\n",
            " -0.068026   0.26147   -0.14252    0.18657    0.030249  -0.07934\n",
            "  0.87696    0.61781    0.36835   -0.07306   -0.19303    0.3721\n",
            " -0.77087   -0.0062782 -0.19233   -0.43884   -0.79847    0.066636\n",
            " -0.21387   -0.65263   -0.073964   0.64115   -0.52014   -0.05981\n",
            " -0.1692    -0.413      0.060197   0.16327    0.43353    0.070021\n",
            "  0.063543   0.28527   -0.43474    0.15441    0.098037   0.098685\n",
            " -0.3965     0.38171   -0.084065  -0.4813    -0.59213    0.40444\n",
            " -0.2026     0.45569    0.039036  -0.41786   -0.20322   -0.11932\n",
            "  0.23747    0.26336    0.17139    0.12521   -0.55276    0.45515\n",
            " -0.63826    0.14054    0.35333   -0.28417    0.3889    -0.13004\n",
            " -0.027142  -0.23109    0.034327  -0.10685    0.85855    0.15145\n",
            "  0.16814    0.2281     0.22235   -0.1825    -0.019222   0.026105\n",
            "  0.47734    0.42115   -0.087767  -0.17439    0.22166   -0.36831\n",
            " -1.069      0.40489   -0.31038   -0.21588   -0.7282     0.29296\n",
            " -0.42949    0.23485    0.020585  -0.47795   -0.20216   -0.22146\n",
            " -0.45778    0.032547  -0.13727   -0.48945   -0.58148    0.051203\n",
            " -0.065926   0.46718   -0.080438  -0.25042   -0.4015     0.40254\n",
            "  0.12       0.5246     0.21582    0.1333     0.27662    0.2163\n",
            " -0.28177    0.67185   -0.025996  -0.40781   -0.23629    0.97455\n",
            " -0.51452    0.22697   -0.34857   -0.55928    0.019104  -0.016163\n",
            " -0.22626    0.094269   0.10808   -0.018804  -0.080299   0.0058964\n",
            " -0.61886    0.44842    0.2494    -0.25172    0.6705     0.23657\n",
            " -0.17631    0.28634   -0.39527   -0.22096    0.23069    0.0644\n",
            "  0.13151   -0.030479   0.38503   -0.084794   0.66178   -0.34578\n",
            "  0.3868     0.31506    0.20155   -0.026189   0.051188   0.16359\n",
            " -0.37096    0.21546   -0.19758   -0.083407   0.48437   -0.5487\n",
            "  0.35188   -0.43539    0.3976    -0.026514  -0.14485   -0.11205\n",
            "  0.59835    0.38055    0.1582    -0.24293    0.39837    0.44276\n",
            "  0.36113   -0.2358    -0.32568    0.54672   -0.36544   -0.33871\n",
            "  0.2154    -0.36877   -0.18857    0.42323   -0.56938   -0.20276\n",
            "  0.35452   -0.0167     1.157      0.22296   -0.35115    0.3662\n",
            " -0.20903    0.73497    0.018414   0.27861    0.044337   0.14504\n",
            " -0.23001   -0.54025   -0.26259   -0.94587    0.22239    0.44651\n",
            " -0.46075   -0.42224    0.0022315 -0.25522   -0.13135    0.65923\n",
            "  0.21267   -0.26498   -0.16777   -0.047013  -0.18551    0.12607\n",
            "  0.43205    0.153     -0.33748    0.010732  -0.18332   -0.28507\n",
            "  0.23396    0.3868    -0.34724    0.41692    0.56315    0.32366\n",
            "  0.55303    0.02256   -0.48281    0.54561   -0.51086   -0.55446\n",
            " -0.018992   0.62551    0.11436   -0.10939   -0.61894   -0.18419\n",
            "  0.27755   -0.29704   -0.21562   -0.011765   0.051859   0.04041\n",
            " -0.16798    0.65697   -0.36868    0.068085   0.34986    0.076252\n",
            "  0.12035    0.16001   -0.0088939  0.14892   -0.70374   -0.031891\n",
            "  0.2803    -0.26916   -0.61974    0.67423    0.080773  -0.32835\n",
            " -0.276     -0.60342   -0.60185    0.10982   -0.20312    0.42309\n",
            "  0.63701    0.51885   -0.31899    0.34256   -0.035933  -0.049542\n",
            " -0.89278   -0.03686    0.12862    0.41469   -0.37262   -0.20523\n",
            " -0.02476   -0.11959   -0.12129    0.099622   0.24538   -0.026313 ]\n",
            "over:  [-8.8137e-02 -2.1696e-02  2.9863e-01 -1.8325e-02 -2.3575e-01  1.1022e-01\n",
            " -1.7493e-01  9.9241e-03  2.3832e-01 -1.7643e+00  2.2489e-01  4.0552e-01\n",
            " -4.8176e-01 -6.6099e-02  1.3290e-01  4.7502e-01 -5.6438e-02  3.2902e-01\n",
            "  9.7628e-02  4.2467e-01  2.5285e-01 -1.7258e-01  7.6564e-02 -1.5678e-01\n",
            " -2.2694e-01 -2.1213e-01 -3.3460e-01  7.3842e-02 -4.4671e-01  3.3979e-01\n",
            " -2.3534e-01  1.5013e-01 -3.4718e-01  5.4379e-02 -8.8699e-01 -3.5534e-01\n",
            " -1.3166e-01 -1.8265e-02 -1.8708e-01  3.0193e-01  1.0008e-01 -1.1980e-01\n",
            " -7.4867e-01  1.5592e-01  4.2757e-01 -2.9996e-01 -1.2499e-01  1.2750e-01\n",
            " -2.1962e-01  4.5077e-01 -3.2268e-01 -2.8934e-01 -1.3745e-01 -1.7738e-01\n",
            "  2.4185e-01 -1.2240e-02  1.7264e-01  2.7287e-01 -8.2743e-02  2.0570e-01\n",
            "  2.2559e-02 -7.5793e-02  2.1027e-01 -3.1239e-01  1.3032e-01 -7.5693e-01\n",
            "  9.0872e-02  4.9975e-01  1.1746e-01 -5.3133e-01 -8.5348e-02  4.4042e-01\n",
            "  1.2231e-01 -1.8672e-01  1.1668e-01  1.0322e-02 -2.6779e-01  1.5042e-01\n",
            " -5.4751e-01 -3.8439e-01 -6.7117e-01 -3.4912e-01  1.4190e-01  1.2742e-01\n",
            " -1.2879e-01 -1.3582e-01  2.9059e-01  1.4339e-01  2.8467e-01  7.0642e-02\n",
            "  4.7118e-03  1.8321e-01 -4.0973e-01  2.1973e-01 -6.6693e-01 -1.0599e-01\n",
            " -3.4465e-01  2.3103e-01 -3.6278e-01 -1.2365e-02  1.1544e-01  3.6134e-02\n",
            "  7.4889e-02 -6.4933e-01 -3.3362e-02 -3.0498e-01  4.0964e-01  2.6898e-01\n",
            " -2.1150e-01 -1.1446e-01 -4.8326e-02 -5.9265e-01 -3.7301e-01 -5.4902e-02\n",
            " -1.9869e-01  2.3181e-01 -2.9017e-01  6.2177e-01  8.9856e-02 -6.4116e-01\n",
            "  3.9304e-02  9.7170e-02 -2.9954e-01  4.0426e-01  8.4010e-02  1.2902e-01\n",
            " -3.5864e-01  3.9975e-01  1.3183e-01 -1.4797e-01 -3.1449e-01  4.8654e-01\n",
            "  2.9974e-02  5.3637e-01  1.1619e-01  1.4643e-01 -2.2927e-01  7.9999e-02\n",
            "  1.3114e-01 -3.0946e-02  1.6410e-01 -3.5597e-01  2.0801e-01  3.3193e-01\n",
            " -8.4092e-01  3.3762e-01 -7.5518e-02 -4.3158e-01  1.9592e-01 -2.7815e-01\n",
            "  6.6744e-01  3.1189e-02 -1.1706e-02  5.3737e-01  2.9596e-01  3.7335e-01\n",
            " -2.2166e-01  2.3843e-02 -1.1905e-01 -1.8529e-01  1.1857e-02 -2.3540e-01\n",
            "  2.3800e-01 -3.1987e-02 -1.6400e-01 -7.9319e-02  9.9570e-02  2.6182e-02\n",
            " -6.0793e-01 -6.7515e-02  3.9870e-02  7.0721e-02 -6.0965e-01 -7.3549e-01\n",
            " -8.1241e-03 -1.3363e-01 -1.6572e-01  3.2373e-01  1.0115e-01  6.0659e-01\n",
            " -2.2547e-02  2.5960e-01  2.4251e-01 -7.8426e-02 -7.8699e-02 -4.1680e-01\n",
            " -1.4208e-01  2.5136e-02 -3.4187e-01  2.7631e-01  2.4892e-01  2.7898e-01\n",
            " -2.6522e-01 -3.3989e-01  1.7929e-01 -4.0393e-01  2.7421e-01  2.2639e-01\n",
            "  4.5234e-01 -2.4806e-01  9.4945e-01  1.4040e-01  2.3117e-02 -3.3321e-01\n",
            "  3.6958e-01 -1.7507e-01 -1.8646e-01 -2.4238e-01  2.0633e-02 -7.8795e-02\n",
            "  5.1631e-01  4.5651e-01  2.5398e-01  3.8711e-01  1.6812e-01 -5.8263e-01\n",
            " -9.9027e-02 -2.3445e-01  3.6928e-02  6.1330e-02  2.4186e-01 -2.0908e-01\n",
            " -3.8720e-02  1.4625e-01 -3.6779e-02  2.5993e-01  3.1897e-01 -5.5307e-02\n",
            " -7.7177e-02  3.0117e-01  2.3307e-01  4.1980e-01 -1.3339e-01 -2.0384e-02\n",
            "  7.1158e-01  8.4989e-02  3.2791e-01  4.8060e-01 -3.3761e-01  5.7392e-02\n",
            " -2.6536e-01  3.0228e-01  1.8540e-01 -8.3752e-02 -7.3776e-01 -1.4404e-03\n",
            "  3.4121e-01  2.9959e-02  4.2035e-01  7.3122e-02 -1.9430e-01 -2.2341e-01\n",
            "  5.8658e-01 -2.2756e-01  6.3029e-01 -6.8682e-02 -3.5365e-01  2.6851e-01\n",
            " -7.3124e-02  1.5702e-02  1.2022e-01 -2.4631e-01  2.8471e-01  3.8292e-01\n",
            " -3.8869e-01  2.0974e-01 -2.0512e-01 -1.8508e-01  3.2543e-01  3.7336e-03\n",
            " -1.9901e-02 -8.4242e-02  2.9326e-01 -5.8162e-02  3.6575e-01  4.6895e-02\n",
            " -2.1328e+00 -3.5109e-01  4.1716e-01  1.8393e-01 -3.0990e-01  2.7303e-01\n",
            "  1.6627e-02  4.4978e-03 -7.2902e-02  5.3814e-02 -5.7213e-02  1.5815e-01\n",
            "  1.4517e-01  1.6580e-01 -7.3557e-02  1.6125e-01 -9.9237e-02  2.6099e-01\n",
            "  2.7941e-02  3.2140e-01  1.6931e-01 -3.5469e-01 -4.2713e-01 -3.9323e-01]\n",
            "the:  [ 4.6560e-02  2.1318e-01 -7.4364e-03 -4.5854e-01 -3.5639e-02  2.3643e-01\n",
            " -2.8836e-01  2.1521e-01 -1.3486e-01 -1.6413e+00 -2.6091e-01  3.2434e-02\n",
            "  5.6621e-02 -4.3296e-02 -2.1672e-02  2.2476e-01 -7.5129e-02 -6.7018e-02\n",
            " -1.4247e-01  3.8825e-02 -1.8951e-01  2.9977e-01  3.9305e-01  1.7887e-01\n",
            " -1.7343e-01 -2.1178e-01  2.3617e-01 -6.3681e-02 -4.2318e-01 -1.1661e-01\n",
            "  9.3754e-02  1.7296e-01 -3.3073e-01  4.9112e-01 -6.8995e-01 -9.2462e-02\n",
            "  2.4742e-01 -1.7991e-01  9.7908e-02  8.3118e-02  1.5299e-01 -2.7276e-01\n",
            " -3.8934e-02  5.4453e-01  5.3737e-01  2.9105e-01 -7.3514e-03  4.7880e-02\n",
            " -4.0760e-01 -2.6759e-02  1.7919e-01  1.0977e-02 -1.0963e-01 -2.6395e-01\n",
            "  7.3990e-02  2.6236e-01 -1.5080e-01  3.4623e-01  2.5758e-01  1.1971e-01\n",
            " -3.7135e-02 -7.1593e-02  4.3898e-01 -4.0764e-02  1.6425e-02 -4.4640e-01\n",
            "  1.7197e-01  4.6246e-02  5.8639e-02  4.1499e-02  5.3948e-01  5.2495e-01\n",
            "  1.1361e-01 -4.8315e-02 -3.6385e-01  1.8704e-01  9.2761e-02 -1.1129e-01\n",
            " -4.2085e-01  1.3992e-01 -3.9338e-01 -6.7945e-02  1.2188e-01  1.6707e-01\n",
            "  7.5169e-02 -1.5529e-02 -1.9499e-01  1.9638e-01  5.3194e-02  2.5170e-01\n",
            " -3.4845e-01 -1.0638e-01 -3.4692e-01 -1.9024e-01 -2.0040e-01  1.2154e-01\n",
            " -2.9208e-01  2.3353e-02 -1.1618e-01 -3.5768e-01  6.2304e-02  3.5884e-01\n",
            "  2.9060e-02  7.3005e-03  4.9482e-03 -1.5048e-01 -1.2313e-01  1.9337e-01\n",
            "  1.2173e-01  4.4503e-01  2.5147e-01  1.0781e-01 -1.7716e-01  3.8691e-02\n",
            "  8.1530e-02  1.4667e-01  6.3666e-02  6.1332e-02 -7.5569e-02 -3.7724e-01\n",
            "  1.5850e-02 -3.0342e-01  2.8374e-01 -4.2013e-02 -4.0715e-02 -1.5269e-01\n",
            "  7.4980e-02  1.5577e-01  1.0433e-01  3.1393e-01  1.9309e-01  1.9429e-01\n",
            "  1.5185e-01 -1.0192e-01 -1.8785e-02  2.0791e-01  1.3366e-01  1.9038e-01\n",
            " -2.5558e-01  3.0400e-01 -1.8960e-02  2.0147e-01 -4.2110e-01 -7.5156e-03\n",
            " -2.7977e-01 -1.9314e-01  4.6204e-02  1.9971e-01 -3.0207e-01  2.5735e-01\n",
            "  6.8107e-01 -1.9409e-01  2.3984e-01  2.2493e-01  6.5224e-01 -1.3561e-01\n",
            " -1.7383e-01 -4.8209e-02 -1.1860e-01  2.1588e-03 -1.9525e-02  1.1948e-01\n",
            "  1.9346e-01 -4.0820e-01 -8.2966e-02  1.6626e-01 -1.0601e-01  3.5861e-01\n",
            "  1.6922e-01  7.2590e-02 -2.4803e-01 -1.0024e-01 -5.2491e-01 -1.7745e-01\n",
            " -3.6647e-01  2.6180e-01 -1.2077e-02  8.3190e-02 -2.1528e-01  4.1045e-01\n",
            "  2.9136e-01  3.0869e-01  7.8864e-02  3.2207e-01 -4.1023e-02 -1.0970e-01\n",
            " -9.2041e-02 -1.2339e-01 -1.6416e-01  3.5382e-01 -8.2774e-02  3.3171e-01\n",
            " -2.4738e-01 -4.8928e-02  1.5746e-01  1.8988e-01 -2.6642e-02  6.3315e-02\n",
            " -1.0673e-02  3.4089e-01  1.4106e+00  1.3417e-01  2.8191e-01 -2.5940e-01\n",
            "  5.5267e-02 -5.2425e-02 -2.5789e-01  1.9127e-02 -2.2084e-02  3.2113e-01\n",
            "  6.8818e-02  5.1207e-01  1.6478e-01 -2.0194e-01  2.9232e-01  9.8575e-02\n",
            "  1.3145e-02 -1.0652e-01  1.3510e-01 -4.5332e-02  2.0697e-01 -4.8425e-01\n",
            " -4.4706e-01  3.3305e-03  2.9264e-03 -1.0975e-01 -2.3325e-01  2.2442e-01\n",
            " -1.0503e-01  1.2339e-01  1.0978e-01  4.8994e-02 -2.5157e-01  4.0319e-01\n",
            "  3.5318e-01  1.8651e-01 -2.3622e-02 -1.2734e-01  1.1475e-01  2.7359e-01\n",
            " -2.1866e-01  1.5794e-02  8.1754e-01 -2.3792e-02 -8.5469e-01 -1.6203e-01\n",
            "  1.8076e-01  2.8014e-02 -1.4340e-01  1.3139e-03 -9.1735e-02 -8.9704e-02\n",
            "  1.1105e-01 -1.6703e-01  6.8377e-02 -8.7388e-02 -3.9789e-02  1.4184e-02\n",
            "  2.1187e-01  2.8579e-01 -2.8797e-01 -5.8996e-02 -3.2436e-02 -4.7009e-03\n",
            " -1.7052e-01 -3.4741e-02 -1.1489e-01  7.5093e-02  9.9526e-02  4.8183e-02\n",
            " -7.3775e-02 -4.1817e-01  4.1268e-03  4.4414e-01 -1.6062e-01  1.4294e-01\n",
            " -2.2628e+00 -2.7347e-02  8.1311e-01  7.7417e-01 -2.5639e-01 -1.1576e-01\n",
            " -1.1982e-01 -2.1363e-01  2.8429e-02  2.7261e-01  3.1026e-02  9.6782e-02\n",
            "  6.7769e-03  1.4082e-01 -1.3064e-02 -2.9686e-01 -7.9913e-02  1.9500e-01\n",
            "  3.1549e-02  2.8506e-01 -8.7461e-02  9.0611e-03 -2.0989e-01  5.3913e-02]\n",
            "lazy:  [ 4.2791e-01 -1.6070e-01  2.4912e-01  3.9763e-01 -3.2224e-01  1.9783e-04\n",
            "  8.8576e-02  4.0501e-01 -2.4655e-01  1.6410e-02 -2.3331e-01 -1.2307e-01\n",
            " -3.9679e-01  2.1877e-02  1.6211e-01  3.8852e-01  2.5025e-01 -4.3968e-02\n",
            "  1.0819e+00  6.6517e-01  2.1829e-01  7.9898e-01 -6.1695e-01 -1.0184e-01\n",
            "  2.2900e-01 -3.1982e-01  3.1205e-01 -1.0453e-01  4.4810e-01  3.6708e-02\n",
            " -1.1376e-02  7.0543e-01  2.7454e-01  2.5835e-01 -5.1821e-01  8.2996e-01\n",
            " -8.0672e-02 -4.5489e-01 -3.4843e-01  5.1421e-01 -5.7408e-01  6.4612e-01\n",
            " -2.1564e-01 -5.4848e-01  2.3656e-01  1.8453e-02  8.6403e-01 -1.0357e-01\n",
            " -5.6097e-02 -4.8564e-01  2.7927e-01 -6.1733e-01  5.2877e-01 -1.9221e-01\n",
            " -1.4684e-01  4.2272e-01  5.6312e-02 -3.3168e-01  8.1864e-02  2.2225e-01\n",
            "  2.7757e-01 -2.1934e-02  2.8499e-01  5.7453e-03 -4.0598e-01  6.1549e-02\n",
            "  1.1544e-01  7.2053e-02 -5.4945e-02 -3.9549e-02 -1.9371e-01  2.7872e-01\n",
            " -1.0139e-01 -7.1846e-02 -3.4043e-01 -2.2490e-02 -2.6097e-03  6.5403e-01\n",
            "  4.1425e-01 -1.1459e-01 -4.9802e-01 -3.4516e-02 -3.0815e-02 -6.1508e-01\n",
            "  4.8955e-01 -1.0641e-01  6.3485e-02  5.5039e-01 -1.6282e-01 -7.7526e-02\n",
            " -1.5945e-01  3.0791e-01 -3.0439e-02 -3.8283e-01  7.8436e-02  1.1488e-01\n",
            "  6.7573e-02  2.2181e-01 -1.4319e-02  1.4366e-02  2.8839e-01 -9.1358e-01\n",
            " -5.3084e-01  1.3097e-01 -2.0027e-01  2.1495e-01 -3.6158e-01  7.6012e-02\n",
            "  1.2718e-01  2.5851e-01  6.6530e-02  3.1628e-01 -6.3175e-01 -4.1942e-01\n",
            "  3.8640e-01  7.3017e-02 -9.2298e-02 -8.8510e-01 -2.1618e-01  2.9006e-01\n",
            "  3.6404e-01  2.3740e-01 -2.2910e-01  3.2436e-01  6.0954e-01  3.2458e-01\n",
            " -8.4691e-02  4.1471e-01  2.6053e-01  6.8716e-02 -4.4528e-01  2.9296e-02\n",
            " -4.7913e-02  4.5709e-01 -5.2956e-01 -3.0998e-01  3.2488e-01 -3.6054e-01\n",
            "  1.8449e-01 -3.8492e-01  3.9918e-02  4.0046e-01 -8.7039e-02 -4.9739e-01\n",
            " -7.1877e-01  1.4894e-01  1.5550e-01  3.2388e-01  6.7209e-01  4.0215e-01\n",
            " -7.3436e-01  7.0311e-02 -7.3754e-02  3.1062e-01  1.4725e-03  4.3386e-02\n",
            "  2.9529e-01 -1.0544e-01  7.5028e-01  2.2274e-01  4.3789e-02 -6.7316e-01\n",
            "  6.8448e-01 -5.5239e-01 -2.2204e-02 -1.8850e-01 -4.0747e-01 -5.7321e-02\n",
            "  1.8211e-01 -5.8300e-01 -2.0733e-01  2.8411e-01 -3.5269e-01 -1.2422e-03\n",
            " -1.7660e-01 -6.9418e-01 -2.7758e-01  3.6022e-01 -1.7472e-01 -2.9792e-01\n",
            "  4.5945e-01  1.3176e-01 -2.2119e-01 -1.0709e-01  1.6470e-02  1.5636e-01\n",
            "  4.0296e-01 -7.1640e-01  4.4003e-01 -2.0855e-01 -5.1675e-01  3.3292e-01\n",
            "  2.5018e-01 -5.7151e-01 -7.5581e-04 -8.8453e-02 -4.6790e-01 -6.3341e-01\n",
            "  1.7374e-01 -1.2076e-01  5.9592e-01 -2.6351e-02 -1.7858e-02  1.2978e-01\n",
            "  2.4669e-01  9.1323e-02 -1.4112e-01  4.6466e-02  1.8030e-01  1.7382e-01\n",
            " -7.7972e-02 -1.4600e-01 -5.1364e-01  5.1154e-01 -3.3271e-01  5.2346e-01\n",
            " -9.4829e-02 -2.0365e-01  5.6919e-01 -1.5709e-01 -5.4340e-01  2.4034e-01\n",
            " -4.5061e-02  1.5918e-01 -7.0530e-01 -7.9981e-03  5.1987e-01 -1.6802e-01\n",
            " -8.0854e-03  2.4719e-01  3.6062e-01 -2.2302e-01 -3.2196e-01 -7.6371e-01\n",
            "  1.9203e-02  2.0398e-01 -4.4568e-01  1.1332e-01 -1.3784e-01 -5.6301e-02\n",
            "  5.5306e-01  4.6183e-01 -8.0710e-01 -4.1624e-01 -5.1206e-01 -8.1953e-01\n",
            "  7.8391e-03  2.8204e-02  2.0151e-01  4.5986e-01  2.0020e-01 -9.1094e-02\n",
            "  4.3782e-01  3.4559e-01  3.6562e-01  3.4960e-01  1.7984e-01 -2.3978e-01\n",
            " -2.5039e-01  6.7002e-03  1.0974e-01  8.1626e-02 -2.4783e-01  2.6453e-01\n",
            " -3.6779e-02  3.1099e-01  6.7982e-01 -4.6699e-01 -2.8060e-01  8.2703e-01\n",
            "  2.3553e-01 -7.4127e-01  2.9891e-02 -1.3198e-01  2.2106e-01  1.7262e-01\n",
            " -4.2037e-01  5.6484e-01 -7.0211e-01 -1.5537e-01 -8.0067e-02 -6.9698e-02\n",
            "  8.0176e-01 -2.4841e-01 -7.1711e-01 -2.5340e-01  7.2812e-01  1.6527e-01\n",
            " -2.2780e-01 -3.2008e-01  2.8609e-01 -5.8733e-02 -5.4448e-01  2.6380e-01\n",
            "  3.3366e-01 -5.1100e-01 -1.0377e-01 -1.9413e-01 -3.9855e-01  2.2238e-01]\n",
            "dog:  [-1.1043e-01  8.1217e-01  7.3668e-02  1.9023e-01 -5.2888e-02  6.1468e-02\n",
            "  1.6076e-01  4.1302e-01 -3.0199e-01 -9.0827e-01  2.7504e-01 -3.1890e-02\n",
            " -2.8842e-01  2.3447e-01  4.7679e-01  5.0124e-01  2.9371e-01  2.7029e-01\n",
            "  5.4745e-02  9.8038e-02  5.7116e-01  3.6755e-01  4.0734e-02  3.4347e-01\n",
            " -1.8256e-01 -2.8935e-01  2.3826e-02 -1.9401e-01  2.4444e-01  1.3407e-01\n",
            " -1.6494e-01 -2.6983e-01 -2.6234e-01 -2.1779e-01 -8.7528e-01  7.3822e-01\n",
            " -8.7931e-02 -1.0876e-02 -2.6540e-01  3.4668e-01 -5.5814e-01  1.7591e-01\n",
            "  1.6926e-01 -1.5725e-01 -5.0430e-01 -2.0100e-01  6.6701e-01 -3.2518e-02\n",
            "  4.5012e-02  6.5675e-02 -1.6061e-01 -7.3363e-01  2.4642e-01  3.4325e-01\n",
            "  2.1899e-01  4.8646e-02 -5.9987e-01 -5.8153e-02 -5.1694e-02 -5.7846e-01\n",
            "  3.0000e-01  3.5078e-01  4.6646e-01 -7.5309e-03  1.0455e-01 -5.1016e-01\n",
            " -5.5987e-02 -1.0295e-01 -2.6476e-01 -4.1230e-02 -2.8371e-02  5.1979e-01\n",
            " -3.4849e-01 -4.7217e-01 -3.7229e-01 -3.2790e-02  1.3989e-01  3.5716e-01\n",
            "  1.9305e-01 -2.1986e-01  2.4136e-01  4.0976e-01  3.7516e-01  1.4255e-01\n",
            " -3.4143e-02 -7.2653e-01 -1.0832e-01  6.8616e-01 -2.6335e-01 -4.2345e-01\n",
            " -2.4253e-01  1.5778e-01  1.4258e-01 -3.2749e-01 -3.4699e-01  1.6148e-01\n",
            "  1.9603e-01  4.1639e-01 -2.3370e-01  7.5816e-02  1.5899e-01  1.6623e-03\n",
            " -4.8301e-02 -1.0611e-01 -1.9326e-01  1.4494e-01  1.5406e-02  1.0629e-01\n",
            " -3.6699e-02  6.3230e-01  1.2986e-01  4.9902e-01 -1.1323e+00 -1.2636e-01\n",
            "  6.4718e-02  1.2374e-01 -4.9712e-01 -1.4836e-02  1.0488e-01 -4.9818e-01\n",
            " -2.8856e-01  3.8949e-01 -3.1828e-02 -2.8625e-01 -9.8758e-02 -7.6990e-02\n",
            " -2.4234e-01  7.5793e-01  3.4835e-01 -7.1030e-01  4.5318e-01 -3.4418e-01\n",
            " -1.9459e-01  6.1478e-01 -2.9010e-02 -2.7864e-01  3.8556e-01  1.0072e-01\n",
            "  1.2895e-01  1.7992e-02  3.3670e-01  2.0698e-01 -3.8049e-01 -6.6661e-03\n",
            "  1.1540e-01 -8.5268e-02 -1.4608e-01  4.4514e-01 -9.3674e-02  2.3639e-01\n",
            " -1.1447e-01  1.0948e+00 -5.7823e-02 -1.6295e-01  5.5880e-01 -1.8988e-02\n",
            " -7.1374e-02  2.1319e-01  6.1277e-02  7.2759e-01  6.2747e-01 -1.9280e-01\n",
            "  1.3057e-01  1.7426e-01 -1.0229e-01  1.5232e-01  5.2500e-01 -2.1919e-01\n",
            " -2.7185e-01 -5.4186e-01  3.1752e-01  1.6375e-01 -2.9039e-01  1.7074e-01\n",
            " -3.1814e-01 -9.6421e-01 -1.1610e-01 -2.9951e-01  1.8686e-01 -4.5986e-01\n",
            "  4.1633e-01 -1.7583e-01 -3.4583e-01 -2.7244e-01 -5.0216e-01  1.2852e-02\n",
            "  5.9838e-01 -1.1237e-01  2.4697e-01 -4.9048e-01 -4.4188e-01 -1.6255e-01\n",
            " -7.3313e-01 -3.7677e-01 -6.8925e-01  6.1174e-02 -4.2101e-01 -1.3153e-01\n",
            " -8.3590e-03 -1.8360e-02  1.3686e+00  4.6169e-02  9.4622e-01 -1.5126e-02\n",
            " -1.2477e-01  4.8754e-01  2.2384e-01 -2.1820e-01 -2.3389e-01  1.5207e-01\n",
            " -2.8718e-01 -6.3908e-01 -2.2383e-01 -1.8014e-01 -3.3548e-01  5.3587e-01\n",
            " -2.9367e-01  1.0866e-01  6.3411e-02 -9.3424e-03 -1.5886e-01  2.2602e-01\n",
            "  1.1925e-01 -4.1442e-01 -7.8062e-02 -9.7857e-02  2.7938e-01 -1.8348e-01\n",
            " -3.4584e-01  1.8489e-01  1.7402e-01 -5.2198e-01 -4.3306e-01  1.6256e-01\n",
            "  1.4032e-01  3.5124e-01 -1.8280e-01 -3.5984e-01 -1.3009e-01  1.6304e-01\n",
            "  3.1734e-01  3.7716e-03 -4.5498e-02 -4.2066e-01 -4.4419e-01 -6.8985e-01\n",
            " -4.9359e-01  7.0281e-02 -1.4377e-01  6.2508e-01 -5.6311e-02  1.8850e-01\n",
            " -5.6785e-02  1.4052e-01  1.1973e+00  7.1894e-01  5.4332e-01 -1.2461e-01\n",
            " -1.1978e-01  3.0163e-01 -1.6273e-01 -4.6740e-02 -2.5249e-01 -3.0659e-02\n",
            " -3.2271e-01  3.2361e-01  3.3244e-01 -2.7819e-02 -3.3367e-01 -2.3444e-02\n",
            " -5.0394e-01 -2.0587e-01 -1.3013e-01 -3.5884e-01  4.5384e-02 -1.1863e-01\n",
            " -1.7257e+00  3.9441e-01 -5.3179e-01  5.8209e-01 -6.5771e-01  3.6849e-01\n",
            "  2.3518e-01  1.0802e-01 -8.3159e-01  6.1486e-01  2.5547e-01 -4.5289e-01\n",
            "  5.1446e-01 -1.7911e-01 -1.2389e-01  1.8688e-01 -4.1102e-01 -7.0877e-01\n",
            " -3.7501e-01 -6.6152e-01  6.7730e-01  3.3936e-01  5.7994e-01  6.8149e-02]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhnv8p_JDkV0",
        "outputId": "9198e0f6-61fc-4ba4-a154-af0f834d7d38"
      },
      "source": [
        "# -----------------------------------------------------\n",
        "# convert positive/negative documents into numpy array\n",
        "# note that reviews vary from 22 to 1052 words   \n",
        "# so we use the first 20 and last 20 words of each review \n",
        "# as our word sequences for analysis\n",
        "# -----------------------------------------------------\n",
        "max_review_length = 0  # initialize\n",
        "for doc in negative_documents:\n",
        "    max_review_length = max(max_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    max_review_length = max(max_review_length, len(doc)) \n",
        "print('max_review_length:', max_review_length) \n",
        "\n",
        "min_review_length = max_review_length  # initialize\n",
        "for doc in negative_documents:\n",
        "    min_review_length = min(min_review_length, len(doc))    \n",
        "for doc in positive_documents:\n",
        "    min_review_length = min(min_review_length, len(doc)) \n",
        "print('min_review_length:', min_review_length) \n",
        "\n",
        "# construct list of 1000 lists with 40 words in each list\n",
        "from itertools import chain\n",
        "documents = []\n",
        "for doc in negative_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))    \n",
        "for doc in positive_documents:\n",
        "    doc_begin = doc[0:20]\n",
        "    doc_end = doc[len(doc) - 20: len(doc)]\n",
        "    documents.append(list(chain(*[doc_begin, doc_end])))    \n",
        "\n",
        "# create list of lists of lists for embeddings\n",
        "embeddings = []    \n",
        "for doc in documents:\n",
        "    embedding = []\n",
        "    for word in doc:\n",
        "       embedding.append(limited_index_to_embedding[limited_word_to_index[word]]) \n",
        "    embeddings.append(embedding)\n",
        "    \n",
        "# embeddings"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_review_length: 1052\n",
            "min_review_length: 22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPCcCDp8DkV1",
        "outputId": "84dbfcde-bad7-4eb1-ba49-40bee8ca98e7"
      },
      "source": [
        "# -----------------------------------------------------    \n",
        "# Check on the embeddings list of list of lists \n",
        "# -----------------------------------------------------\n",
        "# Show the first word in the first document\n",
        "test_word = documents[0][0]    \n",
        "print('First word in first document:', test_word)    \n",
        "print('Embedding for this word:\\n', \n",
        "      limited_index_to_embedding[limited_word_to_index[test_word]])\n",
        "print('Corresponding embedding from embeddings list of list of lists\\n',\n",
        "      embeddings[0][0][:])\n",
        "\n",
        "# Show the seventh word in the tenth document\n",
        "test_word = documents[6][9]    \n",
        "print('First word in first document:', test_word)    \n",
        "print('Embedding for this word:\\n', \n",
        "      limited_index_to_embedding[limited_word_to_index[test_word]])\n",
        "print('Corresponding embedding from embeddings list of list of lists\\n',\n",
        "      embeddings[6][9][:])\n",
        "\n",
        "# Show the last word in the last document\n",
        "test_word = documents[999][39]    \n",
        "print('First word in first document:', test_word)    \n",
        "print('Embedding for this word:\\n', \n",
        "      limited_index_to_embedding[limited_word_to_index[test_word]])\n",
        "print('Corresponding embedding from embeddings list of list of lists\\n',\n",
        "      embeddings[999][39][:])        "
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First word in first document: it\n",
            "Embedding for this word:\n",
            " [ 3.3284e-02 -4.0754e-02 -4.8377e-02  1.2017e-01 -1.3915e-01 -1.7694e-01\n",
            " -6.2908e-02  1.7056e-01  2.0077e-01 -2.4287e+00  4.0703e-01 -9.9281e-02\n",
            "  7.2288e-02  2.1508e-01  2.4937e-01  2.5853e-01 -6.6372e-01  2.2472e-01\n",
            "  2.5758e-01 -1.7459e-01  3.5456e-01  7.4112e-01  1.4282e-01  2.6240e-01\n",
            " -6.3519e-01 -1.1300e-01 -1.2607e-01 -1.7486e-01 -3.3581e-01  3.0123e-01\n",
            "  3.0055e-02  5.0420e-01 -4.9208e-01 -1.9790e-02 -8.6798e-01  1.8906e-01\n",
            " -1.4333e-01  1.2869e-01 -2.4102e-01 -1.5733e-01  1.4114e-01 -2.3983e-02\n",
            " -1.8256e-01  1.9093e-01  3.8730e-01  3.6151e-01  3.9893e-01 -3.3628e-02\n",
            " -1.3357e-03  2.7212e-02 -1.5565e-01  4.9335e-02 -6.7375e-03 -1.1839e-01\n",
            " -2.5112e-01  7.7261e-02  1.0928e-01  3.1826e-01  3.0289e-01 -1.0824e-01\n",
            "  1.4565e-01 -1.1714e-02  1.3254e-01  2.5120e-02 -8.5447e-02 -5.8705e-01\n",
            "  4.5260e-02  1.5113e-01  2.0622e-01 -1.0576e-02  4.1560e-02 -4.3666e-02\n",
            "  1.2812e-02  5.6017e-01  2.4370e-03 -1.9418e-01  1.5809e-01  2.3800e-01\n",
            " -2.8004e-01  1.7902e-01 -5.0701e-01 -1.2564e-01  2.2921e-01  3.8399e-02\n",
            "  4.3865e-01  2.1877e-01 -1.2866e-01  2.4962e-01  7.3349e-02  2.4244e-01\n",
            " -3.3333e-01  3.6894e-01  2.4531e-02 -3.1091e-01 -1.6011e-01 -1.0162e-01\n",
            " -5.5647e-01  1.6483e-01 -1.8894e-01 -2.9003e-01  3.5750e-01 -8.8686e-02\n",
            " -1.6001e-01 -7.5006e-02  1.5644e-01 -1.1019e-01 -9.0256e-02  4.4778e-02\n",
            " -1.3956e-01  4.8925e-01 -1.8615e-01 -4.3215e-01 -2.8625e-01 -4.0695e-01\n",
            " -3.3083e-02  4.9212e-02 -3.0505e-01 -5.4375e-02  3.2744e-01 -3.8276e-01\n",
            " -2.3654e-01 -3.3828e-01  6.0812e-02  2.2109e-01 -7.0865e-02 -2.9227e-01\n",
            "  2.7939e-01  3.4040e-01 -6.2571e-02  1.4745e-01  4.4940e-01  1.4379e-01\n",
            "  4.0838e-01 -2.0624e-01 -1.5140e-01  1.1336e-01 -1.8322e-02 -6.2837e-02\n",
            " -5.7378e-02  1.5515e-01 -1.8452e-01  2.8504e-01 -1.2027e-01  4.2864e-02\n",
            " -7.5146e-01 -5.4257e-01  2.0493e-01  1.8292e-02 -2.8326e-01  1.3001e-01\n",
            " -2.6985e-01 -5.9708e-02  1.0544e-01 -3.2074e-01  3.7084e-01  2.7499e-01\n",
            " -1.2890e-02  9.3589e-02  3.6826e-02  8.7546e-02  1.1627e-01 -4.4689e-01\n",
            " -1.9197e-01 -1.3519e-01  4.0186e-02  5.7983e-02  7.9410e-02  3.3099e-01\n",
            "  1.8328e-01  1.1349e-01  1.8865e-02 -1.8187e-02 -6.9136e-01  2.6210e-01\n",
            "  1.6679e-01 -4.4771e-02 -2.7263e-01 -3.5347e-02  9.7969e-02  1.1006e-01\n",
            "  2.7094e-01  7.5156e-02  3.2314e-01 -1.0247e-01  3.9139e-01 -1.8149e-01\n",
            " -1.7153e-01 -9.7689e-02 -4.9381e-02  2.1734e-01 -3.6354e-02  2.6657e-01\n",
            "  3.2800e-01 -2.4923e-01 -1.8902e-01 -1.5799e-01 -9.5551e-02  1.1969e-01\n",
            "  1.6522e-01 -1.4670e-01  1.0909e+00 -4.8956e-01 -3.0497e-01 -2.5222e-01\n",
            "  1.0357e-02  2.6115e-01 -1.7184e-02 -2.1640e-01 -2.8018e-01 -3.9493e-01\n",
            " -3.0610e-01 -1.9881e-01  2.5107e-01  2.3895e-01  5.3286e-02  4.6876e-02\n",
            " -1.5066e-01  1.8805e-01 -2.3810e-01  7.2075e-02  7.4246e-02  1.0051e-01\n",
            " -4.8924e-01  2.4402e-01  1.7252e-01 -1.6709e-02  3.3460e-01 -3.7864e-02\n",
            "  7.4991e-02 -5.7255e-02  4.9690e-02 -5.4617e-02 -1.5873e-01 -1.3856e-01\n",
            " -1.8037e-01 -2.0470e-02  9.3404e-02 -1.0968e-01  1.8737e-01 -9.1064e-02\n",
            "  2.5560e-01 -1.2483e-01  5.0991e-01 -3.1007e-02 -6.6628e-01 -4.6616e-02\n",
            "  2.9607e-01  9.4352e-02 -5.6352e-02 -4.1199e-01 -4.6639e-02 -2.1880e-01\n",
            " -4.5296e-01  7.7997e-03  2.7725e-01 -1.7912e-01 -1.4488e-01 -2.5470e-01\n",
            "  3.7993e-01 -2.4450e-01 -1.9020e-01 -4.5530e-02 -9.6199e-02  1.4147e-01\n",
            "  3.5747e-02  5.1315e-02 -1.2186e-02 -2.1784e-01  3.3448e-01  3.8657e-03\n",
            "  1.7195e-01 -1.9242e-01 -1.6028e-01  3.8035e-01  1.8887e-01  1.1157e-01\n",
            " -2.2484e+00 -4.2740e-01  5.8428e-01  2.0266e-01 -2.2752e-01  8.1917e-02\n",
            "  1.3578e-01 -2.2877e-01 -1.5087e-01  6.7262e-02 -1.8536e-01  1.7819e-01\n",
            " -1.0328e-01  1.8844e-01  9.1222e-02 -4.0200e-01  1.5430e-01  2.3099e-01\n",
            "  8.6138e-02 -2.4281e-03  6.5196e-02 -1.5408e-01  1.7806e-01 -1.9683e-01]\n",
            "Corresponding embedding from embeddings list of list of lists\n",
            " [ 3.3284e-02 -4.0754e-02 -4.8377e-02  1.2017e-01 -1.3915e-01 -1.7694e-01\n",
            " -6.2908e-02  1.7056e-01  2.0077e-01 -2.4287e+00  4.0703e-01 -9.9281e-02\n",
            "  7.2288e-02  2.1508e-01  2.4937e-01  2.5853e-01 -6.6372e-01  2.2472e-01\n",
            "  2.5758e-01 -1.7459e-01  3.5456e-01  7.4112e-01  1.4282e-01  2.6240e-01\n",
            " -6.3519e-01 -1.1300e-01 -1.2607e-01 -1.7486e-01 -3.3581e-01  3.0123e-01\n",
            "  3.0055e-02  5.0420e-01 -4.9208e-01 -1.9790e-02 -8.6798e-01  1.8906e-01\n",
            " -1.4333e-01  1.2869e-01 -2.4102e-01 -1.5733e-01  1.4114e-01 -2.3983e-02\n",
            " -1.8256e-01  1.9093e-01  3.8730e-01  3.6151e-01  3.9893e-01 -3.3628e-02\n",
            " -1.3357e-03  2.7212e-02 -1.5565e-01  4.9335e-02 -6.7375e-03 -1.1839e-01\n",
            " -2.5112e-01  7.7261e-02  1.0928e-01  3.1826e-01  3.0289e-01 -1.0824e-01\n",
            "  1.4565e-01 -1.1714e-02  1.3254e-01  2.5120e-02 -8.5447e-02 -5.8705e-01\n",
            "  4.5260e-02  1.5113e-01  2.0622e-01 -1.0576e-02  4.1560e-02 -4.3666e-02\n",
            "  1.2812e-02  5.6017e-01  2.4370e-03 -1.9418e-01  1.5809e-01  2.3800e-01\n",
            " -2.8004e-01  1.7902e-01 -5.0701e-01 -1.2564e-01  2.2921e-01  3.8399e-02\n",
            "  4.3865e-01  2.1877e-01 -1.2866e-01  2.4962e-01  7.3349e-02  2.4244e-01\n",
            " -3.3333e-01  3.6894e-01  2.4531e-02 -3.1091e-01 -1.6011e-01 -1.0162e-01\n",
            " -5.5647e-01  1.6483e-01 -1.8894e-01 -2.9003e-01  3.5750e-01 -8.8686e-02\n",
            " -1.6001e-01 -7.5006e-02  1.5644e-01 -1.1019e-01 -9.0256e-02  4.4778e-02\n",
            " -1.3956e-01  4.8925e-01 -1.8615e-01 -4.3215e-01 -2.8625e-01 -4.0695e-01\n",
            " -3.3083e-02  4.9212e-02 -3.0505e-01 -5.4375e-02  3.2744e-01 -3.8276e-01\n",
            " -2.3654e-01 -3.3828e-01  6.0812e-02  2.2109e-01 -7.0865e-02 -2.9227e-01\n",
            "  2.7939e-01  3.4040e-01 -6.2571e-02  1.4745e-01  4.4940e-01  1.4379e-01\n",
            "  4.0838e-01 -2.0624e-01 -1.5140e-01  1.1336e-01 -1.8322e-02 -6.2837e-02\n",
            " -5.7378e-02  1.5515e-01 -1.8452e-01  2.8504e-01 -1.2027e-01  4.2864e-02\n",
            " -7.5146e-01 -5.4257e-01  2.0493e-01  1.8292e-02 -2.8326e-01  1.3001e-01\n",
            " -2.6985e-01 -5.9708e-02  1.0544e-01 -3.2074e-01  3.7084e-01  2.7499e-01\n",
            " -1.2890e-02  9.3589e-02  3.6826e-02  8.7546e-02  1.1627e-01 -4.4689e-01\n",
            " -1.9197e-01 -1.3519e-01  4.0186e-02  5.7983e-02  7.9410e-02  3.3099e-01\n",
            "  1.8328e-01  1.1349e-01  1.8865e-02 -1.8187e-02 -6.9136e-01  2.6210e-01\n",
            "  1.6679e-01 -4.4771e-02 -2.7263e-01 -3.5347e-02  9.7969e-02  1.1006e-01\n",
            "  2.7094e-01  7.5156e-02  3.2314e-01 -1.0247e-01  3.9139e-01 -1.8149e-01\n",
            " -1.7153e-01 -9.7689e-02 -4.9381e-02  2.1734e-01 -3.6354e-02  2.6657e-01\n",
            "  3.2800e-01 -2.4923e-01 -1.8902e-01 -1.5799e-01 -9.5551e-02  1.1969e-01\n",
            "  1.6522e-01 -1.4670e-01  1.0909e+00 -4.8956e-01 -3.0497e-01 -2.5222e-01\n",
            "  1.0357e-02  2.6115e-01 -1.7184e-02 -2.1640e-01 -2.8018e-01 -3.9493e-01\n",
            " -3.0610e-01 -1.9881e-01  2.5107e-01  2.3895e-01  5.3286e-02  4.6876e-02\n",
            " -1.5066e-01  1.8805e-01 -2.3810e-01  7.2075e-02  7.4246e-02  1.0051e-01\n",
            " -4.8924e-01  2.4402e-01  1.7252e-01 -1.6709e-02  3.3460e-01 -3.7864e-02\n",
            "  7.4991e-02 -5.7255e-02  4.9690e-02 -5.4617e-02 -1.5873e-01 -1.3856e-01\n",
            " -1.8037e-01 -2.0470e-02  9.3404e-02 -1.0968e-01  1.8737e-01 -9.1064e-02\n",
            "  2.5560e-01 -1.2483e-01  5.0991e-01 -3.1007e-02 -6.6628e-01 -4.6616e-02\n",
            "  2.9607e-01  9.4352e-02 -5.6352e-02 -4.1199e-01 -4.6639e-02 -2.1880e-01\n",
            " -4.5296e-01  7.7997e-03  2.7725e-01 -1.7912e-01 -1.4488e-01 -2.5470e-01\n",
            "  3.7993e-01 -2.4450e-01 -1.9020e-01 -4.5530e-02 -9.6199e-02  1.4147e-01\n",
            "  3.5747e-02  5.1315e-02 -1.2186e-02 -2.1784e-01  3.3448e-01  3.8657e-03\n",
            "  1.7195e-01 -1.9242e-01 -1.6028e-01  3.8035e-01  1.8887e-01  1.1157e-01\n",
            " -2.2484e+00 -4.2740e-01  5.8428e-01  2.0266e-01 -2.2752e-01  8.1917e-02\n",
            "  1.3578e-01 -2.2877e-01 -1.5087e-01  6.7262e-02 -1.8536e-01  1.7819e-01\n",
            " -1.0328e-01  1.8844e-01  9.1222e-02 -4.0200e-01  1.5430e-01  2.3099e-01\n",
            "  8.6138e-02 -2.4281e-03  6.5196e-02 -1.5408e-01  1.7806e-01 -1.9683e-01]\n",
            "First word in first document: imdb\n",
            "Embedding for this word:\n",
            " [ 3.2987e-01  1.2488e-01 -6.8460e-02  4.8648e-02  1.9817e-01  1.0649e-01\n",
            " -3.5121e-01 -5.3906e-01  1.2055e-01  9.2790e-01  1.8102e-01  5.8950e-01\n",
            "  3.4639e-01  3.3407e-01 -9.5844e-01  1.1282e-01 -6.0486e-01  1.7534e-01\n",
            " -3.0254e-01 -3.3947e-01 -2.3796e-01  2.7517e-01 -3.5215e-01 -3.1066e-01\n",
            "  1.4996e-01  5.3321e-01 -1.7695e-01  3.1746e-01  1.1651e-01 -5.6667e-01\n",
            " -1.1733e+00 -1.3056e-01  3.2173e-01  1.3362e-01  2.1065e-01 -2.0648e-01\n",
            " -4.9941e-01 -6.6711e-02 -1.7990e-01 -5.3635e-01  5.2271e-01 -4.3340e-01\n",
            "  2.5311e-01  7.6217e-01 -8.6687e-02  1.6343e-04 -6.7526e-02 -3.9473e-01\n",
            " -4.3243e-01 -7.9435e-01  5.6707e-02  7.1820e-02  7.3976e-01 -9.8761e-01\n",
            "  4.4489e-01  2.4698e-01  3.5966e-01 -3.2106e-01 -6.5959e-01 -2.9089e-01\n",
            " -4.1307e-01  3.9249e-01 -1.0974e-01  3.2027e-01  8.1066e-02 -5.0699e-01\n",
            "  1.1824e-02  1.2024e-01  1.3475e-01  5.1009e-01  5.9881e-01  3.3175e-01\n",
            "  1.0754e-01  1.2857e-01 -1.5136e-01 -9.3311e-02  3.7563e-01 -9.9312e-02\n",
            "  6.2201e-02  4.2232e-01  2.3106e-01 -4.1309e-01  3.0633e-01 -8.8796e-02\n",
            "  1.1454e-01  6.7324e-01 -1.8274e-01 -3.8499e-01  2.7726e-01 -2.7510e-01\n",
            " -5.2550e-01 -7.6729e-01 -1.4429e-01 -1.2605e-01 -4.3526e-02  3.1367e-01\n",
            " -6.2674e-01 -1.2997e-01  1.5994e-01 -3.1504e-01 -3.5710e-01 -5.6822e-02\n",
            "  9.6805e-01  1.7232e-01 -2.3212e-01 -4.4400e-01 -4.7014e-01 -1.2541e-01\n",
            "  4.0340e-01 -5.1195e-01 -1.4251e-01 -3.1946e-02  1.4063e-01 -2.1907e-01\n",
            " -2.5801e-01  5.5518e-02 -6.5711e-02 -2.5251e-01  1.3111e-01 -1.9162e-02\n",
            " -4.7783e-01 -4.9544e-01  4.8814e-01  3.9201e-01  1.3073e-01  2.7454e-01\n",
            "  1.7018e-01 -2.6162e-01 -6.8434e-01 -2.1129e-01 -5.1334e-01  3.9987e-01\n",
            "  2.5235e-01  6.2077e-01  7.7280e-01 -3.4532e-01 -5.6632e-02  3.0524e-01\n",
            " -1.0413e-01  5.5169e-03 -9.2495e-02  9.5877e-02  2.0590e-01 -1.0179e+00\n",
            " -7.8037e-04 -3.4762e-01 -1.7745e-01  7.7203e-02 -2.3392e-01  6.0854e-01\n",
            " -4.4075e-01 -7.0690e-01 -1.1408e-02 -7.1439e-01 -1.3036e-01  3.0149e-01\n",
            "  1.1122e+00  3.3716e-01  2.8395e-01 -1.3932e-01  1.4463e-01  3.4944e-02\n",
            "  2.4699e-01 -1.4129e-01  2.4806e-01 -1.8588e-01 -3.1143e-01 -2.7877e-02\n",
            " -6.4941e-01 -2.3409e-01  2.7998e-01 -5.8887e-01 -4.0050e-01 -7.1326e-01\n",
            "  2.0858e-01 -2.5035e-02 -2.3428e-01  4.5780e-02 -4.3505e-01 -4.2613e-01\n",
            " -8.2784e-01  8.1404e-04  8.0085e-01 -1.0650e-01  7.0774e-01 -7.1375e-01\n",
            "  5.2025e-01 -1.6442e-01  6.1786e-01 -3.0144e-02 -2.2485e-01  1.8237e-01\n",
            "  9.7613e-02 -5.7667e-01  2.3704e-01 -9.4759e-01 -1.0306e-02 -2.5630e-01\n",
            "  1.8427e-01 -3.2511e-01 -6.5489e-01 -3.3952e-01  6.3128e-01 -3.4862e-01\n",
            "  2.1168e-01  3.2476e-01 -7.7586e-02 -3.9367e-01  1.6443e-01  1.2541e-01\n",
            " -1.5439e-01 -5.4468e-01 -4.4309e-01 -4.7373e-01  3.3964e-01 -1.6344e-02\n",
            " -8.1734e-01  1.0136e+00 -1.3501e-01  3.5874e-01 -1.1965e+00  8.0581e-01\n",
            "  7.6289e-02 -3.2870e-01  1.3591e-01  8.7823e-02 -5.1809e-01 -8.2669e-02\n",
            "  4.2504e-01  7.7691e-02  3.0135e-01  2.6845e-01 -2.9945e-01 -3.4096e-01\n",
            "  6.2028e-01 -1.3959e-01  3.2483e-02  7.5565e-01 -4.3143e-01  2.3452e-01\n",
            "  3.9307e-01  1.4720e-01  2.8075e-02 -3.3411e-01  4.7671e-01  3.3166e-01\n",
            " -2.8366e-01  1.0444e+00 -3.3378e-01 -3.2183e-01 -1.8885e-01 -3.2857e-01\n",
            "  6.0769e-01  4.4010e-01 -6.7781e-01 -5.4487e-01 -4.0019e-01  4.7477e-02\n",
            " -1.8370e-01  2.8901e-01  3.8515e-02  6.4988e-01 -5.6625e-03 -3.6840e-01\n",
            "  4.2701e-01 -2.8441e-01  6.4221e-01 -2.7915e-02  2.9971e-01  4.0847e-01\n",
            "  3.7322e-01  1.4493e-02 -8.3073e-02 -2.6366e-01  1.6684e-01 -7.5768e-01\n",
            "  4.6815e-01 -1.2203e+00  1.7425e-01 -3.8583e-01  3.1938e-01 -2.5882e-01\n",
            " -6.5388e-01  1.4525e-01 -4.0011e-01 -4.2063e-01  1.5513e-01 -4.9951e-01\n",
            " -3.5299e-01  3.7435e-01  1.6926e-01  8.9898e-02 -9.0817e-01 -6.6111e-01\n",
            " -5.7273e-01 -8.6414e-01  1.1475e-01 -4.2112e-01  2.3024e-01 -3.5775e-01]\n",
            "Corresponding embedding from embeddings list of list of lists\n",
            " [ 3.2987e-01  1.2488e-01 -6.8460e-02  4.8648e-02  1.9817e-01  1.0649e-01\n",
            " -3.5121e-01 -5.3906e-01  1.2055e-01  9.2790e-01  1.8102e-01  5.8950e-01\n",
            "  3.4639e-01  3.3407e-01 -9.5844e-01  1.1282e-01 -6.0486e-01  1.7534e-01\n",
            " -3.0254e-01 -3.3947e-01 -2.3796e-01  2.7517e-01 -3.5215e-01 -3.1066e-01\n",
            "  1.4996e-01  5.3321e-01 -1.7695e-01  3.1746e-01  1.1651e-01 -5.6667e-01\n",
            " -1.1733e+00 -1.3056e-01  3.2173e-01  1.3362e-01  2.1065e-01 -2.0648e-01\n",
            " -4.9941e-01 -6.6711e-02 -1.7990e-01 -5.3635e-01  5.2271e-01 -4.3340e-01\n",
            "  2.5311e-01  7.6217e-01 -8.6687e-02  1.6343e-04 -6.7526e-02 -3.9473e-01\n",
            " -4.3243e-01 -7.9435e-01  5.6707e-02  7.1820e-02  7.3976e-01 -9.8761e-01\n",
            "  4.4489e-01  2.4698e-01  3.5966e-01 -3.2106e-01 -6.5959e-01 -2.9089e-01\n",
            " -4.1307e-01  3.9249e-01 -1.0974e-01  3.2027e-01  8.1066e-02 -5.0699e-01\n",
            "  1.1824e-02  1.2024e-01  1.3475e-01  5.1009e-01  5.9881e-01  3.3175e-01\n",
            "  1.0754e-01  1.2857e-01 -1.5136e-01 -9.3311e-02  3.7563e-01 -9.9312e-02\n",
            "  6.2201e-02  4.2232e-01  2.3106e-01 -4.1309e-01  3.0633e-01 -8.8796e-02\n",
            "  1.1454e-01  6.7324e-01 -1.8274e-01 -3.8499e-01  2.7726e-01 -2.7510e-01\n",
            " -5.2550e-01 -7.6729e-01 -1.4429e-01 -1.2605e-01 -4.3526e-02  3.1367e-01\n",
            " -6.2674e-01 -1.2997e-01  1.5994e-01 -3.1504e-01 -3.5710e-01 -5.6822e-02\n",
            "  9.6805e-01  1.7232e-01 -2.3212e-01 -4.4400e-01 -4.7014e-01 -1.2541e-01\n",
            "  4.0340e-01 -5.1195e-01 -1.4251e-01 -3.1946e-02  1.4063e-01 -2.1907e-01\n",
            " -2.5801e-01  5.5518e-02 -6.5711e-02 -2.5251e-01  1.3111e-01 -1.9162e-02\n",
            " -4.7783e-01 -4.9544e-01  4.8814e-01  3.9201e-01  1.3073e-01  2.7454e-01\n",
            "  1.7018e-01 -2.6162e-01 -6.8434e-01 -2.1129e-01 -5.1334e-01  3.9987e-01\n",
            "  2.5235e-01  6.2077e-01  7.7280e-01 -3.4532e-01 -5.6632e-02  3.0524e-01\n",
            " -1.0413e-01  5.5169e-03 -9.2495e-02  9.5877e-02  2.0590e-01 -1.0179e+00\n",
            " -7.8037e-04 -3.4762e-01 -1.7745e-01  7.7203e-02 -2.3392e-01  6.0854e-01\n",
            " -4.4075e-01 -7.0690e-01 -1.1408e-02 -7.1439e-01 -1.3036e-01  3.0149e-01\n",
            "  1.1122e+00  3.3716e-01  2.8395e-01 -1.3932e-01  1.4463e-01  3.4944e-02\n",
            "  2.4699e-01 -1.4129e-01  2.4806e-01 -1.8588e-01 -3.1143e-01 -2.7877e-02\n",
            " -6.4941e-01 -2.3409e-01  2.7998e-01 -5.8887e-01 -4.0050e-01 -7.1326e-01\n",
            "  2.0858e-01 -2.5035e-02 -2.3428e-01  4.5780e-02 -4.3505e-01 -4.2613e-01\n",
            " -8.2784e-01  8.1404e-04  8.0085e-01 -1.0650e-01  7.0774e-01 -7.1375e-01\n",
            "  5.2025e-01 -1.6442e-01  6.1786e-01 -3.0144e-02 -2.2485e-01  1.8237e-01\n",
            "  9.7613e-02 -5.7667e-01  2.3704e-01 -9.4759e-01 -1.0306e-02 -2.5630e-01\n",
            "  1.8427e-01 -3.2511e-01 -6.5489e-01 -3.3952e-01  6.3128e-01 -3.4862e-01\n",
            "  2.1168e-01  3.2476e-01 -7.7586e-02 -3.9367e-01  1.6443e-01  1.2541e-01\n",
            " -1.5439e-01 -5.4468e-01 -4.4309e-01 -4.7373e-01  3.3964e-01 -1.6344e-02\n",
            " -8.1734e-01  1.0136e+00 -1.3501e-01  3.5874e-01 -1.1965e+00  8.0581e-01\n",
            "  7.6289e-02 -3.2870e-01  1.3591e-01  8.7823e-02 -5.1809e-01 -8.2669e-02\n",
            "  4.2504e-01  7.7691e-02  3.0135e-01  2.6845e-01 -2.9945e-01 -3.4096e-01\n",
            "  6.2028e-01 -1.3959e-01  3.2483e-02  7.5565e-01 -4.3143e-01  2.3452e-01\n",
            "  3.9307e-01  1.4720e-01  2.8075e-02 -3.3411e-01  4.7671e-01  3.3166e-01\n",
            " -2.8366e-01  1.0444e+00 -3.3378e-01 -3.2183e-01 -1.8885e-01 -3.2857e-01\n",
            "  6.0769e-01  4.4010e-01 -6.7781e-01 -5.4487e-01 -4.0019e-01  4.7477e-02\n",
            " -1.8370e-01  2.8901e-01  3.8515e-02  6.4988e-01 -5.6625e-03 -3.6840e-01\n",
            "  4.2701e-01 -2.8441e-01  6.4221e-01 -2.7915e-02  2.9971e-01  4.0847e-01\n",
            "  3.7322e-01  1.4493e-02 -8.3073e-02 -2.6366e-01  1.6684e-01 -7.5768e-01\n",
            "  4.6815e-01 -1.2203e+00  1.7425e-01 -3.8583e-01  3.1938e-01 -2.5882e-01\n",
            " -6.5388e-01  1.4525e-01 -4.0011e-01 -4.2063e-01  1.5513e-01 -4.9951e-01\n",
            " -3.5299e-01  3.7435e-01  1.6926e-01  8.9898e-02 -9.0817e-01 -6.6111e-01\n",
            " -5.7273e-01 -8.6414e-01  1.1475e-01 -4.2112e-01  2.3024e-01 -3.5775e-01]\n",
            "First word in first document: it\n",
            "Embedding for this word:\n",
            " [ 3.3284e-02 -4.0754e-02 -4.8377e-02  1.2017e-01 -1.3915e-01 -1.7694e-01\n",
            " -6.2908e-02  1.7056e-01  2.0077e-01 -2.4287e+00  4.0703e-01 -9.9281e-02\n",
            "  7.2288e-02  2.1508e-01  2.4937e-01  2.5853e-01 -6.6372e-01  2.2472e-01\n",
            "  2.5758e-01 -1.7459e-01  3.5456e-01  7.4112e-01  1.4282e-01  2.6240e-01\n",
            " -6.3519e-01 -1.1300e-01 -1.2607e-01 -1.7486e-01 -3.3581e-01  3.0123e-01\n",
            "  3.0055e-02  5.0420e-01 -4.9208e-01 -1.9790e-02 -8.6798e-01  1.8906e-01\n",
            " -1.4333e-01  1.2869e-01 -2.4102e-01 -1.5733e-01  1.4114e-01 -2.3983e-02\n",
            " -1.8256e-01  1.9093e-01  3.8730e-01  3.6151e-01  3.9893e-01 -3.3628e-02\n",
            " -1.3357e-03  2.7212e-02 -1.5565e-01  4.9335e-02 -6.7375e-03 -1.1839e-01\n",
            " -2.5112e-01  7.7261e-02  1.0928e-01  3.1826e-01  3.0289e-01 -1.0824e-01\n",
            "  1.4565e-01 -1.1714e-02  1.3254e-01  2.5120e-02 -8.5447e-02 -5.8705e-01\n",
            "  4.5260e-02  1.5113e-01  2.0622e-01 -1.0576e-02  4.1560e-02 -4.3666e-02\n",
            "  1.2812e-02  5.6017e-01  2.4370e-03 -1.9418e-01  1.5809e-01  2.3800e-01\n",
            " -2.8004e-01  1.7902e-01 -5.0701e-01 -1.2564e-01  2.2921e-01  3.8399e-02\n",
            "  4.3865e-01  2.1877e-01 -1.2866e-01  2.4962e-01  7.3349e-02  2.4244e-01\n",
            " -3.3333e-01  3.6894e-01  2.4531e-02 -3.1091e-01 -1.6011e-01 -1.0162e-01\n",
            " -5.5647e-01  1.6483e-01 -1.8894e-01 -2.9003e-01  3.5750e-01 -8.8686e-02\n",
            " -1.6001e-01 -7.5006e-02  1.5644e-01 -1.1019e-01 -9.0256e-02  4.4778e-02\n",
            " -1.3956e-01  4.8925e-01 -1.8615e-01 -4.3215e-01 -2.8625e-01 -4.0695e-01\n",
            " -3.3083e-02  4.9212e-02 -3.0505e-01 -5.4375e-02  3.2744e-01 -3.8276e-01\n",
            " -2.3654e-01 -3.3828e-01  6.0812e-02  2.2109e-01 -7.0865e-02 -2.9227e-01\n",
            "  2.7939e-01  3.4040e-01 -6.2571e-02  1.4745e-01  4.4940e-01  1.4379e-01\n",
            "  4.0838e-01 -2.0624e-01 -1.5140e-01  1.1336e-01 -1.8322e-02 -6.2837e-02\n",
            " -5.7378e-02  1.5515e-01 -1.8452e-01  2.8504e-01 -1.2027e-01  4.2864e-02\n",
            " -7.5146e-01 -5.4257e-01  2.0493e-01  1.8292e-02 -2.8326e-01  1.3001e-01\n",
            " -2.6985e-01 -5.9708e-02  1.0544e-01 -3.2074e-01  3.7084e-01  2.7499e-01\n",
            " -1.2890e-02  9.3589e-02  3.6826e-02  8.7546e-02  1.1627e-01 -4.4689e-01\n",
            " -1.9197e-01 -1.3519e-01  4.0186e-02  5.7983e-02  7.9410e-02  3.3099e-01\n",
            "  1.8328e-01  1.1349e-01  1.8865e-02 -1.8187e-02 -6.9136e-01  2.6210e-01\n",
            "  1.6679e-01 -4.4771e-02 -2.7263e-01 -3.5347e-02  9.7969e-02  1.1006e-01\n",
            "  2.7094e-01  7.5156e-02  3.2314e-01 -1.0247e-01  3.9139e-01 -1.8149e-01\n",
            " -1.7153e-01 -9.7689e-02 -4.9381e-02  2.1734e-01 -3.6354e-02  2.6657e-01\n",
            "  3.2800e-01 -2.4923e-01 -1.8902e-01 -1.5799e-01 -9.5551e-02  1.1969e-01\n",
            "  1.6522e-01 -1.4670e-01  1.0909e+00 -4.8956e-01 -3.0497e-01 -2.5222e-01\n",
            "  1.0357e-02  2.6115e-01 -1.7184e-02 -2.1640e-01 -2.8018e-01 -3.9493e-01\n",
            " -3.0610e-01 -1.9881e-01  2.5107e-01  2.3895e-01  5.3286e-02  4.6876e-02\n",
            " -1.5066e-01  1.8805e-01 -2.3810e-01  7.2075e-02  7.4246e-02  1.0051e-01\n",
            " -4.8924e-01  2.4402e-01  1.7252e-01 -1.6709e-02  3.3460e-01 -3.7864e-02\n",
            "  7.4991e-02 -5.7255e-02  4.9690e-02 -5.4617e-02 -1.5873e-01 -1.3856e-01\n",
            " -1.8037e-01 -2.0470e-02  9.3404e-02 -1.0968e-01  1.8737e-01 -9.1064e-02\n",
            "  2.5560e-01 -1.2483e-01  5.0991e-01 -3.1007e-02 -6.6628e-01 -4.6616e-02\n",
            "  2.9607e-01  9.4352e-02 -5.6352e-02 -4.1199e-01 -4.6639e-02 -2.1880e-01\n",
            " -4.5296e-01  7.7997e-03  2.7725e-01 -1.7912e-01 -1.4488e-01 -2.5470e-01\n",
            "  3.7993e-01 -2.4450e-01 -1.9020e-01 -4.5530e-02 -9.6199e-02  1.4147e-01\n",
            "  3.5747e-02  5.1315e-02 -1.2186e-02 -2.1784e-01  3.3448e-01  3.8657e-03\n",
            "  1.7195e-01 -1.9242e-01 -1.6028e-01  3.8035e-01  1.8887e-01  1.1157e-01\n",
            " -2.2484e+00 -4.2740e-01  5.8428e-01  2.0266e-01 -2.2752e-01  8.1917e-02\n",
            "  1.3578e-01 -2.2877e-01 -1.5087e-01  6.7262e-02 -1.8536e-01  1.7819e-01\n",
            " -1.0328e-01  1.8844e-01  9.1222e-02 -4.0200e-01  1.5430e-01  2.3099e-01\n",
            "  8.6138e-02 -2.4281e-03  6.5196e-02 -1.5408e-01  1.7806e-01 -1.9683e-01]\n",
            "Corresponding embedding from embeddings list of list of lists\n",
            " [ 3.3284e-02 -4.0754e-02 -4.8377e-02  1.2017e-01 -1.3915e-01 -1.7694e-01\n",
            " -6.2908e-02  1.7056e-01  2.0077e-01 -2.4287e+00  4.0703e-01 -9.9281e-02\n",
            "  7.2288e-02  2.1508e-01  2.4937e-01  2.5853e-01 -6.6372e-01  2.2472e-01\n",
            "  2.5758e-01 -1.7459e-01  3.5456e-01  7.4112e-01  1.4282e-01  2.6240e-01\n",
            " -6.3519e-01 -1.1300e-01 -1.2607e-01 -1.7486e-01 -3.3581e-01  3.0123e-01\n",
            "  3.0055e-02  5.0420e-01 -4.9208e-01 -1.9790e-02 -8.6798e-01  1.8906e-01\n",
            " -1.4333e-01  1.2869e-01 -2.4102e-01 -1.5733e-01  1.4114e-01 -2.3983e-02\n",
            " -1.8256e-01  1.9093e-01  3.8730e-01  3.6151e-01  3.9893e-01 -3.3628e-02\n",
            " -1.3357e-03  2.7212e-02 -1.5565e-01  4.9335e-02 -6.7375e-03 -1.1839e-01\n",
            " -2.5112e-01  7.7261e-02  1.0928e-01  3.1826e-01  3.0289e-01 -1.0824e-01\n",
            "  1.4565e-01 -1.1714e-02  1.3254e-01  2.5120e-02 -8.5447e-02 -5.8705e-01\n",
            "  4.5260e-02  1.5113e-01  2.0622e-01 -1.0576e-02  4.1560e-02 -4.3666e-02\n",
            "  1.2812e-02  5.6017e-01  2.4370e-03 -1.9418e-01  1.5809e-01  2.3800e-01\n",
            " -2.8004e-01  1.7902e-01 -5.0701e-01 -1.2564e-01  2.2921e-01  3.8399e-02\n",
            "  4.3865e-01  2.1877e-01 -1.2866e-01  2.4962e-01  7.3349e-02  2.4244e-01\n",
            " -3.3333e-01  3.6894e-01  2.4531e-02 -3.1091e-01 -1.6011e-01 -1.0162e-01\n",
            " -5.5647e-01  1.6483e-01 -1.8894e-01 -2.9003e-01  3.5750e-01 -8.8686e-02\n",
            " -1.6001e-01 -7.5006e-02  1.5644e-01 -1.1019e-01 -9.0256e-02  4.4778e-02\n",
            " -1.3956e-01  4.8925e-01 -1.8615e-01 -4.3215e-01 -2.8625e-01 -4.0695e-01\n",
            " -3.3083e-02  4.9212e-02 -3.0505e-01 -5.4375e-02  3.2744e-01 -3.8276e-01\n",
            " -2.3654e-01 -3.3828e-01  6.0812e-02  2.2109e-01 -7.0865e-02 -2.9227e-01\n",
            "  2.7939e-01  3.4040e-01 -6.2571e-02  1.4745e-01  4.4940e-01  1.4379e-01\n",
            "  4.0838e-01 -2.0624e-01 -1.5140e-01  1.1336e-01 -1.8322e-02 -6.2837e-02\n",
            " -5.7378e-02  1.5515e-01 -1.8452e-01  2.8504e-01 -1.2027e-01  4.2864e-02\n",
            " -7.5146e-01 -5.4257e-01  2.0493e-01  1.8292e-02 -2.8326e-01  1.3001e-01\n",
            " -2.6985e-01 -5.9708e-02  1.0544e-01 -3.2074e-01  3.7084e-01  2.7499e-01\n",
            " -1.2890e-02  9.3589e-02  3.6826e-02  8.7546e-02  1.1627e-01 -4.4689e-01\n",
            " -1.9197e-01 -1.3519e-01  4.0186e-02  5.7983e-02  7.9410e-02  3.3099e-01\n",
            "  1.8328e-01  1.1349e-01  1.8865e-02 -1.8187e-02 -6.9136e-01  2.6210e-01\n",
            "  1.6679e-01 -4.4771e-02 -2.7263e-01 -3.5347e-02  9.7969e-02  1.1006e-01\n",
            "  2.7094e-01  7.5156e-02  3.2314e-01 -1.0247e-01  3.9139e-01 -1.8149e-01\n",
            " -1.7153e-01 -9.7689e-02 -4.9381e-02  2.1734e-01 -3.6354e-02  2.6657e-01\n",
            "  3.2800e-01 -2.4923e-01 -1.8902e-01 -1.5799e-01 -9.5551e-02  1.1969e-01\n",
            "  1.6522e-01 -1.4670e-01  1.0909e+00 -4.8956e-01 -3.0497e-01 -2.5222e-01\n",
            "  1.0357e-02  2.6115e-01 -1.7184e-02 -2.1640e-01 -2.8018e-01 -3.9493e-01\n",
            " -3.0610e-01 -1.9881e-01  2.5107e-01  2.3895e-01  5.3286e-02  4.6876e-02\n",
            " -1.5066e-01  1.8805e-01 -2.3810e-01  7.2075e-02  7.4246e-02  1.0051e-01\n",
            " -4.8924e-01  2.4402e-01  1.7252e-01 -1.6709e-02  3.3460e-01 -3.7864e-02\n",
            "  7.4991e-02 -5.7255e-02  4.9690e-02 -5.4617e-02 -1.5873e-01 -1.3856e-01\n",
            " -1.8037e-01 -2.0470e-02  9.3404e-02 -1.0968e-01  1.8737e-01 -9.1064e-02\n",
            "  2.5560e-01 -1.2483e-01  5.0991e-01 -3.1007e-02 -6.6628e-01 -4.6616e-02\n",
            "  2.9607e-01  9.4352e-02 -5.6352e-02 -4.1199e-01 -4.6639e-02 -2.1880e-01\n",
            " -4.5296e-01  7.7997e-03  2.7725e-01 -1.7912e-01 -1.4488e-01 -2.5470e-01\n",
            "  3.7993e-01 -2.4450e-01 -1.9020e-01 -4.5530e-02 -9.6199e-02  1.4147e-01\n",
            "  3.5747e-02  5.1315e-02 -1.2186e-02 -2.1784e-01  3.3448e-01  3.8657e-03\n",
            "  1.7195e-01 -1.9242e-01 -1.6028e-01  3.8035e-01  1.8887e-01  1.1157e-01\n",
            " -2.2484e+00 -4.2740e-01  5.8428e-01  2.0266e-01 -2.2752e-01  8.1917e-02\n",
            "  1.3578e-01 -2.2877e-01 -1.5087e-01  6.7262e-02 -1.8536e-01  1.7819e-01\n",
            " -1.0328e-01  1.8844e-01  9.1222e-02 -4.0200e-01  1.5430e-01  2.3099e-01\n",
            "  8.6138e-02 -2.4281e-03  6.5196e-02 -1.5408e-01  1.7806e-01 -1.9683e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ym8YPK5DkV1"
      },
      "source": [
        "RANDOM_SEED = 9999\n",
        "# -----------------------------------------------------    \n",
        "# Make embeddings a numpy array for use in an RNN \n",
        "# Create training and test sets with Scikit Learn\n",
        "# -----------------------------------------------------\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Define the labels to be used 500 negative (0) and 500 positive (1)\n",
        "thumbs_down_up = np.concatenate((np.zeros((500), dtype = np.int32), \n",
        "                      np.ones((500), dtype = np.int32)), axis = 0)\n",
        "\n",
        "# Scikit Learn for random splitting of the data  \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Random splitting of the data in to training (80%) and test (20%)  \n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(embeddings_array, thumbs_down_up, test_size=0.20, \n",
        "                     random_state = RANDOM_SEED)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_20t4njbdlpf"
      },
      "source": [
        "Model 2a: simple RNN (300d)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqqWjUXaDkV2",
        "outputId": "985015a8-6fef-4561-d910-db57b593133a"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "\n",
        "learning_rate = 0.001\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "basic_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
        "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)\n",
        "\n",
        "logits = tf.layers.dense(states, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
        "                                                          logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        print('\\n  ---- Epoch ', epoch, ' ----\\n')\n",
        "        for iteration in range(y_train.shape[0] // batch_size):          \n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            print('  Batch ', iteration, ' training observations from ',  \n",
        "                  iteration*batch_size, ' to ', (iteration + 1)*batch_size-1,)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print('\\n  Train accuracy:', acc_train, 'Test accuracy:', acc_test)\n",
        "        \n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "metrics['Model 2a-simple RNN (300d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:421: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  ---- Epoch  0  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.56 Test accuracy: 0.49\n",
            "\n",
            "  ---- Epoch  1  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.63 Test accuracy: 0.555\n",
            "\n",
            "  ---- Epoch  2  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.62 Test accuracy: 0.6\n",
            "\n",
            "  ---- Epoch  3  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.64 Test accuracy: 0.605\n",
            "\n",
            "  ---- Epoch  4  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.66 Test accuracy: 0.595\n",
            "\n",
            "  ---- Epoch  5  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.69 Test accuracy: 0.59\n",
            "\n",
            "  ---- Epoch  6  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.72 Test accuracy: 0.58\n",
            "\n",
            "  ---- Epoch  7  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.73 Test accuracy: 0.575\n",
            "\n",
            "  ---- Epoch  8  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.57\n",
            "\n",
            "  ---- Epoch  9  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.575\n",
            "\n",
            "  ---- Epoch  10  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.76 Test accuracy: 0.59\n",
            "\n",
            "  ---- Epoch  11  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.6\n",
            "\n",
            "  ---- Epoch  12  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.76 Test accuracy: 0.615\n",
            "\n",
            "  ---- Epoch  13  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.75 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  14  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.79 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  15  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.81 Test accuracy: 0.615\n",
            "\n",
            "  ---- Epoch  16  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  17  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  18  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  19  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.83 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  20  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.86 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  21  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  22  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.63\n",
            "\n",
            "  ---- Epoch  23  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.615\n",
            "\n",
            "  ---- Epoch  24  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.62\n",
            "\n",
            "  ---- Epoch  25  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  26  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.88 Test accuracy: 0.63\n",
            "\n",
            "  ---- Epoch  27  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.63\n",
            "\n",
            "  ---- Epoch  28  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.89 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  29  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  30  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.91 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  31  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.93 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  32  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.93 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  33  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.92 Test accuracy: 0.63\n",
            "\n",
            "  ---- Epoch  34  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  35  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.9 Test accuracy: 0.63\n",
            "\n",
            "  ---- Epoch  36  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.94 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  37  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.91 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  38  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.635\n",
            "\n",
            "  ---- Epoch  39  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  40  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  41  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  42  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  43  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  44  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  45  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  46  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  47  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  48  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  49  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  50  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.62\n",
            "\n",
            "  ---- Epoch  51  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  52  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.95 Test accuracy: 0.635\n",
            "\n",
            "  ---- Epoch  53  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.635\n",
            "\n",
            "  ---- Epoch  54  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  55  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.97 Test accuracy: 0.665\n",
            "\n",
            "  ---- Epoch  56  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  57  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  58  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  59  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  60  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.67\n",
            "\n",
            "  ---- Epoch  61  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  62  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.665\n",
            "\n",
            "  ---- Epoch  63  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  64  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  65  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  66  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.665\n",
            "\n",
            "  ---- Epoch  67  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.665\n",
            "\n",
            "  ---- Epoch  68  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  69  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  70  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  71  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  72  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  73  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  74  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  75  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  76  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  77  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  78  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.98 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  79  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.96 Test accuracy: 0.625\n",
            "\n",
            "  ---- Epoch  80  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.92 Test accuracy: 0.615\n",
            "\n",
            "  ---- Epoch  81  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  82  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 0.99 Test accuracy: 0.64\n",
            "\n",
            "  ---- Epoch  83  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  84  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  85  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.645\n",
            "\n",
            "  ---- Epoch  86  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  87  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  88  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  89  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  90  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.65\n",
            "\n",
            "  ---- Epoch  91  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.655\n",
            "\n",
            "  ---- Epoch  92  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  93  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  94  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  95  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  96  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  97  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  98  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n",
            "\n",
            "  ---- Epoch  99  ----\n",
            "\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "\n",
            "  Train accuracy: 1.0 Test accuracy: 0.66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0d4YdYeDkV2"
      },
      "source": [
        "Model 2b: Long Short term Memory (LTSM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc6i-9gadlph",
        "outputId": "f72baf70-6e9e-44e4-c7d9-39c5fb378317"
      },
      "source": [
        "\n",
        "reset_graph()\n",
        "\n",
        "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "n_layers = 3\n",
        "\n",
        "learning_rate = 0.0001\n",
        "\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "lstm_cells = [tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
        "              for layer in range(n_layers)]\n",
        "multi_cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
        "top_layer_h_state = states[-1][1]\n",
        "logits = tf.layers.dense(top_layer_h_state, n_outputs, name=\"softmax\")\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(y_train.shape[0] // batch_size):          \n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            print('  Batch ', iteration, ' training observations from ',  \n",
        "                  iteration*batch_size, ' to ', (iteration + 1)*batch_size-1,)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(\"Epoch\", epoch, \"Train accuracy =\", acc_train, \"Test accuracy =\", acc_test)\n",
        "\n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "\n",
        "metrics['Model 2b-LTSM (300d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 0 Train accuracy = 0.5 Test accuracy = 0.48\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 1 Train accuracy = 0.48 Test accuracy = 0.48\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 2 Train accuracy = 0.51 Test accuracy = 0.48\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 3 Train accuracy = 0.56 Test accuracy = 0.49\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 4 Train accuracy = 0.59 Test accuracy = 0.535\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 5 Train accuracy = 0.63 Test accuracy = 0.575\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 6 Train accuracy = 0.64 Test accuracy = 0.59\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 7 Train accuracy = 0.65 Test accuracy = 0.6\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 8 Train accuracy = 0.66 Test accuracy = 0.605\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 9 Train accuracy = 0.68 Test accuracy = 0.61\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 10 Train accuracy = 0.7 Test accuracy = 0.62\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 11 Train accuracy = 0.69 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 12 Train accuracy = 0.72 Test accuracy = 0.645\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 13 Train accuracy = 0.69 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 14 Train accuracy = 0.69 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 15 Train accuracy = 0.67 Test accuracy = 0.71\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 16 Train accuracy = 0.69 Test accuracy = 0.705\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 17 Train accuracy = 0.68 Test accuracy = 0.7\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 18 Train accuracy = 0.7 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 19 Train accuracy = 0.7 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 20 Train accuracy = 0.71 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 21 Train accuracy = 0.75 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 22 Train accuracy = 0.76 Test accuracy = 0.65\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 23 Train accuracy = 0.77 Test accuracy = 0.645\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 24 Train accuracy = 0.77 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 25 Train accuracy = 0.77 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 26 Train accuracy = 0.77 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 27 Train accuracy = 0.78 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 28 Train accuracy = 0.8 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 29 Train accuracy = 0.81 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 30 Train accuracy = 0.81 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 31 Train accuracy = 0.81 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 32 Train accuracy = 0.81 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 33 Train accuracy = 0.82 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 34 Train accuracy = 0.82 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 35 Train accuracy = 0.83 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 36 Train accuracy = 0.83 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 37 Train accuracy = 0.84 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 38 Train accuracy = 0.84 Test accuracy = 0.66\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 39 Train accuracy = 0.85 Test accuracy = 0.665\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 40 Train accuracy = 0.85 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 41 Train accuracy = 0.85 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 42 Train accuracy = 0.86 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 43 Train accuracy = 0.86 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 44 Train accuracy = 0.86 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 45 Train accuracy = 0.87 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 46 Train accuracy = 0.87 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 47 Train accuracy = 0.87 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 48 Train accuracy = 0.87 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 49 Train accuracy = 0.87 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 50 Train accuracy = 0.87 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 51 Train accuracy = 0.87 Test accuracy = 0.67\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 52 Train accuracy = 0.87 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 53 Train accuracy = 0.87 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 54 Train accuracy = 0.88 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 55 Train accuracy = 0.89 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 56 Train accuracy = 0.9 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 57 Train accuracy = 0.9 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 58 Train accuracy = 0.9 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 59 Train accuracy = 0.92 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 60 Train accuracy = 0.92 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 61 Train accuracy = 0.93 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 62 Train accuracy = 0.93 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 63 Train accuracy = 0.93 Test accuracy = 0.68\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 64 Train accuracy = 0.93 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 65 Train accuracy = 0.93 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 66 Train accuracy = 0.93 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 67 Train accuracy = 0.94 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 68 Train accuracy = 0.94 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 69 Train accuracy = 0.94 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 70 Train accuracy = 0.94 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 71 Train accuracy = 0.94 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 72 Train accuracy = 0.94 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 73 Train accuracy = 0.94 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 74 Train accuracy = 0.94 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 75 Train accuracy = 0.95 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 76 Train accuracy = 0.95 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 77 Train accuracy = 0.95 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 78 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 79 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 80 Train accuracy = 0.93 Test accuracy = 0.7\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 81 Train accuracy = 0.94 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 82 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 83 Train accuracy = 0.94 Test accuracy = 0.675\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 84 Train accuracy = 0.92 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 85 Train accuracy = 0.95 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 86 Train accuracy = 0.96 Test accuracy = 0.7\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 87 Train accuracy = 0.95 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 88 Train accuracy = 0.95 Test accuracy = 0.7\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 89 Train accuracy = 0.95 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 90 Train accuracy = 0.95 Test accuracy = 0.69\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 91 Train accuracy = 0.95 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 92 Train accuracy = 0.95 Test accuracy = 0.685\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 93 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 94 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 95 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 96 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 97 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 98 Train accuracy = 0.95 Test accuracy = 0.695\n",
            "  Batch  0  training observations from  0  to  99\n",
            "  Batch  1  training observations from  100  to  199\n",
            "  Batch  2  training observations from  200  to  299\n",
            "  Batch  3  training observations from  300  to  399\n",
            "  Batch  4  training observations from  400  to  499\n",
            "  Batch  5  training observations from  500  to  599\n",
            "  Batch  6  training observations from  600  to  699\n",
            "  Batch  7  training observations from  700  to  799\n",
            "Epoch 99 Train accuracy = 0.95 Test accuracy = 0.695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JffFgpjdlpi"
      },
      "source": [
        "Model 2c: Drop cell (300d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvoT2CJWdlpi",
        "outputId": "ff70215e-1383-4ddf-f9f3-afdfb7f3157f"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "# lstm_cell = tf.contrib.rnn.BasicLSTMCell(num_units=n_neurons)\n",
        "\n",
        "n_steps = embeddings_array.shape[1]  # number of words per document \n",
        "n_inputs = embeddings_array.shape[2]  # dimension of  pre-trained embeddings\n",
        "n_neurons = 20  # analyst specified number of neurons\n",
        "n_outputs = 2  # thumbs-down or thumbs-up\n",
        "n_layers = 3\n",
        "\n",
        "learning_rate = 0.001\n",
        "# Start timer\n",
        "start = datetime.datetime.now()\n",
        "\n",
        "# Set X and y placeholders\n",
        "\n",
        "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
        "y = tf.placeholder(tf.int32, [None])\n",
        "\n",
        "keep_prob = tf.placeholder_with_default(.5, shape=())\n",
        "cells = [tf.nn.rnn_cell.BasicRNNCell(num_units=n_neurons)\n",
        "         for layer in range(n_layers)]\n",
        "cells_drop = [tf.nn.rnn_cell.DropoutWrapper(cell, input_keep_prob=keep_prob)\n",
        "              for cell in cells]\n",
        "multi_layer_cell = tf.nn.rnn_cell.MultiRNNCell(cells_drop)\n",
        "outputs, states = tf.nn.dynamic_rnn(multi_layer_cell, X, dtype=tf.float32)\n",
        "\n",
        "states_concat = tf.concat(axis=1, values=states)\n",
        "logits = tf.layers.dense(states_concat, n_outputs)\n",
        "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "loss = tf.reduce_mean(xentropy)\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "training_op = optimizer.minimize(loss)\n",
        "correct = tf.nn.in_top_k(logits, y, 1)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "        \n",
        "n_epochs = 100\n",
        "batch_size = 100\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(y_train.shape[0] // batch_size):\n",
        "            X_batch = X_train[iteration*batch_size:(iteration + 1)*batch_size,:]\n",
        "            y_batch = y_train[iteration*batch_size:(iteration + 1)*batch_size]\n",
        "            X_batch = X_batch.reshape((-1, n_steps, n_inputs))\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Test accuracy:\", acc_test)\n",
        "\n",
        "# Record the time it takes\n",
        "duration = datetime.datetime.now() - start\n",
        "\n",
        "metrics['Model 2c-Drop Cell (300d)'] = [100,duration, acc_train, acc_test]"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:421: UserWarning: `tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.SimpleRNNCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicRNNCell` is deprecated and will be \"\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.5 Test accuracy: 0.485\n",
            "1 Train accuracy: 0.48 Test accuracy: 0.49\n",
            "2 Train accuracy: 0.55 Test accuracy: 0.455\n",
            "3 Train accuracy: 0.6 Test accuracy: 0.54\n",
            "4 Train accuracy: 0.5 Test accuracy: 0.5\n",
            "5 Train accuracy: 0.62 Test accuracy: 0.525\n",
            "6 Train accuracy: 0.55 Test accuracy: 0.49\n",
            "7 Train accuracy: 0.55 Test accuracy: 0.545\n",
            "8 Train accuracy: 0.62 Test accuracy: 0.58\n",
            "9 Train accuracy: 0.66 Test accuracy: 0.525\n",
            "10 Train accuracy: 0.69 Test accuracy: 0.535\n",
            "11 Train accuracy: 0.62 Test accuracy: 0.61\n",
            "12 Train accuracy: 0.61 Test accuracy: 0.515\n",
            "13 Train accuracy: 0.63 Test accuracy: 0.545\n",
            "14 Train accuracy: 0.7 Test accuracy: 0.57\n",
            "15 Train accuracy: 0.66 Test accuracy: 0.565\n",
            "16 Train accuracy: 0.73 Test accuracy: 0.605\n",
            "17 Train accuracy: 0.65 Test accuracy: 0.57\n",
            "18 Train accuracy: 0.78 Test accuracy: 0.59\n",
            "19 Train accuracy: 0.71 Test accuracy: 0.595\n",
            "20 Train accuracy: 0.72 Test accuracy: 0.585\n",
            "21 Train accuracy: 0.76 Test accuracy: 0.605\n",
            "22 Train accuracy: 0.7 Test accuracy: 0.6\n",
            "23 Train accuracy: 0.78 Test accuracy: 0.61\n",
            "24 Train accuracy: 0.73 Test accuracy: 0.655\n",
            "25 Train accuracy: 0.73 Test accuracy: 0.645\n",
            "26 Train accuracy: 0.76 Test accuracy: 0.6\n",
            "27 Train accuracy: 0.77 Test accuracy: 0.58\n",
            "28 Train accuracy: 0.73 Test accuracy: 0.68\n",
            "29 Train accuracy: 0.8 Test accuracy: 0.685\n",
            "30 Train accuracy: 0.75 Test accuracy: 0.595\n",
            "31 Train accuracy: 0.81 Test accuracy: 0.66\n",
            "32 Train accuracy: 0.75 Test accuracy: 0.67\n",
            "33 Train accuracy: 0.79 Test accuracy: 0.64\n",
            "34 Train accuracy: 0.83 Test accuracy: 0.675\n",
            "35 Train accuracy: 0.79 Test accuracy: 0.595\n",
            "36 Train accuracy: 0.77 Test accuracy: 0.63\n",
            "37 Train accuracy: 0.76 Test accuracy: 0.645\n",
            "38 Train accuracy: 0.75 Test accuracy: 0.66\n",
            "39 Train accuracy: 0.75 Test accuracy: 0.64\n",
            "40 Train accuracy: 0.82 Test accuracy: 0.6\n",
            "41 Train accuracy: 0.82 Test accuracy: 0.625\n",
            "42 Train accuracy: 0.75 Test accuracy: 0.63\n",
            "43 Train accuracy: 0.84 Test accuracy: 0.605\n",
            "44 Train accuracy: 0.79 Test accuracy: 0.69\n",
            "45 Train accuracy: 0.86 Test accuracy: 0.605\n",
            "46 Train accuracy: 0.78 Test accuracy: 0.685\n",
            "47 Train accuracy: 0.81 Test accuracy: 0.675\n",
            "48 Train accuracy: 0.8 Test accuracy: 0.67\n",
            "49 Train accuracy: 0.8 Test accuracy: 0.63\n",
            "50 Train accuracy: 0.89 Test accuracy: 0.675\n",
            "51 Train accuracy: 0.84 Test accuracy: 0.68\n",
            "52 Train accuracy: 0.79 Test accuracy: 0.66\n",
            "53 Train accuracy: 0.77 Test accuracy: 0.655\n",
            "54 Train accuracy: 0.81 Test accuracy: 0.68\n",
            "55 Train accuracy: 0.8 Test accuracy: 0.625\n",
            "56 Train accuracy: 0.84 Test accuracy: 0.655\n",
            "57 Train accuracy: 0.86 Test accuracy: 0.69\n",
            "58 Train accuracy: 0.84 Test accuracy: 0.64\n",
            "59 Train accuracy: 0.85 Test accuracy: 0.69\n",
            "60 Train accuracy: 0.86 Test accuracy: 0.64\n",
            "61 Train accuracy: 0.82 Test accuracy: 0.65\n",
            "62 Train accuracy: 0.81 Test accuracy: 0.64\n",
            "63 Train accuracy: 0.79 Test accuracy: 0.605\n",
            "64 Train accuracy: 0.83 Test accuracy: 0.625\n",
            "65 Train accuracy: 0.82 Test accuracy: 0.615\n",
            "66 Train accuracy: 0.76 Test accuracy: 0.64\n",
            "67 Train accuracy: 0.82 Test accuracy: 0.64\n",
            "68 Train accuracy: 0.82 Test accuracy: 0.65\n",
            "69 Train accuracy: 0.84 Test accuracy: 0.645\n",
            "70 Train accuracy: 0.87 Test accuracy: 0.64\n",
            "71 Train accuracy: 0.83 Test accuracy: 0.635\n",
            "72 Train accuracy: 0.84 Test accuracy: 0.705\n",
            "73 Train accuracy: 0.84 Test accuracy: 0.65\n",
            "74 Train accuracy: 0.85 Test accuracy: 0.61\n",
            "75 Train accuracy: 0.8 Test accuracy: 0.635\n",
            "76 Train accuracy: 0.85 Test accuracy: 0.645\n",
            "77 Train accuracy: 0.75 Test accuracy: 0.665\n",
            "78 Train accuracy: 0.85 Test accuracy: 0.635\n",
            "79 Train accuracy: 0.78 Test accuracy: 0.665\n",
            "80 Train accuracy: 0.82 Test accuracy: 0.65\n",
            "81 Train accuracy: 0.81 Test accuracy: 0.655\n",
            "82 Train accuracy: 0.86 Test accuracy: 0.62\n",
            "83 Train accuracy: 0.9 Test accuracy: 0.61\n",
            "84 Train accuracy: 0.74 Test accuracy: 0.63\n",
            "85 Train accuracy: 0.84 Test accuracy: 0.615\n",
            "86 Train accuracy: 0.83 Test accuracy: 0.59\n",
            "87 Train accuracy: 0.84 Test accuracy: 0.635\n",
            "88 Train accuracy: 0.84 Test accuracy: 0.61\n",
            "89 Train accuracy: 0.87 Test accuracy: 0.6\n",
            "90 Train accuracy: 0.88 Test accuracy: 0.62\n",
            "91 Train accuracy: 0.83 Test accuracy: 0.64\n",
            "92 Train accuracy: 0.87 Test accuracy: 0.64\n",
            "93 Train accuracy: 0.85 Test accuracy: 0.64\n",
            "94 Train accuracy: 0.85 Test accuracy: 0.68\n",
            "95 Train accuracy: 0.84 Test accuracy: 0.64\n",
            "96 Train accuracy: 0.79 Test accuracy: 0.63\n",
            "97 Train accuracy: 0.8 Test accuracy: 0.645\n",
            "98 Train accuracy: 0.9 Test accuracy: 0.61\n",
            "99 Train accuracy: 0.86 Test accuracy: 0.655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjHY6f47dlpj"
      },
      "source": [
        "Result"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "2rVU5w3_dlpj",
        "scrolled": true,
        "outputId": "b2606650-b6d2-497c-ea15-ebcf6d43c6b0"
      },
      "source": [
        "# Convert metrics dictionary to dataframe for display\n",
        "results = pd.DataFrame.from_dict(metrics, orient='index')\n",
        "results.columns = names\n",
        "\n",
        "# Sort by model number\n",
        "results.reset_index(inplace=True)\n",
        "results.sort_values(by=['index'], axis=0, inplace=True)\n",
        "results.set_index(['index'], inplace=True)\n",
        "results.index.name = None\n",
        "results\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch Count</th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>Training Accuracy</th>\n",
              "      <th>Test Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Model 1a-simple RNN (100d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:12.424161</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model 1b-LSTM (100d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:35.369073</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model 1c-Drop Cell (100d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:22.474514</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model 2a-simple RNN (300d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:23.215711</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model 2b-LTSM (300d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:47.749650</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model 2c-Drop Cell (300d)</th>\n",
              "      <td>100</td>\n",
              "      <td>0 days 00:00:41.109933</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.655</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Epoch Count  ... Test Accuracy\n",
              "Model 1a-simple RNN (100d)          100  ...         0.685\n",
              "Model 1b-LSTM (100d)                100  ...         0.665\n",
              "Model 1c-Drop Cell (100d)           100  ...         0.640\n",
              "Model 2a-simple RNN (300d)          100  ...         0.660\n",
              "Model 2b-LTSM (300d)                100  ...         0.695\n",
              "Model 2c-Drop Cell (300d)           100  ...         0.655\n",
              "\n",
              "[6 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ3zk6-6dlpl"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "# Background and management problem description\n",
        "\n",
        "Establishing an effective and efficient customer management system by building a language model that is capable of identifying negative customer feelings\n",
        "\n",
        "# Research design and modeling methods\n",
        "Utilize RNN within Python for negative and positive comments identification.\n",
        "The steps for the analysis are the following:\n",
        "1.\tRevise the jump-start code to accommodate two pre-trained word vectors and two vocabulary sizes. \n",
        "2.\tBuild four distinct language models by twisting the RNN structures or hyperparameter settings.\n",
        "3.\tEvaluate four language models using classification accuracy in the test set. \n",
        "\n",
        "# Results and Recommendations\n",
        "Below is a summary of the models that were created in the process of this analysis and their performance comparison. Performance variables include processing time and the accuracy scores of training and test sets.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "With a 69.5% Test accuracy and 95% Training accuracy, if not considering the process time, I would recommend Model 2b-LTSM (300d) to be used as an language model for building a customer support system that is capable to identify negative comments from customers, if taking into consideration of process time, Model 1a-simple RNN (100d) can be used as an alternative option for speedy identification, with a slightly lower test accuracy of 68.5%."
      ]
    }
  ]
}